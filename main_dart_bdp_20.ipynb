{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0171405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "from data_loader_darts import get_dataloaders_simple\n",
    "# from darts_search_bdp import train_darts_search_bdp\n",
    "from darts_search_bdp import train_darts_search_bdp\n",
    "from model_build import FinalNetwork\n",
    "from cell_plot import plot_cell\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48d0748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading 50/50 split data...\n",
      "[DEBUG] Loaded ./PSG/SC4001E0.npz → 841 samples\n",
      "[DEBUG] Loaded ./PSG/SC4002E0.npz → 1127 samples\n",
      "[DEBUG] Loaded ./PSG/SC4011E0.npz → 1103 samples\n",
      "[DEBUG] Loaded ./PSG/SC4012E0.npz → 1186 samples\n",
      "[DEBUG] Loaded ./PSG/SC4021E0.npz → 1025 samples\n",
      "[DEBUG] Loaded ./PSG/SC4022E0.npz → 1009 samples\n",
      "[DEBUG] Loaded ./PSG/SC4031E0.npz → 952 samples\n",
      "[DEBUG] Loaded ./PSG/SC4032E0.npz → 911 samples\n",
      "[DEBUG] Loaded ./PSG/SC4041E0.npz → 1235 samples\n",
      "[DEBUG] Loaded ./PSG/SC4042E0.npz → 1200 samples\n",
      "[DEBUG] Loaded ./PSG/SC4051E0.npz → 672 samples\n",
      "[DEBUG] Loaded ./PSG/SC4052E0.npz → 1246 samples\n",
      "[DEBUG] Loaded ./PSG/SC4061E0.npz → 843 samples\n",
      "[DEBUG] Loaded ./PSG/SC4062E0.npz → 1016 samples\n",
      "[DEBUG] Loaded ./PSG/SC4071E0.npz → 976 samples\n",
      "[DEBUG] Loaded ./PSG/SC4072E0.npz → 1273 samples\n",
      "[DEBUG] Loaded ./PSG/SC4081E0.npz → 1134 samples\n",
      "[DEBUG] Loaded ./PSG/SC4082E0.npz → 1054 samples\n",
      "[DEBUG] Loaded ./PSG/SC4091E0.npz → 1132 samples\n",
      "[DEBUG] Loaded ./PSG/SC4092E0.npz → 1105 samples\n",
      "[DEBUG] Loaded ./PSG/SC4101E0.npz → 1104 samples\n",
      "[DEBUG] Loaded ./PSG/SC4102E0.npz → 1092 samples\n",
      "[DEBUG] Loaded ./PSG/SC4111E0.npz → 928 samples\n",
      "[DEBUG] Loaded ./PSG/SC4112E0.npz → 802 samples\n",
      "[DEBUG] Loaded ./PSG/SC4121E0.npz → 1052 samples\n",
      "[DEBUG] Loaded ./PSG/SC4122E0.npz → 977 samples\n",
      "[DEBUG] Loaded ./PSG/SC4131E0.npz → 1028 samples\n",
      "[DEBUG] Loaded ./PSG/SC4141E0.npz → 1004 samples\n",
      "[DEBUG] Loaded ./PSG/SC4142E0.npz → 952 samples\n",
      "[DEBUG] Loaded ./PSG/SC4151E0.npz → 952 samples\n",
      "[DEBUG] Loaded ./PSG/SC4152E0.npz → 1762 samples\n",
      "[DEBUG] Loaded ./PSG/SC4161E0.npz → 1144 samples\n",
      "[DEBUG] Loaded ./PSG/SC4162E0.npz → 1003 samples\n",
      "[DEBUG] Loaded ./PSG/SC4171E0.npz → 1002 samples\n",
      "[DEBUG] Loaded ./PSG/SC4172E0.npz → 1773 samples\n",
      "[DEBUG] Loaded ./PSG/SC4181E0.npz → 964 samples\n",
      "[DEBUG] Loaded ./PSG/SC4182E0.npz → 920 samples\n",
      "[DEBUG] Loaded ./PSG/SC4191E0.npz → 1535 samples\n",
      "[DEBUG] Loaded ./PSG/SC4192E0.npz → 1274 samples\n",
      "[INFO] DARTS will run on 21154 train samples and 21154 val samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Set random seed\n",
    "set_seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 2. Load data\n",
    "print(\"[INFO] Loading 50/50 split data...\")\n",
    "train_loader, val_loader, num_classes = get_dataloaders_simple(batch_size=32)\n",
    "print(f\"[INFO] DARTS will run on {len(train_loader.dataset.y)} train samples and {len(val_loader.dataset.y)} val samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d3954e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running DARTS search with BDP...\n",
      "\n",
      "[Epoch 1/25] Starting...\n",
      "[Epoch 1] Train Loss: 1.0660 | Acc: 0.5704 || Val Loss: 1.0277 | Acc: 0.5929\n",
      "\n",
      "[Epoch 2/25] Starting...\n",
      "[Epoch 2] Train Loss: 0.8630 | Acc: 0.6669 || Val Loss: 0.7655 | Acc: 0.6751\n",
      "\n",
      "[Epoch 3/25] Starting...\n",
      "[Epoch 3] Train Loss: 0.7609 | Acc: 0.7169 || Val Loss: 0.7263 | Acc: 0.7390\n",
      "\n",
      "[Epoch 4/25] Starting...\n",
      "[Epoch 4] Train Loss: 0.6786 | Acc: 0.7443 || Val Loss: 0.6234 | Acc: 0.7743\n",
      "\n",
      "[Epoch 5/25] Starting...\n",
      "[Epoch 5] Train Loss: 0.6301 | Acc: 0.7639 || Val Loss: 0.8818 | Acc: 0.6819\n",
      "[Annealable Pruning] T = 1.2218\n",
      "[Prune Epoch 5] Pruned 1057 train, 1057 val\n",
      "[After Prune] Remaining train samples: 20097, val samples: 20097\n",
      "\n",
      "[Epoch 6/25] Starting...\n",
      "[Epoch 6] Train Loss: 0.6176 | Acc: 0.7682 || Val Loss: 0.5769 | Acc: 0.7913\n",
      "\n",
      "[Epoch 7/25] Starting...\n",
      "[Epoch 7] Train Loss: 0.5778 | Acc: 0.7850 || Val Loss: 0.6124 | Acc: 0.7707\n",
      "\n",
      "[Epoch 8/25] Starting...\n",
      "[Epoch 8] Train Loss: 0.5711 | Acc: 0.7888 || Val Loss: 0.5566 | Acc: 0.7910\n",
      "\n",
      "[Epoch 9/25] Starting...\n",
      "[Epoch 9] Train Loss: 0.5693 | Acc: 0.7898 || Val Loss: 0.8004 | Acc: 0.6741\n",
      "\n",
      "[Epoch 10/25] Starting...\n",
      "[Epoch 10] Train Loss: 0.5782 | Acc: 0.7851 || Val Loss: 0.6181 | Acc: 0.7688\n",
      "[Annealable Pruning] T = 0.9454\n",
      "[Prune Epoch 10] Pruned 1057 train, 1057 val\n",
      "[After Prune] Remaining train samples: 19063, val samples: 19169\n",
      "\n",
      "[Epoch 11/25] Starting...\n",
      "[Epoch 11] Train Loss: 0.5474 | Acc: 0.7948 || Val Loss: 0.5868 | Acc: 0.7934\n",
      "\n",
      "[Epoch 12/25] Starting...\n",
      "[Epoch 12] Train Loss: 0.5333 | Acc: 0.8031 || Val Loss: 0.5248 | Acc: 0.8050\n",
      "\n",
      "[Epoch 13/25] Starting...\n",
      "[Epoch 13] Train Loss: 0.5222 | Acc: 0.8089 || Val Loss: 0.5351 | Acc: 0.8093\n",
      "\n",
      "[Epoch 14/25] Starting...\n",
      "[Epoch 14] Train Loss: 0.5109 | Acc: 0.8121 || Val Loss: 0.5130 | Acc: 0.8104\n",
      "\n",
      "[Epoch 15/25] Starting...\n",
      "[Epoch 15] Train Loss: 0.5169 | Acc: 0.8090 || Val Loss: 0.5257 | Acc: 0.8105\n",
      "[Annealable Pruning] T = 0.7315\n",
      "[Prune Epoch 15] Pruned 1057 train, 1057 val\n",
      "[After Prune] Remaining train samples: 18050, val samples: 18427\n",
      "\n",
      "[Epoch 16/25] Starting...\n",
      "[Epoch 16] Train Loss: 0.5050 | Acc: 0.8148 || Val Loss: 0.5147 | Acc: 0.8076\n",
      "\n",
      "[Epoch 17/25] Starting...\n",
      "[Epoch 17] Train Loss: 0.4980 | Acc: 0.8167 || Val Loss: 0.4899 | Acc: 0.8237\n",
      "\n",
      "[Epoch 18/25] Starting...\n",
      "[Epoch 18] Train Loss: 0.4905 | Acc: 0.8188 || Val Loss: 0.4789 | Acc: 0.8295\n",
      "\n",
      "[Epoch 19/25] Starting...\n",
      "[Epoch 19] Train Loss: 0.4819 | Acc: 0.8206 || Val Loss: 0.4790 | Acc: 0.8238\n",
      "\n",
      "[Epoch 20/25] Starting...\n",
      "[Epoch 20] Train Loss: 0.4801 | Acc: 0.8223 || Val Loss: 0.4744 | Acc: 0.8303\n",
      "[Annealable Pruning] T = 0.5660\n",
      "[Prune Epoch 20] Pruned 1057 train, 1057 val\n",
      "[After Prune] Remaining train samples: 17062, val samples: 17897\n",
      "\n",
      "[Epoch 21/25] Starting...\n",
      "[Epoch 21] Train Loss: 0.4761 | Acc: 0.8255 || Val Loss: 0.4900 | Acc: 0.8220\n",
      "\n",
      "[Epoch 22/25] Starting...\n",
      "[Epoch 22] Train Loss: 0.4675 | Acc: 0.8275 || Val Loss: 0.4711 | Acc: 0.8296\n",
      "\n",
      "[Epoch 23/25] Starting...\n",
      "[Epoch 23] Train Loss: 0.4630 | Acc: 0.8291 || Val Loss: 0.4692 | Acc: 0.8317\n",
      "\n",
      "[Epoch 24/25] Starting...\n",
      "[Epoch 24] Train Loss: 0.4586 | Acc: 0.8308 || Val Loss: 0.4628 | Acc: 0.8342\n",
      "\n",
      "[Epoch 25/25] Starting...\n",
      "[Epoch 25] Train Loss: 0.4571 | Acc: 0.8330 || Val Loss: 0.4628 | Acc: 0.8315\n",
      "[INFO] Metrics saved to 'search_metrics_log.csv'\n",
      "\n",
      "Final Searched Genotype:\n",
      " Genotype(normal=[('sep_conv_1x5', 0), ('sep_conv_1x5', 1), ('sep_conv_1x5', 0), ('max_pool_3x3', 2), ('max_pool_3x3', 2), ('max_pool_3x3', 3), ('sep_conv_1x5', 0), ('sep_conv_1x5', 1), ('sep_conv_1x5', 1), ('max_pool_3x3', 5), ('dil_conv_1x5', 0), ('dil_conv_1x5', 0)], normal_concat=[0, 1, 2, 3, 4], reduce=[('sep_conv_1x3', 0), ('sep_conv_1x5', 1), ('dil_conv_1x5', 0), ('dil_conv_1x5', 2), ('max_pool_3x3', 0), ('max_pool_3x3', 3), ('max_pool_3x3', 0), ('max_pool_3x3', 4), ('max_pool_3x3', 5), ('max_pool_3x3', 0)], reduce_concat=[0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 3. Run DARTS search with pruning\n",
    "print(\"[INFO] Running DARTS search with BDP...\")\n",
    "searched_genotype, pruned_train_loader, pruned_val_loader = train_darts_search_bdp(\n",
    "    train_loader, val_loader, num_classes,\n",
    "    epochs=25, prune_every=5, pt=0.05, pv=0.05,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27bb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Genotype = namedtuple('Genotype', 'normal normal_concat reduce reduce_concat')\n",
    "\n",
    "searched_genotype = Genotype(\n",
    "    normal=[\n",
    "        ('sep_conv_1x5', 0),\n",
    "        ('sep_conv_1x5', 1),\n",
    "        ('sep_conv_1x5', 0),\n",
    "        ('max_pool_3x3', 2),\n",
    "        ('max_pool_3x3', 2),\n",
    "        ('max_pool_3x3', 3),\n",
    "        ('sep_conv_1x5', 0),\n",
    "        ('sep_conv_1x5', 1),\n",
    "        ('sep_conv_1x5', 1),\n",
    "        ('max_pool_3x3', 5),\n",
    "        ('dil_conv_1x5', 0),\n",
    "        ('dil_conv_1x5', 0)\n",
    "    ],\n",
    "    normal_concat=[0, 1, 2, 3, 4],\n",
    "\n",
    "    reduce=[\n",
    "        ('sep_conv_1x3', 0),\n",
    "        ('sep_conv_1x5', 1),\n",
    "        ('dil_conv_1x5', 0),\n",
    "        ('dil_conv_1x5', 2),\n",
    "        ('max_pool_3x3', 0),\n",
    "        ('max_pool_3x3', 3),\n",
    "        ('max_pool_3x3', 0),\n",
    "        ('max_pool_3x3', 4),\n",
    "        ('max_pool_3x3', 5),\n",
    "        ('avg_pool_3x3', 0)\n",
    "    ],\n",
    "    reduce_concat=[0, 1, 2, 3, 4]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774adc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running 5-Fold Cross Validation on pruned data...\n",
      "✅ Đã lưu dữ liệu gốc (KHÔNG chuẩn hóa) vào 'pruned_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"[INFO] Running 5-Fold Cross Validation on pruned data...\")\n",
    "\n",
    "# === Hàm trích xuất toàn bộ dữ liệu từ DataLoader ===\n",
    "def extract_from_loader(loader):\n",
    "    X_list, y_list = [], []\n",
    "    for x, y in loader:\n",
    "        X_list.append(x.cpu())\n",
    "        y_list.append(y.cpu())\n",
    "    return torch.cat(X_list, dim=0), torch.cat(y_list, dim=0)\n",
    "\n",
    "# === Trích xuất X, y từ train và val loader ===\n",
    "X_train_all, y_train_all = extract_from_loader(pruned_train_loader)\n",
    "X_val_all,   y_val_all   = extract_from_loader(pruned_val_loader)\n",
    "\n",
    "# Gộp train + val\n",
    "X_all = torch.cat([X_train_all, X_val_all], dim=0)  # shape: (N, C, T) hoặc (N, T)\n",
    "y_all = torch.cat([y_train_all, y_val_all], dim=0)  # shape: (N,)\n",
    "\n",
    "# === Chuyển về numpy ===\n",
    "X_np = X_all.numpy()\n",
    "y_np = y_all.numpy().reshape(-1, 1)\n",
    "\n",
    "# === Reshape X về (N, D) nếu cần (flatten nếu có chiều phụ) ===\n",
    "if X_np.ndim > 2:\n",
    "    X_np = X_np.reshape(X_np.shape[0], -1)  # (N, D)\n",
    "\n",
    "# ❌ KHÔNG chuẩn hóa, giữ nguyên raw X_np\n",
    "\n",
    "# === Ghép lại X và y ===\n",
    "data_np = np.hstack((X_np, y_np))  # shape: (N, D+1)\n",
    "\n",
    "# === Tạo DataFrame và lưu CSV ===\n",
    "num_features = X_np.shape[1]\n",
    "column_names = [f\"feature_{i}\" for i in range(num_features)] + [\"label\"]\n",
    "df = pd.DataFrame(data_np, columns=column_names)\n",
    "\n",
    "df.to_csv(\"pruned_dataset.csv\", index=False)\n",
    "print(\"✅ Đã lưu dữ liệu gốc (KHÔNG chuẩn hóa) vào 'pruned_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f83a9662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Number of samples per class:\n",
      "  Class 0: 6570 samples\n",
      "  Class 1: 2504 samples\n",
      "  Class 2: 14965 samples\n",
      "  Class 3: 4274 samples\n",
      "  Class 4: 6638 samples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"pruned_dataset.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "unique, counts = np.unique(y_np, return_counts=True)\n",
    "\n",
    "print(\"\\n[INFO] Number of samples per class:\")\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"  Class {label}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cec369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://deb.nodesource.com/node_20.x nodistro InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Reading package lists... Done\u001b[33m\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "171 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Note, selecting 'libgraphviz-dev' instead of 'graphviz-dev'\n",
      "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
      "libgraphviz-dev is already the newest version (2.42.2-6ubuntu0.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 171 not upgraded.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pygraphviz\n",
      "  Downloading pygraphviz-1.14.tar.gz (106 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pygraphviz\n",
      "  Building wheel for pygraphviz (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pygraphviz: filename=pygraphviz-1.14-cp310-cp310-linux_x86_64.whl size=168674 sha256=076585350cd5f30df76e3f0724db748f4413b53c909b29634faae15a4433c5ee\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vk28zoi1/wheels/61/ab/cd/e24a22c32830b8b4948c8887d8714d399f0f806f206a034698\n",
      "Successfully built pygraphviz\n",
      "\u001b[33mWARNING: Error parsing dependencies of devscripts: Invalid version: '2.22.1ubuntu1'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pygraphviz\n",
      "Successfully installed pygraphviz-1.14\n",
      "[INFO] Visualizing searched cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/Duc/NASEEG1_Final/NASEEG/SleepC/sleep_nas/cell_plot.py:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "!sudo apt update\n",
    "!sudo apt install -y graphviz graphviz-dev\n",
    "!pip install pygraphviz\n",
    "# 4. Visualize searched cells\n",
    "print(\"[INFO] Visualizing searched cells...\")\n",
    "plot_cell(searched_genotype, 'normal')\n",
    "plot_cell(searched_genotype, 'reduce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-search filter pruning based on information capacity and independence (Stage 2)\n",
    "# === Entropy-based pruning ===\n",
    "def compute_filter_entropy(weight_tensor):\n",
    "    entropy_list = []\n",
    "    for filt in weight_tensor:\n",
    "        filt_flat = filt.view(filt.size(0), -1)\n",
    "        norms = torch.norm(filt_flat, dim=1) + 1e-6\n",
    "        p = norms / norms.sum()\n",
    "        entropy = -torch.sum(p * torch.log2(p))\n",
    "        entropy_list.append(entropy.item())\n",
    "    return entropy_list\n",
    "\n",
    "def prune_model_entropy(model, prune_ratio=0.5):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv1d):\n",
    "            weight = module.weight.data.detach().cpu()\n",
    "            entropy = compute_filter_entropy(weight)\n",
    "            entropy_tensor = torch.tensor(entropy)\n",
    "            k = int((1 - prune_ratio) * len(entropy))\n",
    "            topk_indices = torch.topk(entropy_tensor, k=k).indices\n",
    "            mask = torch.zeros_like(entropy_tensor)\n",
    "            mask[topk_indices] = 1.0\n",
    "            full_mask = mask[:, None, None].expand_as(weight).to(module.weight.device)\n",
    "            module.weight.data *= full_mask\n",
    "    return model\n",
    "\n",
    "def count_pruned_weights(model):\n",
    "    total, nonzero = 0, 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, (nn.Conv1d, nn.Linear)):\n",
    "            w = module.weight.data\n",
    "            total += w.numel()\n",
    "            nonzero += w.nonzero().size(0)\n",
    "    zero = total - nonzero\n",
    "    print(f\"[INFO] Total weights: {total}\")\n",
    "    print(f\"[INFO] Non-zero weights: {nonzero}\")\n",
    "    print(f\"[INFO] Pruned weights: {zero}\")\n",
    "    print(f\"[INFO] Pruned ratio: {100 * zero / total:.2f}%\")\n",
    "\n",
    "def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    gmeans = []\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        recall_c = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        gmeans.append(recall_c)\n",
    "\n",
    "    mgm = np.sqrt(np.prod(gmeans)) if np.all(np.array(gmeans) > 0) else 0.0\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, mf1, mgm, prec, rec, f1s, gmeans, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca70344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5451 | Train Acc: 0.8001 | Val Loss: 0.6944 | Val Acc: 0.7412\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4539 | Train Acc: 0.8337 | Val Loss: 0.6234 | Val Acc: 0.7750\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4392 | Train Acc: 0.8378 | Val Loss: 0.4072 | Val Acc: 0.8515\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4238 | Train Acc: 0.8445 | Val Loss: 0.4571 | Val Acc: 0.8346\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4201 | Train Acc: 0.8448 | Val Loss: 0.4132 | Val Acc: 0.8552\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4096 | Train Acc: 0.8501 | Val Loss: 0.4279 | Val Acc: 0.8441\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.4097 | Train Acc: 0.8486 | Val Loss: 0.4284 | Val Acc: 0.8429\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.3994 | Train Acc: 0.8524 | Val Loss: 0.4099 | Val Acc: 0.8489\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.3920 | Train Acc: 0.8572 | Val Loss: 0.4235 | Val Acc: 0.8435\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.3849 | Train Acc: 0.8584 | Val Loss: 0.3952 | Val Acc: 0.8528\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3827 | Train Acc: 0.8602 | Val Loss: 0.3973 | Val Acc: 0.8525\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3786 | Train Acc: 0.8601 | Val Loss: 0.4061 | Val Acc: 0.8562\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3759 | Train Acc: 0.8601 | Val Loss: 0.3728 | Val Acc: 0.8625\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3666 | Train Acc: 0.8665 | Val Loss: 0.3904 | Val Acc: 0.8511\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3634 | Train Acc: 0.8658 | Val Loss: 0.4568 | Val Acc: 0.8346\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3613 | Train Acc: 0.8672 | Val Loss: 0.3667 | Val Acc: 0.8601\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3546 | Train Acc: 0.8661 | Val Loss: 0.3808 | Val Acc: 0.8582\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3480 | Train Acc: 0.8721 | Val Loss: 0.4005 | Val Acc: 0.8515\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3445 | Train Acc: 0.8710 | Val Loss: 0.4576 | Val Acc: 0.8407\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3320 | Train Acc: 0.8769 | Val Loss: 0.3877 | Val Acc: 0.8564\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3320 | Train Acc: 0.8766 | Val Loss: 0.4150 | Val Acc: 0.8459\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.3259 | Train Acc: 0.8794 | Val Loss: 0.3946 | Val Acc: 0.8604\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.3207 | Train Acc: 0.8807 | Val Loss: 0.3875 | Val Acc: 0.8515\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.3137 | Train Acc: 0.8849 | Val Loss: 0.4639 | Val Acc: 0.8284\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.3045 | Train Acc: 0.8867 | Val Loss: 0.3906 | Val Acc: 0.8584\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.3006 | Train Acc: 0.8879 | Val Loss: 0.4048 | Val Acc: 0.8497\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.2932 | Train Acc: 0.8887 | Val Loss: 0.4346 | Val Acc: 0.8474\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.2893 | Train Acc: 0.8911 | Val Loss: 0.5081 | Val Acc: 0.8233\n",
      "[Early Stopping] No improvement in 15 epochs. Stopping at epoch 28.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 13\n",
      "ACC: 0.8625 | MF1: 0.8110 | G-Mean: 0.8776\n",
      "[Class 0] Prec: 0.9482 | Rec: 0.8829 | F1: 0.9144 | GM: 0.9344\n",
      "[Class 1] Prec: 0.5321 | Rec: 0.4877 | F1: 0.5089 | GM: 0.6860\n",
      "[Class 2] Prec: 0.9161 | Rec: 0.9018 | F1: 0.9089 | GM: 0.9196\n",
      "[Class 3] Prec: 0.9206 | Rec: 0.8844 | F1: 0.9021 | GM: 0.9353\n",
      "[Class 4] Prec: 0.7618 | Rec: 0.8890 | F1: 0.8205 | GM: 0.9128\n",
      "\n",
      "===== Fold 2 =====\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5625 | Train Acc: 0.7911 | Val Loss: 0.7045 | Val Acc: 0.7774\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4674 | Train Acc: 0.8254 | Val Loss: 0.4247 | Val Acc: 0.8499\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4476 | Train Acc: 0.8354 | Val Loss: 0.4202 | Val Acc: 0.8567\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4281 | Train Acc: 0.8415 | Val Loss: 0.5817 | Val Acc: 0.7798\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4217 | Train Acc: 0.8425 | Val Loss: 0.3981 | Val Acc: 0.8524\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4107 | Train Acc: 0.8471 | Val Loss: 0.4096 | Val Acc: 0.8575\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4010 | Train Acc: 0.8504 | Val Loss: 0.3975 | Val Acc: 0.8549\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.3946 | Train Acc: 0.8539 | Val Loss: 0.4521 | Val Acc: 0.8362\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.3954 | Train Acc: 0.8531 | Val Loss: 0.4052 | Val Acc: 0.8495\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.3871 | Train Acc: 0.8569 | Val Loss: 0.3826 | Val Acc: 0.8609\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3824 | Train Acc: 0.8582 | Val Loss: 0.3870 | Val Acc: 0.8574\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3763 | Train Acc: 0.8600 | Val Loss: 0.3997 | Val Acc: 0.8522\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3720 | Train Acc: 0.8602 | Val Loss: 0.4036 | Val Acc: 0.8539\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3684 | Train Acc: 0.8615 | Val Loss: 0.3806 | Val Acc: 0.8625\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3565 | Train Acc: 0.8661 | Val Loss: 0.4087 | Val Acc: 0.8494\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3514 | Train Acc: 0.8662 | Val Loss: 0.4461 | Val Acc: 0.8416\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3501 | Train Acc: 0.8702 | Val Loss: 0.3813 | Val Acc: 0.8637\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3416 | Train Acc: 0.8715 | Val Loss: 0.3828 | Val Acc: 0.8597\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3300 | Train Acc: 0.8759 | Val Loss: 0.4241 | Val Acc: 0.8505\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3349 | Train Acc: 0.8723 | Val Loss: 0.4445 | Val Acc: 0.8412\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3207 | Train Acc: 0.8790 | Val Loss: 0.4649 | Val Acc: 0.8316\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.3119 | Train Acc: 0.8847 | Val Loss: 0.3937 | Val Acc: 0.8604\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.3067 | Train Acc: 0.8829 | Val Loss: 0.4279 | Val Acc: 0.8475\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.3026 | Train Acc: 0.8882 | Val Loss: 0.4595 | Val Acc: 0.8403\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.2886 | Train Acc: 0.8930 | Val Loss: 0.4203 | Val Acc: 0.8449\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.2852 | Train Acc: 0.8932 | Val Loss: 0.3982 | Val Acc: 0.8581\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.2762 | Train Acc: 0.8962 | Val Loss: 0.4452 | Val Acc: 0.8479\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.2705 | Train Acc: 0.8986 | Val Loss: 0.4271 | Val Acc: 0.8499\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.2639 | Train Acc: 0.8997 | Val Loss: 0.4186 | Val Acc: 0.8561\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.2524 | Train Acc: 0.9049 | Val Loss: 0.4379 | Val Acc: 0.8649\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.2478 | Train Acc: 0.9067 | Val Loss: 0.4508 | Val Acc: 0.8559\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.2434 | Train Acc: 0.9089 | Val Loss: 0.4171 | Val Acc: 0.8512\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.2300 | Train Acc: 0.9136 | Val Loss: 0.4760 | Val Acc: 0.8441\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.2200 | Train Acc: 0.9169 | Val Loss: 0.4714 | Val Acc: 0.8485\n",
      "[Fold 2 | Epoch 35] Train Loss: 0.2222 | Train Acc: 0.9150 | Val Loss: 0.4908 | Val Acc: 0.8529\n",
      "[Fold 2 | Epoch 36] Train Loss: 0.2018 | Train Acc: 0.9246 | Val Loss: 0.4936 | Val Acc: 0.8558\n",
      "[Fold 2 | Epoch 37] Train Loss: 0.2026 | Train Acc: 0.9238 | Val Loss: 0.4765 | Val Acc: 0.8528\n",
      "[Fold 2 | Epoch 38] Train Loss: 0.2000 | Train Acc: 0.9240 | Val Loss: 0.4956 | Val Acc: 0.8358\n",
      "[Fold 2 | Epoch 39] Train Loss: 0.1877 | Train Acc: 0.9297 | Val Loss: 0.5982 | Val Acc: 0.8260\n",
      "[Fold 2 | Epoch 40] Train Loss: 0.1859 | Train Acc: 0.9292 | Val Loss: 0.5357 | Val Acc: 0.8368\n",
      "[Fold 2 | Epoch 41] Train Loss: 0.1753 | Train Acc: 0.9325 | Val Loss: 0.5345 | Val Acc: 0.8425\n",
      "[Fold 2 | Epoch 42] Train Loss: 0.1736 | Train Acc: 0.9351 | Val Loss: 0.6105 | Val Acc: 0.8545\n",
      "[Fold 2 | Epoch 43] Train Loss: 0.1680 | Train Acc: 0.9361 | Val Loss: 0.4930 | Val Acc: 0.8572\n",
      "[Fold 2 | Epoch 44] Train Loss: 0.1615 | Train Acc: 0.9402 | Val Loss: 0.5970 | Val Acc: 0.8479\n",
      "[Fold 2 | Epoch 45] Train Loss: 0.1563 | Train Acc: 0.9406 | Val Loss: 0.6633 | Val Acc: 0.8262\n",
      "[Early Stopping] No improvement in 15 epochs. Stopping at epoch 45.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 30\n",
      "ACC: 0.8649 | MF1: 0.7986 | G-Mean: 0.8549\n",
      "[Class 0] Prec: 0.9204 | Rec: 0.9211 | F1: 0.9208 | GM: 0.9504\n",
      "[Class 1] Prec: 0.5950 | Rec: 0.3395 | F1: 0.4323 | GM: 0.5776\n",
      "[Class 2] Prec: 0.8691 | Rec: 0.9289 | F1: 0.8980 | GM: 0.9136\n",
      "[Class 3] Prec: 0.9565 | Rec: 0.8738 | F1: 0.9133 | GM: 0.9322\n",
      "[Class 4] Prec: 0.8048 | Rec: 0.8535 | F1: 0.8284 | GM: 0.9009\n",
      "\n",
      "===== Fold 3 =====\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5530 | Train Acc: 0.7961 | Val Loss: 0.4446 | Val Acc: 0.8398\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4615 | Train Acc: 0.8286 | Val Loss: 0.4654 | Val Acc: 0.8202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3 | Epoch 3] Train Loss: 0.4437 | Train Acc: 0.8365 | Val Loss: 0.5133 | Val Acc: 0.8197\n",
      "[Fold 3 | Epoch 4] Train Loss: 0.4272 | Train Acc: 0.8433 | Val Loss: 0.5355 | Val Acc: 0.7956\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4211 | Train Acc: 0.8447 | Val Loss: 0.4847 | Val Acc: 0.8136\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4102 | Train Acc: 0.8495 | Val Loss: 0.4942 | Val Acc: 0.8232\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4065 | Train Acc: 0.8487 | Val Loss: 0.3988 | Val Acc: 0.8564\n",
      "[Fold 3 | Epoch 8] Train Loss: 0.3979 | Train Acc: 0.8542 | Val Loss: 0.4107 | Val Acc: 0.8459\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.3924 | Train Acc: 0.8573 | Val Loss: 0.4076 | Val Acc: 0.8482\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.3855 | Train Acc: 0.8572 | Val Loss: 0.3837 | Val Acc: 0.8535\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3828 | Train Acc: 0.8569 | Val Loss: 0.4953 | Val Acc: 0.8295\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3778 | Train Acc: 0.8584 | Val Loss: 0.3814 | Val Acc: 0.8558\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3699 | Train Acc: 0.8618 | Val Loss: 0.3734 | Val Acc: 0.8612\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3711 | Train Acc: 0.8615 | Val Loss: 0.4114 | Val Acc: 0.8465\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3658 | Train Acc: 0.8641 | Val Loss: 0.4032 | Val Acc: 0.8496\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3566 | Train Acc: 0.8653 | Val Loss: 0.4097 | Val Acc: 0.8498\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3531 | Train Acc: 0.8667 | Val Loss: 0.4216 | Val Acc: 0.8498\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3480 | Train Acc: 0.8689 | Val Loss: 0.3987 | Val Acc: 0.8551\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3426 | Train Acc: 0.8699 | Val Loss: 0.3951 | Val Acc: 0.8528\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.3357 | Train Acc: 0.8746 | Val Loss: 0.3854 | Val Acc: 0.8544\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.3339 | Train Acc: 0.8749 | Val Loss: 0.4012 | Val Acc: 0.8612\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.3186 | Train Acc: 0.8812 | Val Loss: 0.3931 | Val Acc: 0.8535\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.3149 | Train Acc: 0.8822 | Val Loss: 0.3806 | Val Acc: 0.8638\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.3104 | Train Acc: 0.8831 | Val Loss: 0.4177 | Val Acc: 0.8458\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.3009 | Train Acc: 0.8880 | Val Loss: 0.4054 | Val Acc: 0.8591\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.2961 | Train Acc: 0.8879 | Val Loss: 0.4552 | Val Acc: 0.8512\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.2875 | Train Acc: 0.8928 | Val Loss: 0.4629 | Val Acc: 0.8358\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.2783 | Train Acc: 0.8954 | Val Loss: 0.4122 | Val Acc: 0.8519\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.2703 | Train Acc: 0.8992 | Val Loss: 0.4633 | Val Acc: 0.8376\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.2615 | Train Acc: 0.9006 | Val Loss: 0.4464 | Val Acc: 0.8445\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.2681 | Train Acc: 0.8992 | Val Loss: 0.4711 | Val Acc: 0.8366\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.2475 | Train Acc: 0.9071 | Val Loss: 0.4228 | Val Acc: 0.8522\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.2465 | Train Acc: 0.9076 | Val Loss: 0.4420 | Val Acc: 0.8496\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.2315 | Train Acc: 0.9131 | Val Loss: 0.4298 | Val Acc: 0.8504\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.2224 | Train Acc: 0.9155 | Val Loss: 0.4913 | Val Acc: 0.8339\n",
      "[Fold 3 | Epoch 36] Train Loss: 0.2184 | Train Acc: 0.9157 | Val Loss: 0.4563 | Val Acc: 0.8585\n",
      "[Fold 3 | Epoch 37] Train Loss: 0.2107 | Train Acc: 0.9204 | Val Loss: 0.4598 | Val Acc: 0.8574\n",
      "[Fold 3 | Epoch 38] Train Loss: 0.2058 | Train Acc: 0.9220 | Val Loss: 0.5093 | Val Acc: 0.8482\n",
      "[Early Stopping] No improvement in 15 epochs. Stopping at epoch 38.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 23\n",
      "ACC: 0.8638 | MF1: 0.8024 | G-Mean: 0.8663\n",
      "[Class 0] Prec: 0.9261 | Rec: 0.9079 | F1: 0.9169 | GM: 0.9451\n",
      "[Class 1] Prec: 0.5289 | Rec: 0.3825 | F1: 0.4439 | GM: 0.6102\n",
      "[Class 2] Prec: 0.9108 | Rec: 0.9020 | F1: 0.9064 | GM: 0.9181\n",
      "[Class 3] Prec: 0.9309 | Rec: 0.9015 | F1: 0.9159 | GM: 0.9452\n",
      "[Class 4] Prec: 0.7732 | Rec: 0.8927 | F1: 0.8287 | GM: 0.9129\n",
      "\n",
      "===== Fold 4 =====\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5646 | Train Acc: 0.7924 | Val Loss: 0.6500 | Val Acc: 0.7692\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4654 | Train Acc: 0.8268 | Val Loss: 0.4858 | Val Acc: 0.8232\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4342 | Train Acc: 0.8390 | Val Loss: 0.5711 | Val Acc: 0.8027\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4249 | Train Acc: 0.8434 | Val Loss: 0.4164 | Val Acc: 0.8501\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4115 | Train Acc: 0.8483 | Val Loss: 0.4575 | Val Acc: 0.8363\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4054 | Train Acc: 0.8503 | Val Loss: 0.3865 | Val Acc: 0.8661\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.3976 | Train Acc: 0.8506 | Val Loss: 0.4541 | Val Acc: 0.8335\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.3951 | Train Acc: 0.8519 | Val Loss: 0.4570 | Val Acc: 0.8219\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.3892 | Train Acc: 0.8559 | Val Loss: 0.3925 | Val Acc: 0.8624\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.3808 | Train Acc: 0.8584 | Val Loss: 0.3905 | Val Acc: 0.8559\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.3760 | Train Acc: 0.8596 | Val Loss: 0.4273 | Val Acc: 0.8512\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3738 | Train Acc: 0.8618 | Val Loss: 0.4242 | Val Acc: 0.8494\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3664 | Train Acc: 0.8635 | Val Loss: 0.3927 | Val Acc: 0.8561\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3627 | Train Acc: 0.8649 | Val Loss: 0.4610 | Val Acc: 0.8375\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3551 | Train Acc: 0.8663 | Val Loss: 0.4112 | Val Acc: 0.8565\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3500 | Train Acc: 0.8687 | Val Loss: 0.3870 | Val Acc: 0.8488\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3410 | Train Acc: 0.8729 | Val Loss: 0.4060 | Val Acc: 0.8512\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3372 | Train Acc: 0.8743 | Val Loss: 0.4000 | Val Acc: 0.8557\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3277 | Train Acc: 0.8759 | Val Loss: 0.3998 | Val Acc: 0.8601\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3224 | Train Acc: 0.8797 | Val Loss: 0.3991 | Val Acc: 0.8565\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3196 | Train Acc: 0.8800 | Val Loss: 0.4107 | Val Acc: 0.8672\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.3113 | Train Acc: 0.8832 | Val Loss: 0.4740 | Val Acc: 0.8465\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.3025 | Train Acc: 0.8876 | Val Loss: 0.4030 | Val Acc: 0.8567\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.2988 | Train Acc: 0.8865 | Val Loss: 0.4162 | Val Acc: 0.8521\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.2918 | Train Acc: 0.8896 | Val Loss: 0.4347 | Val Acc: 0.8499\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.2814 | Train Acc: 0.8949 | Val Loss: 0.4258 | Val Acc: 0.8435\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.2674 | Train Acc: 0.8987 | Val Loss: 0.4745 | Val Acc: 0.8575\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.2648 | Train Acc: 0.8996 | Val Loss: 0.6560 | Val Acc: 0.7804\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.2582 | Train Acc: 0.9034 | Val Loss: 0.4560 | Val Acc: 0.8462\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.2513 | Train Acc: 0.9055 | Val Loss: 0.4467 | Val Acc: 0.8474\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.2415 | Train Acc: 0.9075 | Val Loss: 0.4974 | Val Acc: 0.8454\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.2369 | Train Acc: 0.9100 | Val Loss: 0.5210 | Val Acc: 0.8436\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.2297 | Train Acc: 0.9126 | Val Loss: 0.4983 | Val Acc: 0.8569\n",
      "[Fold 4 | Epoch 34] Train Loss: 0.2200 | Train Acc: 0.9165 | Val Loss: 0.5731 | Val Acc: 0.8454\n",
      "[Fold 4 | Epoch 35] Train Loss: 0.2095 | Train Acc: 0.9197 | Val Loss: 0.5086 | Val Acc: 0.8415\n",
      "[Fold 4 | Epoch 36] Train Loss: 0.2051 | Train Acc: 0.9241 | Val Loss: 0.5351 | Val Acc: 0.8431\n",
      "[Early Stopping] No improvement in 15 epochs. Stopping at epoch 36.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 21\n",
      "ACC: 0.8672 | MF1: 0.8035 | G-Mean: 0.8638\n",
      "[Class 0] Prec: 0.9268 | Rec: 0.9310 | F1: 0.9289 | GM: 0.9564\n",
      "[Class 1] Prec: 0.5916 | Rec: 0.3763 | F1: 0.4600 | GM: 0.6074\n",
      "[Class 2] Prec: 0.9008 | Rec: 0.9121 | F1: 0.9064 | GM: 0.9179\n",
      "[Class 3] Prec: 0.9560 | Rec: 0.8676 | F1: 0.9096 | GM: 0.9288\n",
      "[Class 4] Prec: 0.7536 | Rec: 0.8819 | F1: 0.8127 | GM: 0.9088\n",
      "\n",
      "===== Fold 5 =====\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.5555 | Train Acc: 0.7955 | Val Loss: 0.4649 | Val Acc: 0.8325\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4632 | Train Acc: 0.8296 | Val Loss: 0.4352 | Val Acc: 0.8422\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4421 | Train Acc: 0.8349 | Val Loss: 0.4154 | Val Acc: 0.8449\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4242 | Train Acc: 0.8415 | Val Loss: 0.4954 | Val Acc: 0.8243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 5] Train Loss: 0.4201 | Train Acc: 0.8459 | Val Loss: 0.4205 | Val Acc: 0.8539\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4103 | Train Acc: 0.8505 | Val Loss: 0.4824 | Val Acc: 0.8222\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.4045 | Train Acc: 0.8500 | Val Loss: 0.4481 | Val Acc: 0.8372\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.4010 | Train Acc: 0.8519 | Val Loss: 0.4000 | Val Acc: 0.8548\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.3925 | Train Acc: 0.8540 | Val Loss: 0.3935 | Val Acc: 0.8531\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.3847 | Train Acc: 0.8574 | Val Loss: 0.3780 | Val Acc: 0.8615\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.3790 | Train Acc: 0.8595 | Val Loss: 0.4379 | Val Acc: 0.8445\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3747 | Train Acc: 0.8623 | Val Loss: 0.3980 | Val Acc: 0.8502\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3697 | Train Acc: 0.8624 | Val Loss: 0.4387 | Val Acc: 0.8454\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3643 | Train Acc: 0.8662 | Val Loss: 0.4430 | Val Acc: 0.8359\n",
      "[Fold 5 | Epoch 15] Train Loss: 0.3574 | Train Acc: 0.8702 | Val Loss: 0.4096 | Val Acc: 0.8549\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3566 | Train Acc: 0.8676 | Val Loss: 0.3858 | Val Acc: 0.8601\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3479 | Train Acc: 0.8724 | Val Loss: 0.3940 | Val Acc: 0.8522\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3422 | Train Acc: 0.8717 | Val Loss: 0.4258 | Val Acc: 0.8383\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3407 | Train Acc: 0.8733 | Val Loss: 0.3768 | Val Acc: 0.8585\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3293 | Train Acc: 0.8770 | Val Loss: 0.3739 | Val Acc: 0.8651\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.3263 | Train Acc: 0.8772 | Val Loss: 0.4190 | Val Acc: 0.8426\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.3202 | Train Acc: 0.8805 | Val Loss: 0.4028 | Val Acc: 0.8526\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.3141 | Train Acc: 0.8800 | Val Loss: 0.4330 | Val Acc: 0.8565\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.3073 | Train Acc: 0.8826 | Val Loss: 0.4436 | Val Acc: 0.8409\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.2996 | Train Acc: 0.8865 | Val Loss: 0.4079 | Val Acc: 0.8672\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.2916 | Train Acc: 0.8906 | Val Loss: 0.4281 | Val Acc: 0.8484\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.2896 | Train Acc: 0.8939 | Val Loss: 0.3879 | Val Acc: 0.8671\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.2871 | Train Acc: 0.8901 | Val Loss: 0.4178 | Val Acc: 0.8604\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.2695 | Train Acc: 0.8990 | Val Loss: 0.5011 | Val Acc: 0.8411\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.2699 | Train Acc: 0.8999 | Val Loss: 0.4843 | Val Acc: 0.8276\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.2552 | Train Acc: 0.9029 | Val Loss: 0.4189 | Val Acc: 0.8594\n",
      "[Fold 5 | Epoch 32] Train Loss: 0.2483 | Train Acc: 0.9053 | Val Loss: 0.4476 | Val Acc: 0.8557\n",
      "[Fold 5 | Epoch 33] Train Loss: 0.2424 | Train Acc: 0.9081 | Val Loss: 0.5025 | Val Acc: 0.8395\n",
      "[Fold 5 | Epoch 34] Train Loss: 0.2401 | Train Acc: 0.9099 | Val Loss: 0.4325 | Val Acc: 0.8562\n",
      "[Fold 5 | Epoch 35] Train Loss: 0.2310 | Train Acc: 0.9117 | Val Loss: 0.4720 | Val Acc: 0.8454\n",
      "[Fold 5 | Epoch 36] Train Loss: 0.2222 | Train Acc: 0.9152 | Val Loss: 0.4537 | Val Acc: 0.8591\n",
      "[Fold 5 | Epoch 37] Train Loss: 0.2164 | Train Acc: 0.9188 | Val Loss: 0.4881 | Val Acc: 0.8539\n",
      "[Fold 5 | Epoch 38] Train Loss: 0.2103 | Train Acc: 0.9212 | Val Loss: 0.5238 | Val Acc: 0.8512\n",
      "[Fold 5 | Epoch 39] Train Loss: 0.2056 | Train Acc: 0.9224 | Val Loss: 0.4460 | Val Acc: 0.8641\n",
      "[Fold 5 | Epoch 40] Train Loss: 0.2000 | Train Acc: 0.9248 | Val Loss: 0.4928 | Val Acc: 0.8471\n",
      "[Early Stopping] No improvement in 15 epochs. Stopping at epoch 40.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 25\n",
      "ACC: 0.8672 | MF1: 0.8141 | G-Mean: 0.8796\n",
      "[Class 0] Prec: 0.9434 | Rec: 0.8880 | F1: 0.9149 | GM: 0.9367\n",
      "[Class 1] Prec: 0.5388 | Rec: 0.4748 | F1: 0.5048 | GM: 0.6783\n",
      "[Class 2] Prec: 0.9040 | Rec: 0.9085 | F1: 0.9063 | GM: 0.9174\n",
      "[Class 3] Prec: 0.8765 | Rec: 0.9544 | F1: 0.9138 | GM: 0.9677\n",
      "[Class 4] Prec: 0.8176 | Rec: 0.8440 | F1: 0.8306 | GM: 0.8981\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8652 | MF1: 0.8065 | G-Mean: 0.8691\n",
      "[Class 0] Prec: 0.9325 | Rec: 0.9065 | F1: 0.9193 | GM: 0.9449\n",
      "[Class 1] Prec: 0.5523 | Rec: 0.4133 | F1: 0.4728 | GM: 0.6345\n",
      "[Class 2] Prec: 0.8998 | Rec: 0.9106 | F1: 0.9052 | GM: 0.9173\n",
      "[Class 3] Prec: 0.9262 | Rec: 0.8961 | F1: 0.9109 | GM: 0.9419\n",
      "[Class 4] Prec: 0.7813 | Rec: 0.8723 | F1: 0.8243 | GM: 0.9068\n",
      "Confusion Matrix:\n",
      "[[ 5956   343   114     7   150]\n",
      " [  279  1035   465     4   721]\n",
      " [   68   228 13627   292   750]\n",
      " [    7     1   436  3830     0]\n",
      " [   77   267   502     2  5790]]\n"
     ]
    }
   ],
   "source": [
    "#9_1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from model_build import FinalNetwork\n",
    "\n",
    "# ==== Load and Normalize Data ====\n",
    "df = pd.read_csv(\"pruned_dataset.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "# Z-score normalization\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== Evaluation Metric Function ====\n",
    "def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    gmeans = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        tn = np.sum((y_pred != c) & (y_true != c))\n",
    "        fp = np.sum((y_pred == c) & (y_true != c))\n",
    "        gm = np.sqrt((tp / (tp + fn + 1e-6)) * (tn / (tn + fp + 1e-6)))\n",
    "        gmeans.append(gm)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, mf1, np.mean(gmeans), prec, rec, f1s, gmeans, cm\n",
    "\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=47)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "    X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "    X_val, y_val = X_all[val_idx], y_all[val_idx]\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "\n",
    "    model = FinalNetwork(C=8, num_classes=num_classes, layers=9, genotype=searched_genotype).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "    no_improve_counter = 0  # ← EARLY STOP counter\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] \"\n",
    "              f\"Train Loss: {train_loss/len(train_loader):.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            no_improve_counter = 0  # reset counter\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "        else:\n",
    "            no_improve_counter += 1\n",
    "            if no_improve_counter >= 15:\n",
    "                print(f\"[Early Stopping] No improvement in 15 epochs. Stopping at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e705d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5439 | Train Acc: 0.7987 | Val Loss: 0.4998 | Val Acc: 0.8218\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4643 | Train Acc: 0.8302 | Val Loss: 0.5252 | Val Acc: 0.8126\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4393 | Train Acc: 0.8381 | Val Loss: 0.7205 | Val Acc: 0.7468\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4313 | Train Acc: 0.8399 | Val Loss: 0.4062 | Val Acc: 0.8448\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4185 | Train Acc: 0.8452 | Val Loss: 0.4156 | Val Acc: 0.8409\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4128 | Train Acc: 0.8497 | Val Loss: 0.4137 | Val Acc: 0.8431\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.4080 | Train Acc: 0.8494 | Val Loss: 0.4199 | Val Acc: 0.8445\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.3996 | Train Acc: 0.8518 | Val Loss: 0.4026 | Val Acc: 0.8447\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.3957 | Train Acc: 0.8540 | Val Loss: 0.4579 | Val Acc: 0.8321\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.3884 | Train Acc: 0.8563 | Val Loss: 0.3907 | Val Acc: 0.8532\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3845 | Train Acc: 0.8572 | Val Loss: 0.3986 | Val Acc: 0.8532\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3814 | Train Acc: 0.8573 | Val Loss: 0.4060 | Val Acc: 0.8474\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3749 | Train Acc: 0.8609 | Val Loss: 0.4328 | Val Acc: 0.8368\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3700 | Train Acc: 0.8618 | Val Loss: 0.3848 | Val Acc: 0.8608\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3671 | Train Acc: 0.8633 | Val Loss: 0.4364 | Val Acc: 0.8329\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3616 | Train Acc: 0.8655 | Val Loss: 0.3691 | Val Acc: 0.8592\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3605 | Train Acc: 0.8664 | Val Loss: 0.4046 | Val Acc: 0.8472\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3500 | Train Acc: 0.8669 | Val Loss: 0.3954 | Val Acc: 0.8545\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3456 | Train Acc: 0.8697 | Val Loss: 0.3776 | Val Acc: 0.8607\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3429 | Train Acc: 0.8710 | Val Loss: 0.3819 | Val Acc: 0.8587\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3413 | Train Acc: 0.8698 | Val Loss: 0.4271 | Val Acc: 0.8358\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.3332 | Train Acc: 0.8755 | Val Loss: 0.4142 | Val Acc: 0.8451\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.3283 | Train Acc: 0.8756 | Val Loss: 0.4682 | Val Acc: 0.8389\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.3179 | Train Acc: 0.8813 | Val Loss: 0.5188 | Val Acc: 0.8262\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.3177 | Train Acc: 0.8792 | Val Loss: 0.4233 | Val Acc: 0.8477\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.3100 | Train Acc: 0.8809 | Val Loss: 0.3815 | Val Acc: 0.8574\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.3081 | Train Acc: 0.8849 | Val Loss: 0.4075 | Val Acc: 0.8518\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.2971 | Train Acc: 0.8872 | Val Loss: 0.4170 | Val Acc: 0.8504\n",
      "[Fold 1 | Epoch 29] Train Loss: 0.2907 | Train Acc: 0.8911 | Val Loss: 0.4204 | Val Acc: 0.8558\n",
      "[Early Stopping] No improvement in 15 epochs. Stopping at epoch 29.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 14\n",
      "ACC: 0.8608 | MF1: 0.7950 | G-Mean: 0.8552\n",
      "[Class 0] Prec: 0.9042 | Rec: 0.9319 | F1: 0.9179 | GM: 0.9543\n",
      "[Class 1] Prec: 0.5677 | Rec: 0.3738 | F1: 0.4508 | GM: 0.6043\n",
      "[Class 2] Prec: 0.8865 | Rec: 0.9311 | F1: 0.9083 | GM: 0.9206\n",
      "[Class 3] Prec: 0.9760 | Rec: 0.8000 | F1: 0.8793 | GM: 0.8932\n",
      "[Class 4] Prec: 0.7774 | Rec: 0.8649 | F1: 0.8188 | GM: 0.9036\n",
      "\n",
      "===== Fold 2 =====\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5641 | Train Acc: 0.7896 | Val Loss: 0.5975 | Val Acc: 0.7708\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4639 | Train Acc: 0.8304 | Val Loss: 0.4853 | Val Acc: 0.8362\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4456 | Train Acc: 0.8341 | Val Loss: 0.4392 | Val Acc: 0.8441\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4378 | Train Acc: 0.8391 | Val Loss: 0.4608 | Val Acc: 0.8368\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4265 | Train Acc: 0.8451 | Val Loss: 0.4034 | Val Acc: 0.8578\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4195 | Train Acc: 0.8449 | Val Loss: 0.5253 | Val Acc: 0.8142\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4117 | Train Acc: 0.8450 | Val Loss: 0.4440 | Val Acc: 0.8353\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.3958 | Train Acc: 0.8539 | Val Loss: 0.3866 | Val Acc: 0.8546\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.3989 | Train Acc: 0.8526 | Val Loss: 0.3992 | Val Acc: 0.8607\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.3932 | Train Acc: 0.8550 | Val Loss: 0.4046 | Val Acc: 0.8499\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3848 | Train Acc: 0.8578 | Val Loss: 0.3696 | Val Acc: 0.8599\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3815 | Train Acc: 0.8591 | Val Loss: 0.3665 | Val Acc: 0.8670\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3803 | Train Acc: 0.8574 | Val Loss: 0.3888 | Val Acc: 0.8572\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3720 | Train Acc: 0.8609 | Val Loss: 0.3883 | Val Acc: 0.8595\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3663 | Train Acc: 0.8647 | Val Loss: 0.3699 | Val Acc: 0.8629\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3610 | Train Acc: 0.8654 | Val Loss: 0.3825 | Val Acc: 0.8627\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3617 | Train Acc: 0.8656 | Val Loss: 0.3842 | Val Acc: 0.8555\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3561 | Train Acc: 0.8674 | Val Loss: 0.3598 | Val Acc: 0.8702\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3459 | Train Acc: 0.8714 | Val Loss: 0.3663 | Val Acc: 0.8725\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3442 | Train Acc: 0.8727 | Val Loss: 0.4222 | Val Acc: 0.8535\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3409 | Train Acc: 0.8725 | Val Loss: 0.4272 | Val Acc: 0.8506\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.3331 | Train Acc: 0.8745 | Val Loss: 0.4307 | Val Acc: 0.8445\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.3306 | Train Acc: 0.8749 | Val Loss: 0.3862 | Val Acc: 0.8588\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.3170 | Train Acc: 0.8812 | Val Loss: 0.4023 | Val Acc: 0.8549\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.3136 | Train Acc: 0.8834 | Val Loss: 0.3856 | Val Acc: 0.8651\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.3124 | Train Acc: 0.8828 | Val Loss: 0.3817 | Val Acc: 0.8617\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.3037 | Train Acc: 0.8853 | Val Loss: 0.4218 | Val Acc: 0.8499\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.2976 | Train Acc: 0.8863 | Val Loss: 0.4098 | Val Acc: 0.8581\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.2885 | Train Acc: 0.8914 | Val Loss: 0.3927 | Val Acc: 0.8627\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.2808 | Train Acc: 0.8955 | Val Loss: 0.4072 | Val Acc: 0.8601\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.2774 | Train Acc: 0.8961 | Val Loss: 0.4291 | Val Acc: 0.8648\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.2682 | Train Acc: 0.8991 | Val Loss: 0.4247 | Val Acc: 0.8584\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.2646 | Train Acc: 0.8994 | Val Loss: 0.4021 | Val Acc: 0.8645\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.2566 | Train Acc: 0.9011 | Val Loss: 0.4304 | Val Acc: 0.8642\n",
      "[Early Stopping] No improvement in 15 epochs. Stopping at epoch 34.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 19\n",
      "ACC: 0.8725 | MF1: 0.8177 | G-Mean: 0.8771\n",
      "[Class 0] Prec: 0.9404 | Rec: 0.9226 | F1: 0.9314 | GM: 0.9536\n",
      "[Class 1] Prec: 0.5751 | Rec: 0.4540 | F1: 0.5074 | GM: 0.6652\n",
      "[Class 2] Prec: 0.8914 | Rec: 0.9224 | F1: 0.9067 | GM: 0.9205\n",
      "[Class 3] Prec: 0.9084 | Rec: 0.9147 | F1: 0.9115 | GM: 0.9502\n",
      "[Class 4] Prec: 0.8249 | Rec: 0.8378 | F1: 0.8313 | GM: 0.8958\n",
      "\n",
      "===== Fold 3 =====\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5568 | Train Acc: 0.7904 | Val Loss: 0.7115 | Val Acc: 0.7668\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4774 | Train Acc: 0.8241 | Val Loss: 0.5822 | Val Acc: 0.7911\n",
      "[Fold 3 | Epoch 3] Train Loss: 0.4525 | Train Acc: 0.8344 | Val Loss: 0.4616 | Val Acc: 0.8302\n",
      "[Fold 3 | Epoch 4] Train Loss: 0.4311 | Train Acc: 0.8407 | Val Loss: 0.4011 | Val Acc: 0.8528\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4221 | Train Acc: 0.8439 | Val Loss: 0.6047 | Val Acc: 0.7946\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4151 | Train Acc: 0.8462 | Val Loss: 0.4556 | Val Acc: 0.8355\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4062 | Train Acc: 0.8493 | Val Loss: 0.4331 | Val Acc: 0.8426\n",
      "[Fold 3 | Epoch 8] Train Loss: 0.4020 | Train Acc: 0.8512 | Val Loss: 0.4067 | Val Acc: 0.8464\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.3969 | Train Acc: 0.8532 | Val Loss: 0.3870 | Val Acc: 0.8561\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.3906 | Train Acc: 0.8548 | Val Loss: 0.4261 | Val Acc: 0.8386\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3808 | Train Acc: 0.8593 | Val Loss: 0.4065 | Val Acc: 0.8535\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3810 | Train Acc: 0.8581 | Val Loss: 0.4143 | Val Acc: 0.8456\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3712 | Train Acc: 0.8609 | Val Loss: 0.3836 | Val Acc: 0.8592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3 | Epoch 14] Train Loss: 0.3681 | Train Acc: 0.8625 | Val Loss: 0.3858 | Val Acc: 0.8536\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3650 | Train Acc: 0.8639 | Val Loss: 0.3943 | Val Acc: 0.8529\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3631 | Train Acc: 0.8645 | Val Loss: 0.4019 | Val Acc: 0.8546\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3559 | Train Acc: 0.8669 | Val Loss: 0.4438 | Val Acc: 0.8358\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3539 | Train Acc: 0.8674 | Val Loss: 0.4523 | Val Acc: 0.8352\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3490 | Train Acc: 0.8679 | Val Loss: 0.4036 | Val Acc: 0.8605\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.3403 | Train Acc: 0.8695 | Val Loss: 0.4247 | Val Acc: 0.8482\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.3356 | Train Acc: 0.8749 | Val Loss: 0.4024 | Val Acc: 0.8552\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.3304 | Train Acc: 0.8746 | Val Loss: 0.4003 | Val Acc: 0.8478\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.3243 | Train Acc: 0.8792 | Val Loss: 0.5004 | Val Acc: 0.8315\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.3202 | Train Acc: 0.8788 | Val Loss: 0.4085 | Val Acc: 0.8526\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.3136 | Train Acc: 0.8814 | Val Loss: 0.3936 | Val Acc: 0.8607\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.3030 | Train Acc: 0.8844 | Val Loss: 0.4396 | Val Acc: 0.8406\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.2964 | Train Acc: 0.8873 | Val Loss: 0.4107 | Val Acc: 0.8484\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.2935 | Train Acc: 0.8910 | Val Loss: 0.4984 | Val Acc: 0.8263\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.2879 | Train Acc: 0.8896 | Val Loss: 0.4443 | Val Acc: 0.8305\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.2828 | Train Acc: 0.8922 | Val Loss: 0.4007 | Val Acc: 0.8559\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.2744 | Train Acc: 0.8962 | Val Loss: 0.4104 | Val Acc: 0.8541\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.2722 | Train Acc: 0.8985 | Val Loss: 0.4481 | Val Acc: 0.8378\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.2589 | Train Acc: 0.9029 | Val Loss: 0.5209 | Val Acc: 0.8352\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.2534 | Train Acc: 0.9048 | Val Loss: 0.4504 | Val Acc: 0.8405\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.2447 | Train Acc: 0.9075 | Val Loss: 0.5081 | Val Acc: 0.8312\n",
      "[Fold 3 | Epoch 36] Train Loss: 0.2397 | Train Acc: 0.9083 | Val Loss: 0.4531 | Val Acc: 0.8524\n",
      "[Fold 3 | Epoch 37] Train Loss: 0.2316 | Train Acc: 0.9132 | Val Loss: 0.4425 | Val Acc: 0.8561\n",
      "[Fold 3 | Epoch 38] Train Loss: 0.2302 | Train Acc: 0.9133 | Val Loss: 0.4491 | Val Acc: 0.8464\n",
      "[Fold 3 | Epoch 39] Train Loss: 0.2175 | Train Acc: 0.9168 | Val Loss: 0.4580 | Val Acc: 0.8494\n",
      "[Fold 3 | Epoch 40] Train Loss: 0.2128 | Train Acc: 0.9195 | Val Loss: 0.4656 | Val Acc: 0.8562\n",
      "[Early Stopping] No improvement in 15 epochs. Stopping at epoch 40.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 25\n",
      "ACC: 0.8607 | MF1: 0.8007 | G-Mean: 0.8612\n",
      "[Class 0] Prec: 0.9140 | Rec: 0.9118 | F1: 0.9129 | GM: 0.9457\n",
      "[Class 1] Prec: 0.5440 | Rec: 0.3944 | F1: 0.4573 | GM: 0.6199\n",
      "[Class 2] Prec: 0.8800 | Rec: 0.9235 | F1: 0.9012 | GM: 0.9149\n",
      "[Class 3] Prec: 0.9413 | Rec: 0.8771 | F1: 0.9081 | GM: 0.9331\n",
      "[Class 4] Prec: 0.8098 | Rec: 0.8384 | F1: 0.8239 | GM: 0.8924\n",
      "\n",
      "===== Fold 4 =====\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5553 | Train Acc: 0.7972 | Val Loss: 0.4728 | Val Acc: 0.8282\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4607 | Train Acc: 0.8337 | Val Loss: 0.4817 | Val Acc: 0.8246\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4365 | Train Acc: 0.8378 | Val Loss: 0.4674 | Val Acc: 0.8282\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4215 | Train Acc: 0.8424 | Val Loss: 0.4322 | Val Acc: 0.8443\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4155 | Train Acc: 0.8462 | Val Loss: 0.5789 | Val Acc: 0.7904\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4082 | Train Acc: 0.8483 | Val Loss: 0.4175 | Val Acc: 0.8504\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.4071 | Train Acc: 0.8511 | Val Loss: 0.4224 | Val Acc: 0.8491\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.3967 | Train Acc: 0.8521 | Val Loss: 0.4274 | Val Acc: 0.8428\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.3909 | Train Acc: 0.8541 | Val Loss: 0.4177 | Val Acc: 0.8498\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.3852 | Train Acc: 0.8562 | Val Loss: 0.4339 | Val Acc: 0.8361\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.3812 | Train Acc: 0.8584 | Val Loss: 0.4463 | Val Acc: 0.8361\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3741 | Train Acc: 0.8621 | Val Loss: 0.4175 | Val Acc: 0.8544\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3706 | Train Acc: 0.8603 | Val Loss: 0.4151 | Val Acc: 0.8488\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3654 | Train Acc: 0.8650 | Val Loss: 0.4037 | Val Acc: 0.8481\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3628 | Train Acc: 0.8646 | Val Loss: 0.4002 | Val Acc: 0.8611\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3568 | Train Acc: 0.8646 | Val Loss: 0.4002 | Val Acc: 0.8495\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3581 | Train Acc: 0.8648 | Val Loss: 0.4033 | Val Acc: 0.8587\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3510 | Train Acc: 0.8691 | Val Loss: 0.4155 | Val Acc: 0.8492\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3464 | Train Acc: 0.8697 | Val Loss: 0.3699 | Val Acc: 0.8645\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3420 | Train Acc: 0.8710 | Val Loss: 0.3740 | Val Acc: 0.8621\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3366 | Train Acc: 0.8724 | Val Loss: 0.3883 | Val Acc: 0.8642\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.3297 | Train Acc: 0.8745 | Val Loss: 0.4191 | Val Acc: 0.8449\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.3258 | Train Acc: 0.8765 | Val Loss: 0.3975 | Val Acc: 0.8525\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.3174 | Train Acc: 0.8812 | Val Loss: 0.3990 | Val Acc: 0.8607\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.3152 | Train Acc: 0.8813 | Val Loss: 0.3891 | Val Acc: 0.8615\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.3068 | Train Acc: 0.8836 | Val Loss: 0.4573 | Val Acc: 0.8446\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.3034 | Train Acc: 0.8861 | Val Loss: 0.4924 | Val Acc: 0.8226\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.2967 | Train Acc: 0.8881 | Val Loss: 0.4642 | Val Acc: 0.8474\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.2886 | Train Acc: 0.8901 | Val Loss: 0.3945 | Val Acc: 0.8652\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.2853 | Train Acc: 0.8910 | Val Loss: 0.4194 | Val Acc: 0.8521\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.2807 | Train Acc: 0.8935 | Val Loss: 0.4912 | Val Acc: 0.8359\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.2707 | Train Acc: 0.8980 | Val Loss: 0.4185 | Val Acc: 0.8567\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.2673 | Train Acc: 0.8986 | Val Loss: 0.4198 | Val Acc: 0.8535\n",
      "[Fold 4 | Epoch 34] Train Loss: 0.2566 | Train Acc: 0.9024 | Val Loss: 0.4435 | Val Acc: 0.8554\n",
      "[Fold 4 | Epoch 35] Train Loss: 0.2497 | Train Acc: 0.9049 | Val Loss: 0.4382 | Val Acc: 0.8599\n",
      "[Fold 4 | Epoch 36] Train Loss: 0.2447 | Train Acc: 0.9075 | Val Loss: 0.4946 | Val Acc: 0.8509\n",
      "[Fold 4 | Epoch 37] Train Loss: 0.2369 | Train Acc: 0.9106 | Val Loss: 0.4302 | Val Acc: 0.8632\n",
      "[Fold 4 | Epoch 38] Train Loss: 0.2309 | Train Acc: 0.9119 | Val Loss: 0.4782 | Val Acc: 0.8488\n",
      "[Fold 4 | Epoch 39] Train Loss: 0.2248 | Train Acc: 0.9147 | Val Loss: 0.5545 | Val Acc: 0.8273\n",
      "[Fold 4 | Epoch 40] Train Loss: 0.2180 | Train Acc: 0.9176 | Val Loss: 0.4665 | Val Acc: 0.8536\n",
      "[Fold 4 | Epoch 41] Train Loss: 0.2184 | Train Acc: 0.9183 | Val Loss: 0.4931 | Val Acc: 0.8431\n",
      "[Fold 4 | Epoch 42] Train Loss: 0.2053 | Train Acc: 0.9215 | Val Loss: 0.4750 | Val Acc: 0.8614\n",
      "[Fold 4 | Epoch 43] Train Loss: 0.2045 | Train Acc: 0.9217 | Val Loss: 0.4961 | Val Acc: 0.8451\n",
      "[Fold 4 | Epoch 44] Train Loss: 0.1915 | Train Acc: 0.9278 | Val Loss: 0.5062 | Val Acc: 0.8409\n",
      "[Early Stopping] No improvement in 15 epochs. Stopping at epoch 44.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 29\n",
      "ACC: 0.8652 | MF1: 0.8052 | G-Mean: 0.8698\n",
      "[Class 0] Prec: 0.9098 | Rec: 0.9362 | F1: 0.9228 | GM: 0.9568\n",
      "[Class 1] Prec: 0.5215 | Rec: 0.4213 | F1: 0.4661 | GM: 0.6395\n",
      "[Class 2] Prec: 0.8973 | Rec: 0.9098 | F1: 0.9035 | GM: 0.9154\n",
      "[Class 3] Prec: 0.9271 | Rec: 0.9144 | F1: 0.9207 | GM: 0.9513\n",
      "[Class 4] Prec: 0.8050 | Rec: 0.8209 | F1: 0.8129 | GM: 0.8860\n",
      "\n",
      "===== Fold 5 =====\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.5533 | Train Acc: 0.7945 | Val Loss: 0.4563 | Val Acc: 0.8342\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4713 | Train Acc: 0.8270 | Val Loss: 0.4610 | Val Acc: 0.8342\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4479 | Train Acc: 0.8334 | Val Loss: 0.5051 | Val Acc: 0.8190\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4319 | Train Acc: 0.8402 | Val Loss: 0.4112 | Val Acc: 0.8506\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4238 | Train Acc: 0.8425 | Val Loss: 0.5147 | Val Acc: 0.8169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 6] Train Loss: 0.4095 | Train Acc: 0.8478 | Val Loss: 0.4390 | Val Acc: 0.8280\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.4044 | Train Acc: 0.8518 | Val Loss: 0.4120 | Val Acc: 0.8488\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.4041 | Train Acc: 0.8492 | Val Loss: 0.3990 | Val Acc: 0.8587\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.3971 | Train Acc: 0.8527 | Val Loss: 0.3973 | Val Acc: 0.8512\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.3878 | Train Acc: 0.8556 | Val Loss: 0.3838 | Val Acc: 0.8599\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.3854 | Train Acc: 0.8570 | Val Loss: 0.4331 | Val Acc: 0.8368\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3786 | Train Acc: 0.8598 | Val Loss: 0.3990 | Val Acc: 0.8548\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3709 | Train Acc: 0.8611 | Val Loss: 0.3860 | Val Acc: 0.8534\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3754 | Train Acc: 0.8605 | Val Loss: 0.3991 | Val Acc: 0.8546\n",
      "[Fold 5 | Epoch 15] Train Loss: 0.3644 | Train Acc: 0.8648 | Val Loss: 0.4038 | Val Acc: 0.8516\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3620 | Train Acc: 0.8644 | Val Loss: 0.3966 | Val Acc: 0.8601\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3529 | Train Acc: 0.8682 | Val Loss: 0.3869 | Val Acc: 0.8582\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3523 | Train Acc: 0.8705 | Val Loss: 0.4079 | Val Acc: 0.8484\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3384 | Train Acc: 0.8711 | Val Loss: 0.4027 | Val Acc: 0.8514\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3435 | Train Acc: 0.8711 | Val Loss: 0.4018 | Val Acc: 0.8548\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.3328 | Train Acc: 0.8736 | Val Loss: 0.3819 | Val Acc: 0.8631\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.3251 | Train Acc: 0.8784 | Val Loss: 0.4278 | Val Acc: 0.8577\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.3189 | Train Acc: 0.8799 | Val Loss: 0.3781 | Val Acc: 0.8584\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.3083 | Train Acc: 0.8843 | Val Loss: 0.4313 | Val Acc: 0.8611\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.3127 | Train Acc: 0.8820 | Val Loss: 0.4182 | Val Acc: 0.8496\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.3012 | Train Acc: 0.8854 | Val Loss: 0.4100 | Val Acc: 0.8524\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.2985 | Train Acc: 0.8864 | Val Loss: 0.4168 | Val Acc: 0.8555\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.2860 | Train Acc: 0.8921 | Val Loss: 0.4020 | Val Acc: 0.8545\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.2848 | Train Acc: 0.8904 | Val Loss: 0.4181 | Val Acc: 0.8524\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.2807 | Train Acc: 0.8940 | Val Loss: 0.4652 | Val Acc: 0.8283\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.2706 | Train Acc: 0.8964 | Val Loss: 0.5814 | Val Acc: 0.8166\n",
      "[Fold 5 | Epoch 32] Train Loss: 0.2640 | Train Acc: 0.8988 | Val Loss: 0.4311 | Val Acc: 0.8658\n",
      "[Fold 5 | Epoch 33] Train Loss: 0.2542 | Train Acc: 0.9030 | Val Loss: 0.4342 | Val Acc: 0.8635\n",
      "[Fold 5 | Epoch 34] Train Loss: 0.2534 | Train Acc: 0.9050 | Val Loss: 0.4973 | Val Acc: 0.8422\n",
      "[Fold 5 | Epoch 35] Train Loss: 0.2388 | Train Acc: 0.9087 | Val Loss: 0.4944 | Val Acc: 0.8478\n",
      "[Fold 5 | Epoch 36] Train Loss: 0.2376 | Train Acc: 0.9104 | Val Loss: 0.5210 | Val Acc: 0.8336\n",
      "[Fold 5 | Epoch 37] Train Loss: 0.2238 | Train Acc: 0.9143 | Val Loss: 0.4384 | Val Acc: 0.8546\n",
      "[Fold 5 | Epoch 38] Train Loss: 0.2209 | Train Acc: 0.9170 | Val Loss: 0.4708 | Val Acc: 0.8525\n",
      "[Fold 5 | Epoch 39] Train Loss: 0.2153 | Train Acc: 0.9181 | Val Loss: 0.4676 | Val Acc: 0.8502\n",
      "[Fold 5 | Epoch 40] Train Loss: 0.2093 | Train Acc: 0.9198 | Val Loss: 0.4829 | Val Acc: 0.8579\n",
      "[Fold 5 | Epoch 41] Train Loss: 0.1992 | Train Acc: 0.9265 | Val Loss: 0.4846 | Val Acc: 0.8569\n",
      "[Fold 5 | Epoch 42] Train Loss: 0.1941 | Train Acc: 0.9254 | Val Loss: 0.5130 | Val Acc: 0.8598\n",
      "[Fold 5 | Epoch 43] Train Loss: 0.1948 | Train Acc: 0.9262 | Val Loss: 0.6244 | Val Acc: 0.8325\n",
      "[Fold 5 | Epoch 44] Train Loss: 0.1796 | Train Acc: 0.9309 | Val Loss: 0.5498 | Val Acc: 0.8441\n",
      "[Fold 5 | Epoch 45] Train Loss: 0.1752 | Train Acc: 0.9333 | Val Loss: 0.5388 | Val Acc: 0.8491\n",
      "[Fold 5 | Epoch 46] Train Loss: 0.1754 | Train Acc: 0.9328 | Val Loss: 0.5881 | Val Acc: 0.8569\n",
      "[Fold 5 | Epoch 47] Train Loss: 0.1718 | Train Acc: 0.9347 | Val Loss: 0.5251 | Val Acc: 0.8554\n",
      "[Early Stopping] No improvement in 15 epochs. Stopping at epoch 47.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 32\n",
      "ACC: 0.8658 | MF1: 0.7977 | G-Mean: 0.8564\n",
      "[Class 0] Prec: 0.8977 | Rec: 0.9209 | F1: 0.9092 | GM: 0.9483\n",
      "[Class 1] Prec: 0.5889 | Rec: 0.3400 | F1: 0.4311 | GM: 0.5778\n",
      "[Class 2] Prec: 0.8847 | Rec: 0.9300 | F1: 0.9068 | GM: 0.9186\n",
      "[Class 3] Prec: 0.9451 | Rec: 0.8854 | F1: 0.9143 | GM: 0.9376\n",
      "[Class 4] Prec: 0.8048 | Rec: 0.8507 | F1: 0.8271 | GM: 0.8996\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8650 | MF1: 0.8035 | G-Mean: 0.8641\n",
      "[Class 0] Prec: 0.9133 | Rec: 0.9248 | F1: 0.9190 | GM: 0.9518\n",
      "[Class 1] Prec: 0.5576 | Rec: 0.3962 | F1: 0.4632 | GM: 0.6217\n",
      "[Class 2] Prec: 0.8879 | Rec: 0.9234 | F1: 0.9053 | GM: 0.9180\n",
      "[Class 3] Prec: 0.9380 | Rec: 0.8783 | F1: 0.9072 | GM: 0.9334\n",
      "[Class 4] Prec: 0.8042 | Rec: 0.8426 | F1: 0.8229 | GM: 0.8956\n",
      "Confusion Matrix:\n",
      "[[ 6076   253   102     8   131]\n",
      " [  362   992   498     4   648]\n",
      " [  112   218 13818   235   582]\n",
      " [    9     1   509  3754     1]\n",
      " [   94   315   635     1  5593]]\n"
     ]
    }
   ],
   "source": [
    "#11_1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from model_build import FinalNetwork\n",
    "\n",
    "# ==== Load and Normalize Data ====\n",
    "df = pd.read_csv(\"pruned_dataset.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "# Z-score normalization\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== Evaluation Metric Function ====\n",
    "def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    gmeans = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        tn = np.sum((y_pred != c) & (y_true != c))\n",
    "        fp = np.sum((y_pred == c) & (y_true != c))\n",
    "        gm = np.sqrt((tp / (tp + fn + 1e-6)) * (tn / (tn + fp + 1e-6)))\n",
    "        gmeans.append(gm)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, mf1, np.mean(gmeans), prec, rec, f1s, gmeans, cm\n",
    "\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=47)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "    X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "    X_val, y_val = X_all[val_idx], y_all[val_idx]\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "\n",
    "    model = FinalNetwork(C=8, num_classes=num_classes, layers=11, genotype=searched_genotype).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "    no_improve_counter = 0  # ← EARLY STOP counter\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] \"\n",
    "              f\"Train Loss: {train_loss/len(train_loader):.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            no_improve_counter = 0  # reset counter\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "        else:\n",
    "            no_improve_counter += 1\n",
    "            if no_improve_counter >= 15:\n",
    "                print(f\"[Early Stopping] No improvement in 15 epochs. Stopping at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349050a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[INFO] Total parameters BEFORE pruning: 132,989\n",
      "[INFO] Non-zero parameters AFTER pruning: 66,977\n",
      "[INFO] Pruned parameters: 66,012 (49.64%)\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.6034 | Train Acc: 0.7771 | Val Loss: 0.5232 | Val Acc: 0.8186\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4830 | Train Acc: 0.8211 | Val Loss: 0.4411 | Val Acc: 0.8434\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4625 | Train Acc: 0.8298 | Val Loss: 0.5458 | Val Acc: 0.7970\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4490 | Train Acc: 0.8327 | Val Loss: 0.5270 | Val Acc: 0.8130\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4343 | Train Acc: 0.8394 | Val Loss: 0.4235 | Val Acc: 0.8425\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4269 | Train Acc: 0.8433 | Val Loss: 0.5290 | Val Acc: 0.8344\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.4248 | Train Acc: 0.8425 | Val Loss: 0.4528 | Val Acc: 0.8284\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.4094 | Train Acc: 0.8480 | Val Loss: 0.3933 | Val Acc: 0.8591\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.4091 | Train Acc: 0.8494 | Val Loss: 0.5185 | Val Acc: 0.8248\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.4046 | Train Acc: 0.8492 | Val Loss: 0.3918 | Val Acc: 0.8614\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3984 | Train Acc: 0.8519 | Val Loss: 0.4266 | Val Acc: 0.8414\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3939 | Train Acc: 0.8536 | Val Loss: 0.4356 | Val Acc: 0.8452\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3902 | Train Acc: 0.8553 | Val Loss: 0.4031 | Val Acc: 0.8494\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3905 | Train Acc: 0.8565 | Val Loss: 0.3969 | Val Acc: 0.8510\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3821 | Train Acc: 0.8579 | Val Loss: 0.4219 | Val Acc: 0.8462\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3787 | Train Acc: 0.8588 | Val Loss: 0.3895 | Val Acc: 0.8604\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3739 | Train Acc: 0.8592 | Val Loss: 0.4248 | Val Acc: 0.8499\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3703 | Train Acc: 0.8626 | Val Loss: 0.3911 | Val Acc: 0.8524\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3650 | Train Acc: 0.8636 | Val Loss: 0.3938 | Val Acc: 0.8562\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3646 | Train Acc: 0.8628 | Val Loss: 0.4148 | Val Acc: 0.8517\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3618 | Train Acc: 0.8648 | Val Loss: 0.3774 | Val Acc: 0.8613\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.3531 | Train Acc: 0.8676 | Val Loss: 0.4012 | Val Acc: 0.8487\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.3536 | Train Acc: 0.8676 | Val Loss: 0.3884 | Val Acc: 0.8627\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.3492 | Train Acc: 0.8671 | Val Loss: 0.4133 | Val Acc: 0.8455\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.3484 | Train Acc: 0.8689 | Val Loss: 0.3926 | Val Acc: 0.8538\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.3419 | Train Acc: 0.8730 | Val Loss: 0.4132 | Val Acc: 0.8511\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.3367 | Train Acc: 0.8725 | Val Loss: 0.3993 | Val Acc: 0.8551\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.3372 | Train Acc: 0.8729 | Val Loss: 0.3826 | Val Acc: 0.8582\n",
      "[Fold 1 | Epoch 29] Train Loss: 0.3261 | Train Acc: 0.8781 | Val Loss: 0.3943 | Val Acc: 0.8645\n",
      "[Fold 1 | Epoch 30] Train Loss: 0.3220 | Train Acc: 0.8767 | Val Loss: 0.3936 | Val Acc: 0.8580\n",
      "[Fold 1 | Epoch 31] Train Loss: 0.3172 | Train Acc: 0.8786 | Val Loss: 0.3814 | Val Acc: 0.8641\n",
      "[Fold 1 | Epoch 32] Train Loss: 0.3152 | Train Acc: 0.8808 | Val Loss: 0.4570 | Val Acc: 0.8422\n",
      "[Fold 1 | Epoch 33] Train Loss: 0.3118 | Train Acc: 0.8839 | Val Loss: 0.4488 | Val Acc: 0.8301\n",
      "[Fold 1 | Epoch 34] Train Loss: 0.3021 | Train Acc: 0.8856 | Val Loss: 0.3839 | Val Acc: 0.8614\n",
      "[Fold 1 | Epoch 35] Train Loss: 0.2998 | Train Acc: 0.8878 | Val Loss: 0.4447 | Val Acc: 0.8474\n",
      "[Fold 1 | Epoch 36] Train Loss: 0.2950 | Train Acc: 0.8883 | Val Loss: 0.4543 | Val Acc: 0.8467\n",
      "[Fold 1 | Epoch 37] Train Loss: 0.2913 | Train Acc: 0.8904 | Val Loss: 0.4716 | Val Acc: 0.8485\n",
      "[Fold 1 | Epoch 38] Train Loss: 0.2879 | Train Acc: 0.8915 | Val Loss: 0.4125 | Val Acc: 0.8485\n",
      "[Fold 1 | Epoch 39] Train Loss: 0.2827 | Train Acc: 0.8923 | Val Loss: 0.4642 | Val Acc: 0.8419\n",
      "[Fold 1 | Epoch 40] Train Loss: 0.2822 | Train Acc: 0.8908 | Val Loss: 0.4412 | Val Acc: 0.8494\n",
      "[Fold 1 | Epoch 41] Train Loss: 0.2716 | Train Acc: 0.8982 | Val Loss: 0.4510 | Val Acc: 0.8565\n",
      "[Fold 1 | Epoch 42] Train Loss: 0.2726 | Train Acc: 0.8968 | Val Loss: 0.4600 | Val Acc: 0.8392\n",
      "[Fold 1 | Epoch 43] Train Loss: 0.2612 | Train Acc: 0.9015 | Val Loss: 0.4194 | Val Acc: 0.8608\n",
      "[Fold 1 | Epoch 44] Train Loss: 0.2591 | Train Acc: 0.9022 | Val Loss: 0.4221 | Val Acc: 0.8537\n",
      "[Early Stopping] No improvement in 15 consecutive epochs. Stopping at epoch 44.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 29\n",
      "ACC: 0.8645 | MF1: 0.8013 | G-Mean: 0.8602\n",
      "[Class 0] Prec: 0.9435 | Rec: 0.8931 | F1: 0.9176 | GM: 0.9391\n",
      "[Class 1] Prec: 0.5621 | Rec: 0.3724 | F1: 0.4480 | GM: 0.6036\n",
      "[Class 2] Prec: 0.8843 | Rec: 0.9261 | F1: 0.9047 | GM: 0.9180\n",
      "[Class 3] Prec: 0.9505 | Rec: 0.8874 | F1: 0.9179 | GM: 0.9390\n",
      "[Class 4] Prec: 0.7774 | Rec: 0.8635 | F1: 0.8182 | GM: 0.9012\n",
      "\n",
      "===== Fold 2 =====\n",
      "[INFO] Total parameters BEFORE pruning: 132,989\n",
      "[INFO] Non-zero parameters AFTER pruning: 66,977\n",
      "[INFO] Pruned parameters: 66,012 (49.64%)\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5860 | Train Acc: 0.7808 | Val Loss: 0.6999 | Val Acc: 0.7588\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4783 | Train Acc: 0.8238 | Val Loss: 0.6482 | Val Acc: 0.7718\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4580 | Train Acc: 0.8309 | Val Loss: 0.5778 | Val Acc: 0.7720\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4501 | Train Acc: 0.8342 | Val Loss: 0.4210 | Val Acc: 0.8443\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4332 | Train Acc: 0.8413 | Val Loss: 0.4124 | Val Acc: 0.8524\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4276 | Train Acc: 0.8427 | Val Loss: 0.4497 | Val Acc: 0.8345\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4239 | Train Acc: 0.8438 | Val Loss: 0.4347 | Val Acc: 0.8329\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.4204 | Train Acc: 0.8447 | Val Loss: 0.4332 | Val Acc: 0.8405\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.4056 | Train Acc: 0.8497 | Val Loss: 0.4712 | Val Acc: 0.8233\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.4019 | Train Acc: 0.8527 | Val Loss: 0.3974 | Val Acc: 0.8594\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.4035 | Train Acc: 0.8510 | Val Loss: 0.4371 | Val Acc: 0.8345\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3944 | Train Acc: 0.8535 | Val Loss: 0.5077 | Val Acc: 0.8166\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3914 | Train Acc: 0.8558 | Val Loss: 0.4285 | Val Acc: 0.8369\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3866 | Train Acc: 0.8562 | Val Loss: 0.4183 | Val Acc: 0.8494\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3790 | Train Acc: 0.8611 | Val Loss: 0.4182 | Val Acc: 0.8482\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3849 | Train Acc: 0.8569 | Val Loss: 0.4119 | Val Acc: 0.8492\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3791 | Train Acc: 0.8590 | Val Loss: 0.3794 | Val Acc: 0.8624\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3732 | Train Acc: 0.8613 | Val Loss: 0.4107 | Val Acc: 0.8479\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3755 | Train Acc: 0.8613 | Val Loss: 0.4068 | Val Acc: 0.8548\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3709 | Train Acc: 0.8629 | Val Loss: 0.3995 | Val Acc: 0.8475\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3630 | Train Acc: 0.8657 | Val Loss: 0.5777 | Val Acc: 0.7844\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.3621 | Train Acc: 0.8665 | Val Loss: 0.3904 | Val Acc: 0.8555\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.3611 | Train Acc: 0.8670 | Val Loss: 0.4278 | Val Acc: 0.8516\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.3580 | Train Acc: 0.8667 | Val Loss: 0.3912 | Val Acc: 0.8509\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.3533 | Train Acc: 0.8690 | Val Loss: 0.4020 | Val Acc: 0.8506\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.3466 | Train Acc: 0.8690 | Val Loss: 0.4649 | Val Acc: 0.8292\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.3431 | Train Acc: 0.8731 | Val Loss: 0.4134 | Val Acc: 0.8562\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.3436 | Train Acc: 0.8712 | Val Loss: 0.3902 | Val Acc: 0.8559\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.3363 | Train Acc: 0.8738 | Val Loss: 0.4389 | Val Acc: 0.8396\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.3317 | Train Acc: 0.8769 | Val Loss: 0.4573 | Val Acc: 0.8353\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.3306 | Train Acc: 0.8759 | Val Loss: 0.4733 | Val Acc: 0.8170\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.3243 | Train Acc: 0.8783 | Val Loss: 0.4030 | Val Acc: 0.8542\n",
      "[Early Stopping] No improvement in 15 consecutive epochs. Stopping at epoch 32.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 17\n",
      "ACC: 0.8624 | MF1: 0.7984 | G-Mean: 0.8603\n",
      "[Class 0] Prec: 0.9205 | Rec: 0.9013 | F1: 0.9108 | GM: 0.9409\n",
      "[Class 1] Prec: 0.5710 | Rec: 0.3563 | F1: 0.4388 | GM: 0.5906\n",
      "[Class 2] Prec: 0.8858 | Rec: 0.9190 | F1: 0.9021 | GM: 0.9159\n",
      "[Class 3] Prec: 0.9129 | Rec: 0.9324 | F1: 0.9226 | GM: 0.9594\n",
      "[Class 4] Prec: 0.7927 | Rec: 0.8449 | F1: 0.8180 | GM: 0.8949\n",
      "\n",
      "===== Fold 3 =====\n",
      "[INFO] Total parameters BEFORE pruning: 132,989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Non-zero parameters AFTER pruning: 66,977\n",
      "[INFO] Pruned parameters: 66,012 (49.64%)\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5860 | Train Acc: 0.7832 | Val Loss: 0.6524 | Val Acc: 0.7549\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4786 | Train Acc: 0.8223 | Val Loss: 0.4644 | Val Acc: 0.8217\n",
      "[Fold 3 | Epoch 3] Train Loss: 0.4556 | Train Acc: 0.8335 | Val Loss: 0.4725 | Val Acc: 0.8283\n",
      "[Fold 3 | Epoch 4] Train Loss: 0.4422 | Train Acc: 0.8368 | Val Loss: 0.5546 | Val Acc: 0.7970\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4360 | Train Acc: 0.8388 | Val Loss: 0.4530 | Val Acc: 0.8319\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4253 | Train Acc: 0.8428 | Val Loss: 0.4581 | Val Acc: 0.8272\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4172 | Train Acc: 0.8459 | Val Loss: 0.4062 | Val Acc: 0.8489\n",
      "[Fold 3 | Epoch 8] Train Loss: 0.4124 | Train Acc: 0.8454 | Val Loss: 0.4092 | Val Acc: 0.8485\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.4075 | Train Acc: 0.8477 | Val Loss: 0.3924 | Val Acc: 0.8548\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.4061 | Train Acc: 0.8491 | Val Loss: 0.4078 | Val Acc: 0.8554\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3977 | Train Acc: 0.8522 | Val Loss: 0.4533 | Val Acc: 0.8290\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3958 | Train Acc: 0.8521 | Val Loss: 0.4205 | Val Acc: 0.8468\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3938 | Train Acc: 0.8528 | Val Loss: 0.4024 | Val Acc: 0.8535\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3879 | Train Acc: 0.8561 | Val Loss: 0.5779 | Val Acc: 0.7903\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3840 | Train Acc: 0.8574 | Val Loss: 0.4093 | Val Acc: 0.8518\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3785 | Train Acc: 0.8588 | Val Loss: 0.4839 | Val Acc: 0.8269\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3819 | Train Acc: 0.8564 | Val Loss: 0.4444 | Val Acc: 0.8508\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3754 | Train Acc: 0.8594 | Val Loss: 0.4371 | Val Acc: 0.8408\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3691 | Train Acc: 0.8637 | Val Loss: 0.4342 | Val Acc: 0.8385\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.3661 | Train Acc: 0.8637 | Val Loss: 0.4148 | Val Acc: 0.8418\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.3619 | Train Acc: 0.8640 | Val Loss: 0.3968 | Val Acc: 0.8541\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.3583 | Train Acc: 0.8655 | Val Loss: 0.3968 | Val Acc: 0.8538\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.3595 | Train Acc: 0.8665 | Val Loss: 0.4324 | Val Acc: 0.8419\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.3530 | Train Acc: 0.8683 | Val Loss: 0.3861 | Val Acc: 0.8571\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.3498 | Train Acc: 0.8696 | Val Loss: 0.3886 | Val Acc: 0.8549\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.3435 | Train Acc: 0.8718 | Val Loss: 0.4028 | Val Acc: 0.8519\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.3412 | Train Acc: 0.8726 | Val Loss: 0.3842 | Val Acc: 0.8536\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.3337 | Train Acc: 0.8731 | Val Loss: 0.3994 | Val Acc: 0.8601\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.3290 | Train Acc: 0.8761 | Val Loss: 0.4131 | Val Acc: 0.8452\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.3288 | Train Acc: 0.8764 | Val Loss: 0.3928 | Val Acc: 0.8532\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.3209 | Train Acc: 0.8779 | Val Loss: 0.4265 | Val Acc: 0.8504\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.3167 | Train Acc: 0.8807 | Val Loss: 0.4208 | Val Acc: 0.8518\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.3128 | Train Acc: 0.8815 | Val Loss: 0.4740 | Val Acc: 0.8378\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.3063 | Train Acc: 0.8845 | Val Loss: 0.4144 | Val Acc: 0.8516\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.3020 | Train Acc: 0.8871 | Val Loss: 0.4143 | Val Acc: 0.8559\n",
      "[Fold 3 | Epoch 36] Train Loss: 0.3008 | Train Acc: 0.8873 | Val Loss: 0.4155 | Val Acc: 0.8525\n",
      "[Fold 3 | Epoch 37] Train Loss: 0.2975 | Train Acc: 0.8875 | Val Loss: 0.4327 | Val Acc: 0.8522\n",
      "[Fold 3 | Epoch 38] Train Loss: 0.2907 | Train Acc: 0.8894 | Val Loss: 0.4211 | Val Acc: 0.8466\n",
      "[Fold 3 | Epoch 39] Train Loss: 0.2861 | Train Acc: 0.8912 | Val Loss: 0.4382 | Val Acc: 0.8552\n",
      "[Fold 3 | Epoch 40] Train Loss: 0.2768 | Train Acc: 0.8939 | Val Loss: 0.4445 | Val Acc: 0.8562\n",
      "[Fold 3 | Epoch 41] Train Loss: 0.2783 | Train Acc: 0.8958 | Val Loss: 0.4468 | Val Acc: 0.8469\n",
      "[Fold 3 | Epoch 42] Train Loss: 0.2686 | Train Acc: 0.8980 | Val Loss: 0.4593 | Val Acc: 0.8538\n",
      "[Fold 3 | Epoch 43] Train Loss: 0.2695 | Train Acc: 0.8987 | Val Loss: 0.4472 | Val Acc: 0.8504\n",
      "[Early Stopping] No improvement in 15 consecutive epochs. Stopping at epoch 43.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 28\n",
      "ACC: 0.8601 | MF1: 0.7979 | G-Mean: 0.8606\n",
      "[Class 0] Prec: 0.9093 | Rec: 0.9245 | F1: 0.9169 | GM: 0.9512\n",
      "[Class 1] Prec: 0.5962 | Rec: 0.3691 | F1: 0.4560 | GM: 0.6015\n",
      "[Class 2] Prec: 0.8796 | Rec: 0.9160 | F1: 0.8974 | GM: 0.9109\n",
      "[Class 3] Prec: 0.8756 | Rec: 0.9268 | F1: 0.9005 | GM: 0.9543\n",
      "[Class 4] Prec: 0.8182 | Rec: 0.8189 | F1: 0.8186 | GM: 0.8850\n",
      "\n",
      "===== Fold 4 =====\n",
      "[INFO] Total parameters BEFORE pruning: 132,989\n",
      "[INFO] Non-zero parameters AFTER pruning: 66,977\n",
      "[INFO] Pruned parameters: 66,012 (49.64%)\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.6025 | Train Acc: 0.7733 | Val Loss: 0.5996 | Val Acc: 0.7718\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4797 | Train Acc: 0.8228 | Val Loss: 0.4497 | Val Acc: 0.8399\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4596 | Train Acc: 0.8311 | Val Loss: 0.5520 | Val Acc: 0.7931\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4471 | Train Acc: 0.8367 | Val Loss: 0.6493 | Val Acc: 0.7731\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4352 | Train Acc: 0.8392 | Val Loss: 0.5096 | Val Acc: 0.8242\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4297 | Train Acc: 0.8412 | Val Loss: 0.5188 | Val Acc: 0.8117\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.4200 | Train Acc: 0.8448 | Val Loss: 0.4964 | Val Acc: 0.8382\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.4184 | Train Acc: 0.8455 | Val Loss: 0.4737 | Val Acc: 0.8203\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.4057 | Train Acc: 0.8494 | Val Loss: 0.4405 | Val Acc: 0.8395\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.4092 | Train Acc: 0.8482 | Val Loss: 0.4304 | Val Acc: 0.8494\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.4017 | Train Acc: 0.8501 | Val Loss: 0.4148 | Val Acc: 0.8423\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3949 | Train Acc: 0.8532 | Val Loss: 0.4173 | Val Acc: 0.8452\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3945 | Train Acc: 0.8547 | Val Loss: 0.4246 | Val Acc: 0.8454\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3851 | Train Acc: 0.8573 | Val Loss: 0.4152 | Val Acc: 0.8522\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3878 | Train Acc: 0.8555 | Val Loss: 0.4470 | Val Acc: 0.8326\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3840 | Train Acc: 0.8572 | Val Loss: 0.3876 | Val Acc: 0.8587\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3759 | Train Acc: 0.8620 | Val Loss: 0.3878 | Val Acc: 0.8584\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3752 | Train Acc: 0.8610 | Val Loss: 0.3756 | Val Acc: 0.8651\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3731 | Train Acc: 0.8612 | Val Loss: 0.4112 | Val Acc: 0.8469\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3681 | Train Acc: 0.8640 | Val Loss: 0.3727 | Val Acc: 0.8622\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3668 | Train Acc: 0.8627 | Val Loss: 0.3988 | Val Acc: 0.8575\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.3576 | Train Acc: 0.8680 | Val Loss: 0.4010 | Val Acc: 0.8551\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.3571 | Train Acc: 0.8679 | Val Loss: 0.4085 | Val Acc: 0.8557\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.3532 | Train Acc: 0.8674 | Val Loss: 0.4177 | Val Acc: 0.8402\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.3465 | Train Acc: 0.8716 | Val Loss: 0.4229 | Val Acc: 0.8498\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.3458 | Train Acc: 0.8714 | Val Loss: 0.3989 | Val Acc: 0.8505\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.3420 | Train Acc: 0.8705 | Val Loss: 0.4145 | Val Acc: 0.8486\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.3376 | Train Acc: 0.8718 | Val Loss: 0.4293 | Val Acc: 0.8545\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.3305 | Train Acc: 0.8755 | Val Loss: 0.3900 | Val Acc: 0.8568\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.3281 | Train Acc: 0.8787 | Val Loss: 0.3891 | Val Acc: 0.8591\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.3284 | Train Acc: 0.8780 | Val Loss: 0.4601 | Val Acc: 0.8293\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.3230 | Train Acc: 0.8785 | Val Loss: 0.4254 | Val Acc: 0.8506\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.3177 | Train Acc: 0.8809 | Val Loss: 0.4374 | Val Acc: 0.8496\n",
      "[Early Stopping] No improvement in 15 consecutive epochs. Stopping at epoch 33.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 18\n",
      "ACC: 0.8651 | MF1: 0.8093 | G-Mean: 0.8745\n",
      "[Class 0] Prec: 0.9272 | Rec: 0.9074 | F1: 0.9172 | GM: 0.9447\n",
      "[Class 1] Prec: 0.4875 | Rec: 0.4865 | F1: 0.4870 | GM: 0.6842\n",
      "[Class 2] Prec: 0.8944 | Rec: 0.9219 | F1: 0.9079 | GM: 0.9195\n",
      "[Class 3] Prec: 0.9429 | Rec: 0.8949 | F1: 0.9183 | GM: 0.9423\n",
      "[Class 4] Prec: 0.8222 | Rec: 0.8102 | F1: 0.8162 | GM: 0.8820\n",
      "\n",
      "===== Fold 5 =====\n",
      "[INFO] Total parameters BEFORE pruning: 132,989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Non-zero parameters AFTER pruning: 66,977\n",
      "[INFO] Pruned parameters: 66,012 (49.64%)\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.6023 | Train Acc: 0.7786 | Val Loss: 0.6064 | Val Acc: 0.7884\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4865 | Train Acc: 0.8216 | Val Loss: 0.4873 | Val Acc: 0.8235\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4615 | Train Acc: 0.8316 | Val Loss: 0.4647 | Val Acc: 0.8270\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4465 | Train Acc: 0.8375 | Val Loss: 0.4419 | Val Acc: 0.8343\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4417 | Train Acc: 0.8369 | Val Loss: 0.4422 | Val Acc: 0.8332\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4270 | Train Acc: 0.8444 | Val Loss: 0.4549 | Val Acc: 0.8316\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.4212 | Train Acc: 0.8429 | Val Loss: 0.4037 | Val Acc: 0.8492\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.4188 | Train Acc: 0.8474 | Val Loss: 0.4215 | Val Acc: 0.8402\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.4174 | Train Acc: 0.8485 | Val Loss: 0.4080 | Val Acc: 0.8485\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.4072 | Train Acc: 0.8497 | Val Loss: 0.3816 | Val Acc: 0.8594\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.4089 | Train Acc: 0.8481 | Val Loss: 0.4371 | Val Acc: 0.8305\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.4025 | Train Acc: 0.8524 | Val Loss: 0.4032 | Val Acc: 0.8514\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3932 | Train Acc: 0.8560 | Val Loss: 0.3902 | Val Acc: 0.8496\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3914 | Train Acc: 0.8544 | Val Loss: 0.3649 | Val Acc: 0.8651\n",
      "[Fold 5 | Epoch 15] Train Loss: 0.3865 | Train Acc: 0.8569 | Val Loss: 0.3926 | Val Acc: 0.8511\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3864 | Train Acc: 0.8577 | Val Loss: 0.3856 | Val Acc: 0.8508\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3814 | Train Acc: 0.8582 | Val Loss: 0.3823 | Val Acc: 0.8605\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3736 | Train Acc: 0.8625 | Val Loss: 0.4013 | Val Acc: 0.8466\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3726 | Train Acc: 0.8618 | Val Loss: 0.4019 | Val Acc: 0.8452\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3667 | Train Acc: 0.8636 | Val Loss: 0.4631 | Val Acc: 0.8292\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.3651 | Train Acc: 0.8648 | Val Loss: 0.4189 | Val Acc: 0.8423\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.3603 | Train Acc: 0.8668 | Val Loss: 0.3841 | Val Acc: 0.8597\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.3583 | Train Acc: 0.8663 | Val Loss: 0.3592 | Val Acc: 0.8622\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.3538 | Train Acc: 0.8672 | Val Loss: 0.3631 | Val Acc: 0.8595\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.3532 | Train Acc: 0.8677 | Val Loss: 0.3693 | Val Acc: 0.8597\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.3444 | Train Acc: 0.8716 | Val Loss: 0.4060 | Val Acc: 0.8501\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.3413 | Train Acc: 0.8726 | Val Loss: 0.3857 | Val Acc: 0.8607\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.3394 | Train Acc: 0.8732 | Val Loss: 0.3884 | Val Acc: 0.8538\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.3302 | Train Acc: 0.8768 | Val Loss: 0.4006 | Val Acc: 0.8531\n",
      "[Early Stopping] No improvement in 15 consecutive epochs. Stopping at epoch 29.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 14\n",
      "ACC: 0.8651 | MF1: 0.7947 | G-Mean: 0.8571\n",
      "[Class 0] Prec: 0.9173 | Rec: 0.9367 | F1: 0.9269 | GM: 0.9582\n",
      "[Class 1] Prec: 0.5131 | Rec: 0.3404 | F1: 0.4093 | GM: 0.5759\n",
      "[Class 2] Prec: 0.8973 | Rec: 0.9274 | F1: 0.9121 | GM: 0.9237\n",
      "[Class 3] Prec: 0.9503 | Rec: 0.8674 | F1: 0.9069 | GM: 0.9285\n",
      "[Class 4] Prec: 0.7843 | Rec: 0.8552 | F1: 0.8182 | GM: 0.8994\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8634 | MF1: 0.8006 | G-Mean: 0.8627\n",
      "[Class 0] Prec: 0.9233 | Rec: 0.9126 | F1: 0.9179 | GM: 0.9469\n",
      "[Class 1] Prec: 0.5402 | Rec: 0.3838 | F1: 0.4488 | GM: 0.6116\n",
      "[Class 2] Prec: 0.8883 | Rec: 0.9221 | F1: 0.9049 | GM: 0.9176\n",
      "[Class 3] Prec: 0.9251 | Rec: 0.9020 | F1: 0.9134 | GM: 0.9449\n",
      "[Class 4] Prec: 0.7980 | Rec: 0.8387 | F1: 0.8178 | GM: 0.8927\n",
      "Confusion Matrix:\n",
      "[[ 5996   312   134    11   117]\n",
      " [  333   961   508     4   698]\n",
      " [   78   199 13799   295   594]\n",
      " [    4     0   415  3855     0]\n",
      " [   83   307   679     2  5567]]\n"
     ]
    }
   ],
   "source": [
    "#p11_2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ==== Load and Normalize Data ====\n",
    "df = pd.read_csv(\"pruned_dataset.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "    # === Build and Prune Model ===\n",
    "    model_unpruned = FinalNetwork(C=8, num_classes=num_classes, layers=11, genotype=searched_genotype).to(device)\n",
    "    total_params_before = sum(p.numel() for p in model_unpruned.parameters())\n",
    "    print(f\"[INFO] Total parameters BEFORE pruning: {total_params_before:,}\")\n",
    "\n",
    "    model = prune_model_entropy(model_unpruned, prune_ratio=0.5)\n",
    "    nonzero_params_after = sum((p != 0).sum().item() for p in model.parameters())\n",
    "    zero_params = total_params_before - nonzero_params_after\n",
    "    pruned_ratio = 100 * zero_params / total_params_before\n",
    "    print(f\"[INFO] Non-zero parameters AFTER pruning: {nonzero_params_after:,}\")\n",
    "    print(f\"[INFO] Pruned parameters: {zero_params:,} ({pruned_ratio:.2f}%)\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Dataloader\n",
    "    X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "    X_val, y_val = X_all[val_idx], y_all[val_idx]\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "    no_improve_counter = 0  # ← EARLY STOPPING COUNTER\n",
    "\n",
    "    for epoch in range(50):  # Max epochs\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            no_improve_counter = 0  # reset counter\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(\n",
    "                np.array(val_true), np.array(val_pred), num_classes\n",
    "            )\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "        else:\n",
    "            no_improve_counter += 1\n",
    "            if no_improve_counter >= 15:\n",
    "                print(f\"[Early Stopping] No improvement in 15 consecutive epochs. Stopping at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ac3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5272 | Train Acc: 0.8049 | Val Loss: 0.4331 | Val Acc: 0.8409\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4584 | Train Acc: 0.8326 | Val Loss: 0.4424 | Val Acc: 0.8361\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4330 | Train Acc: 0.8410 | Val Loss: 0.4124 | Val Acc: 0.8518\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4243 | Train Acc: 0.8429 | Val Loss: 0.4136 | Val Acc: 0.8487\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4116 | Train Acc: 0.8492 | Val Loss: 0.4178 | Val Acc: 0.8462\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4012 | Train Acc: 0.8527 | Val Loss: 0.3751 | Val Acc: 0.8572\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.3936 | Train Acc: 0.8540 | Val Loss: 0.4330 | Val Acc: 0.8482\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.3957 | Train Acc: 0.8555 | Val Loss: 0.3718 | Val Acc: 0.8560\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.3813 | Train Acc: 0.8574 | Val Loss: 0.3744 | Val Acc: 0.8610\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.3782 | Train Acc: 0.8604 | Val Loss: 0.4112 | Val Acc: 0.8484\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3719 | Train Acc: 0.8614 | Val Loss: 0.3663 | Val Acc: 0.8635\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3689 | Train Acc: 0.8624 | Val Loss: 0.3819 | Val Acc: 0.8591\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3628 | Train Acc: 0.8647 | Val Loss: 0.4280 | Val Acc: 0.8412\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3528 | Train Acc: 0.8675 | Val Loss: 0.3840 | Val Acc: 0.8554\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3488 | Train Acc: 0.8717 | Val Loss: 0.3883 | Val Acc: 0.8537\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3406 | Train Acc: 0.8713 | Val Loss: 0.4211 | Val Acc: 0.8454\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3331 | Train Acc: 0.8737 | Val Loss: 0.3865 | Val Acc: 0.8520\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3280 | Train Acc: 0.8761 | Val Loss: 0.4073 | Val Acc: 0.8441\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3247 | Train Acc: 0.8792 | Val Loss: 0.3704 | Val Acc: 0.8602\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3075 | Train Acc: 0.8840 | Val Loss: 0.4209 | Val Acc: 0.8414\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3089 | Train Acc: 0.8843 | Val Loss: 0.3844 | Val Acc: 0.8495\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.2985 | Train Acc: 0.8900 | Val Loss: 0.4049 | Val Acc: 0.8488\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.2839 | Train Acc: 0.8941 | Val Loss: 0.5136 | Val Acc: 0.8135\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.2752 | Train Acc: 0.8957 | Val Loss: 0.4427 | Val Acc: 0.8465\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.2688 | Train Acc: 0.8979 | Val Loss: 0.4207 | Val Acc: 0.8577\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.2548 | Train Acc: 0.9049 | Val Loss: 0.4465 | Val Acc: 0.8349\n",
      "[Early Stopping] No improvement in 10 epochs. Stopping at epoch 26.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 11\n",
      "ACC: 0.8635 | MF1: 0.8013 | G-Mean: 0.8601\n",
      "[Class 0] Prec: 0.9120 | Rec: 0.9281 | F1: 0.9200 | GM: 0.9534\n",
      "[Class 1] Prec: 0.5952 | Rec: 0.3795 | F1: 0.4635 | GM: 0.6095\n",
      "[Class 2] Prec: 0.8850 | Rec: 0.9278 | F1: 0.9059 | GM: 0.9184\n",
      "[Class 3] Prec: 0.9533 | Rec: 0.8497 | F1: 0.8985 | GM: 0.9191\n",
      "[Class 4] Prec: 0.7843 | Rec: 0.8556 | F1: 0.8184 | GM: 0.9001\n",
      "\n",
      "===== Fold 2 =====\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5445 | Train Acc: 0.7972 | Val Loss: 0.4953 | Val Acc: 0.8237\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4572 | Train Acc: 0.8303 | Val Loss: 0.4136 | Val Acc: 0.8531\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4370 | Train Acc: 0.8371 | Val Loss: 0.4440 | Val Acc: 0.8328\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4277 | Train Acc: 0.8412 | Val Loss: 0.4865 | Val Acc: 0.8212\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4136 | Train Acc: 0.8468 | Val Loss: 0.4110 | Val Acc: 0.8512\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4036 | Train Acc: 0.8482 | Val Loss: 0.4520 | Val Acc: 0.8396\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.3991 | Train Acc: 0.8511 | Val Loss: 0.4257 | Val Acc: 0.8398\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.3965 | Train Acc: 0.8525 | Val Loss: 0.3935 | Val Acc: 0.8545\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.3873 | Train Acc: 0.8563 | Val Loss: 0.4088 | Val Acc: 0.8496\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.3802 | Train Acc: 0.8587 | Val Loss: 0.3875 | Val Acc: 0.8664\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3776 | Train Acc: 0.8594 | Val Loss: 0.3821 | Val Acc: 0.8622\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3719 | Train Acc: 0.8606 | Val Loss: 0.4350 | Val Acc: 0.8479\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3684 | Train Acc: 0.8627 | Val Loss: 0.4485 | Val Acc: 0.8425\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3601 | Train Acc: 0.8651 | Val Loss: 0.4059 | Val Acc: 0.8632\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3497 | Train Acc: 0.8679 | Val Loss: 0.4072 | Val Acc: 0.8486\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3400 | Train Acc: 0.8735 | Val Loss: 0.4263 | Val Acc: 0.8489\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3357 | Train Acc: 0.8743 | Val Loss: 0.4619 | Val Acc: 0.8329\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3313 | Train Acc: 0.8759 | Val Loss: 0.4009 | Val Acc: 0.8597\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3220 | Train Acc: 0.8784 | Val Loss: 0.3912 | Val Acc: 0.8491\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3165 | Train Acc: 0.8810 | Val Loss: 0.4097 | Val Acc: 0.8555\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3074 | Train Acc: 0.8848 | Val Loss: 0.4603 | Val Acc: 0.8464\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.3024 | Train Acc: 0.8872 | Val Loss: 0.4885 | Val Acc: 0.8336\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.2904 | Train Acc: 0.8940 | Val Loss: 0.4185 | Val Acc: 0.8535\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.2802 | Train Acc: 0.8949 | Val Loss: 0.4699 | Val Acc: 0.8505\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.2689 | Train Acc: 0.8986 | Val Loss: 0.5921 | Val Acc: 0.8116\n",
      "[Early Stopping] No improvement in 10 epochs. Stopping at epoch 25.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 10\n",
      "ACC: 0.8664 | MF1: 0.8146 | G-Mean: 0.8814\n",
      "[Class 0] Prec: 0.9355 | Rec: 0.9116 | F1: 0.9234 | GM: 0.9475\n",
      "[Class 1] Prec: 0.5123 | Rec: 0.5092 | F1: 0.5108 | GM: 0.7005\n",
      "[Class 2] Prec: 0.9007 | Rec: 0.9108 | F1: 0.9057 | GM: 0.9190\n",
      "[Class 3] Prec: 0.8952 | Rec: 0.9276 | F1: 0.9111 | GM: 0.9558\n",
      "[Class 4] Prec: 0.8300 | Rec: 0.8139 | F1: 0.8219 | GM: 0.8842\n",
      "\n",
      "===== Fold 3 =====\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5452 | Train Acc: 0.7976 | Val Loss: 0.4903 | Val Acc: 0.8209\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4579 | Train Acc: 0.8341 | Val Loss: 0.4302 | Val Acc: 0.8382\n",
      "[Fold 3 | Epoch 3] Train Loss: 0.4358 | Train Acc: 0.8375 | Val Loss: 0.4609 | Val Acc: 0.8316\n",
      "[Fold 3 | Epoch 4] Train Loss: 0.4317 | Train Acc: 0.8388 | Val Loss: 0.4354 | Val Acc: 0.8386\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4132 | Train Acc: 0.8469 | Val Loss: 0.4557 | Val Acc: 0.8265\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4098 | Train Acc: 0.8493 | Val Loss: 0.4326 | Val Acc: 0.8356\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4029 | Train Acc: 0.8505 | Val Loss: 0.4037 | Val Acc: 0.8555\n",
      "[Fold 3 | Epoch 8] Train Loss: 0.3948 | Train Acc: 0.8540 | Val Loss: 0.4510 | Val Acc: 0.8332\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.3908 | Train Acc: 0.8558 | Val Loss: 0.3910 | Val Acc: 0.8558\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.3838 | Train Acc: 0.8573 | Val Loss: 0.5012 | Val Acc: 0.8183\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3796 | Train Acc: 0.8598 | Val Loss: 0.3970 | Val Acc: 0.8514\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3754 | Train Acc: 0.8589 | Val Loss: 0.3760 | Val Acc: 0.8597\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3651 | Train Acc: 0.8651 | Val Loss: 0.4050 | Val Acc: 0.8495\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3679 | Train Acc: 0.8635 | Val Loss: 0.4418 | Val Acc: 0.8352\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3543 | Train Acc: 0.8670 | Val Loss: 0.4031 | Val Acc: 0.8561\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3536 | Train Acc: 0.8654 | Val Loss: 0.3919 | Val Acc: 0.8515\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3514 | Train Acc: 0.8686 | Val Loss: 0.3851 | Val Acc: 0.8584\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3406 | Train Acc: 0.8700 | Val Loss: 0.4139 | Val Acc: 0.8492\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3340 | Train Acc: 0.8746 | Val Loss: 0.4342 | Val Acc: 0.8362\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.3283 | Train Acc: 0.8760 | Val Loss: 0.3915 | Val Acc: 0.8587\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.3237 | Train Acc: 0.8797 | Val Loss: 0.4069 | Val Acc: 0.8544\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.3149 | Train Acc: 0.8823 | Val Loss: 0.4184 | Val Acc: 0.8525\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.3071 | Train Acc: 0.8839 | Val Loss: 0.4350 | Val Acc: 0.8405\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.2975 | Train Acc: 0.8881 | Val Loss: 0.6178 | Val Acc: 0.7934\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.2932 | Train Acc: 0.8885 | Val Loss: 0.4608 | Val Acc: 0.8476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3 | Epoch 26] Train Loss: 0.2833 | Train Acc: 0.8923 | Val Loss: 0.4166 | Val Acc: 0.8538\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.2751 | Train Acc: 0.8977 | Val Loss: 0.4863 | Val Acc: 0.8435\n",
      "[Early Stopping] No improvement in 10 epochs. Stopping at epoch 27.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 12\n",
      "ACC: 0.8597 | MF1: 0.8013 | G-Mean: 0.8649\n",
      "[Class 0] Prec: 0.9138 | Rec: 0.9094 | F1: 0.9116 | GM: 0.9445\n",
      "[Class 1] Prec: 0.5108 | Rec: 0.4243 | F1: 0.4635 | GM: 0.6411\n",
      "[Class 2] Prec: 0.8868 | Rec: 0.9208 | F1: 0.9035 | GM: 0.9168\n",
      "[Class 3] Prec: 0.9340 | Rec: 0.8783 | F1: 0.9053 | GM: 0.9333\n",
      "[Class 4] Prec: 0.8150 | Rec: 0.8299 | F1: 0.8224 | GM: 0.8889\n",
      "\n",
      "===== Fold 4 =====\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5518 | Train Acc: 0.7980 | Val Loss: 0.4928 | Val Acc: 0.8180\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4578 | Train Acc: 0.8332 | Val Loss: 0.4837 | Val Acc: 0.8269\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4310 | Train Acc: 0.8403 | Val Loss: 0.4744 | Val Acc: 0.8285\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4199 | Train Acc: 0.8421 | Val Loss: 0.5009 | Val Acc: 0.8260\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4119 | Train Acc: 0.8482 | Val Loss: 0.4106 | Val Acc: 0.8469\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4033 | Train Acc: 0.8530 | Val Loss: 0.3964 | Val Acc: 0.8618\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.3996 | Train Acc: 0.8508 | Val Loss: 0.4097 | Val Acc: 0.8496\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.3887 | Train Acc: 0.8568 | Val Loss: 0.4340 | Val Acc: 0.8438\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.3851 | Train Acc: 0.8560 | Val Loss: 0.5315 | Val Acc: 0.8050\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.3803 | Train Acc: 0.8612 | Val Loss: 0.5286 | Val Acc: 0.8041\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.3718 | Train Acc: 0.8608 | Val Loss: 0.3910 | Val Acc: 0.8604\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3709 | Train Acc: 0.8620 | Val Loss: 0.4035 | Val Acc: 0.8557\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3652 | Train Acc: 0.8636 | Val Loss: 0.4088 | Val Acc: 0.8515\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3575 | Train Acc: 0.8690 | Val Loss: 0.4399 | Val Acc: 0.8435\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3555 | Train Acc: 0.8691 | Val Loss: 0.4307 | Val Acc: 0.8456\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3453 | Train Acc: 0.8723 | Val Loss: 0.4211 | Val Acc: 0.8561\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3399 | Train Acc: 0.8738 | Val Loss: 0.3846 | Val Acc: 0.8644\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3373 | Train Acc: 0.8735 | Val Loss: 0.4103 | Val Acc: 0.8512\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3288 | Train Acc: 0.8756 | Val Loss: 0.4191 | Val Acc: 0.8496\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3208 | Train Acc: 0.8813 | Val Loss: 0.5393 | Val Acc: 0.8109\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3174 | Train Acc: 0.8800 | Val Loss: 0.4610 | Val Acc: 0.8383\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.3083 | Train Acc: 0.8846 | Val Loss: 0.3984 | Val Acc: 0.8619\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.2992 | Train Acc: 0.8880 | Val Loss: 0.4100 | Val Acc: 0.8546\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.2958 | Train Acc: 0.8888 | Val Loss: 0.4174 | Val Acc: 0.8536\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.2922 | Train Acc: 0.8895 | Val Loss: 0.4020 | Val Acc: 0.8568\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.2757 | Train Acc: 0.8966 | Val Loss: 0.4318 | Val Acc: 0.8619\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.2718 | Train Acc: 0.8978 | Val Loss: 0.4416 | Val Acc: 0.8454\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.2616 | Train Acc: 0.9008 | Val Loss: 0.4046 | Val Acc: 0.8644\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.2579 | Train Acc: 0.9022 | Val Loss: 0.4471 | Val Acc: 0.8461\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.2478 | Train Acc: 0.9069 | Val Loss: 0.4928 | Val Acc: 0.8398\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.2412 | Train Acc: 0.9084 | Val Loss: 0.5274 | Val Acc: 0.8289\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.2368 | Train Acc: 0.9087 | Val Loss: 0.4989 | Val Acc: 0.8328\n",
      "[Early Stopping] No improvement in 10 epochs. Stopping at epoch 32.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 17\n",
      "ACC: 0.8644 | MF1: 0.8005 | G-Mean: 0.8618\n",
      "[Class 0] Prec: 0.9200 | Rec: 0.9302 | F1: 0.9251 | GM: 0.9551\n",
      "[Class 1] Prec: 0.5745 | Rec: 0.3783 | F1: 0.4562 | GM: 0.6086\n",
      "[Class 2] Prec: 0.8766 | Rec: 0.9234 | F1: 0.8994 | GM: 0.9123\n",
      "[Class 3] Prec: 0.8924 | Rec: 0.9372 | F1: 0.9143 | GM: 0.9602\n",
      "[Class 4] Prec: 0.8255 | Rec: 0.7908 | F1: 0.8078 | GM: 0.8727\n",
      "\n",
      "===== Fold 5 =====\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.5506 | Train Acc: 0.7951 | Val Loss: 0.6340 | Val Acc: 0.7834\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4579 | Train Acc: 0.8324 | Val Loss: 0.4354 | Val Acc: 0.8425\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4363 | Train Acc: 0.8390 | Val Loss: 0.5800 | Val Acc: 0.7765\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4231 | Train Acc: 0.8440 | Val Loss: 0.4386 | Val Acc: 0.8378\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4153 | Train Acc: 0.8462 | Val Loss: 0.4029 | Val Acc: 0.8577\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.3990 | Train Acc: 0.8514 | Val Loss: 0.4082 | Val Acc: 0.8502\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.3977 | Train Acc: 0.8529 | Val Loss: 0.3997 | Val Acc: 0.8516\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.3899 | Train Acc: 0.8558 | Val Loss: 0.4038 | Val Acc: 0.8489\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.3863 | Train Acc: 0.8586 | Val Loss: 0.3930 | Val Acc: 0.8598\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.3816 | Train Acc: 0.8593 | Val Loss: 0.4027 | Val Acc: 0.8518\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.3767 | Train Acc: 0.8605 | Val Loss: 0.3903 | Val Acc: 0.8618\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3686 | Train Acc: 0.8642 | Val Loss: 0.4056 | Val Acc: 0.8474\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3670 | Train Acc: 0.8644 | Val Loss: 0.4594 | Val Acc: 0.8408\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3613 | Train Acc: 0.8653 | Val Loss: 0.4411 | Val Acc: 0.8445\n",
      "[Fold 5 | Epoch 15] Train Loss: 0.3552 | Train Acc: 0.8669 | Val Loss: 0.3824 | Val Acc: 0.8567\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3536 | Train Acc: 0.8668 | Val Loss: 0.3681 | Val Acc: 0.8678\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3439 | Train Acc: 0.8728 | Val Loss: 0.3936 | Val Acc: 0.8551\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3382 | Train Acc: 0.8744 | Val Loss: 0.4298 | Val Acc: 0.8456\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3363 | Train Acc: 0.8740 | Val Loss: 0.4161 | Val Acc: 0.8468\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3314 | Train Acc: 0.8763 | Val Loss: 0.3906 | Val Acc: 0.8589\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.3236 | Train Acc: 0.8788 | Val Loss: 0.4200 | Val Acc: 0.8564\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.3177 | Train Acc: 0.8803 | Val Loss: 0.4254 | Val Acc: 0.8411\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.3070 | Train Acc: 0.8844 | Val Loss: 0.4181 | Val Acc: 0.8452\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.3045 | Train Acc: 0.8827 | Val Loss: 0.4253 | Val Acc: 0.8461\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.2957 | Train Acc: 0.8890 | Val Loss: 0.4439 | Val Acc: 0.8466\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.2926 | Train Acc: 0.8899 | Val Loss: 0.4010 | Val Acc: 0.8501\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.2854 | Train Acc: 0.8923 | Val Loss: 0.4214 | Val Acc: 0.8501\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.2774 | Train Acc: 0.8976 | Val Loss: 0.3898 | Val Acc: 0.8574\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.2645 | Train Acc: 0.8993 | Val Loss: 0.4487 | Val Acc: 0.8471\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.2616 | Train Acc: 0.9020 | Val Loss: 0.4661 | Val Acc: 0.8549\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.2552 | Train Acc: 0.9035 | Val Loss: 0.4614 | Val Acc: 0.8594\n",
      "[Early Stopping] No improvement in 10 epochs. Stopping at epoch 31.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 16\n",
      "ACC: 0.8678 | MF1: 0.8042 | G-Mean: 0.8681\n",
      "[Class 0] Prec: 0.9009 | Rec: 0.9186 | F1: 0.9097 | GM: 0.9475\n",
      "[Class 1] Prec: 0.5476 | Rec: 0.3823 | F1: 0.4502 | GM: 0.6108\n",
      "[Class 2] Prec: 0.9104 | Rec: 0.9125 | F1: 0.9114 | GM: 0.9219\n",
      "[Class 3] Prec: 0.9209 | Rec: 0.9263 | F1: 0.9236 | GM: 0.9571\n",
      "[Class 4] Prec: 0.7939 | Rec: 0.8612 | F1: 0.8262 | GM: 0.9032\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8644 | MF1: 0.8047 | G-Mean: 0.8676\n",
      "[Class 0] Prec: 0.9166 | Rec: 0.9196 | F1: 0.9181 | GM: 0.9496\n",
      "[Class 1] Prec: 0.5435 | Rec: 0.4141 | F1: 0.4701 | GM: 0.6348\n",
      "[Class 2] Prec: 0.8917 | Rec: 0.9191 | F1: 0.9052 | GM: 0.9177\n",
      "[Class 3] Prec: 0.9176 | Rec: 0.9041 | F1: 0.9108 | GM: 0.9454\n",
      "[Class 4] Prec: 0.8090 | Rec: 0.8305 | F1: 0.8196 | GM: 0.8901\n",
      "Confusion Matrix:\n",
      "[[ 6042   291   115    14   108]\n",
      " [  338  1037   502    11   616]\n",
      " [   87   226 13754   320   578]\n",
      " [    8     0   402  3864     0]\n",
      " [  117   354   652     2  5513]]\n"
     ]
    }
   ],
   "source": [
    "#p7_1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from model_build import FinalNetwork\n",
    "\n",
    "# ==== Load and Normalize Data ====\n",
    "df = pd.read_csv(\"pruned_dataset.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "# Z-score normalization\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== Evaluation Metric Function ====\n",
    "def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    gmeans = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        tn = np.sum((y_pred != c) & (y_true != c))\n",
    "        fp = np.sum((y_pred == c) & (y_true != c))\n",
    "        gm = np.sqrt((tp / (tp + fn + 1e-6)) * (tn / (tn + fp + 1e-6)))\n",
    "        gmeans.append(gm)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, mf1, np.mean(gmeans), prec, rec, f1s, gmeans, cm\n",
    "\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=47)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "    X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "    X_val, y_val = X_all[val_idx], y_all[val_idx]\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "\n",
    "    model = FinalNetwork(C=8, num_classes=num_classes, layers=7, genotype=searched_genotype).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0055)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "    no_improve_counter = 0  # ← EARLY STOP counter\n",
    "\n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] \"\n",
    "              f\"Train Loss: {train_loss/len(train_loader):.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            no_improve_counter = 0  # reset counter\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "        else:\n",
    "            no_improve_counter += 1\n",
    "            if no_improve_counter >= 15:\n",
    "                print(f\"[Early Stopping] No improvement in 10 epochs. Stopping at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[INFO] Total parameters BEFORE pruning: 83,789\n",
      "[INFO] Non-zero parameters AFTER pruning: 42,377\n",
      "[INFO] Pruned parameters: 41,412 (49.42%)\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5837 | Train Acc: 0.7809 | Val Loss: 0.4900 | Val Acc: 0.8216\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4625 | Train Acc: 0.8293 | Val Loss: 0.4490 | Val Acc: 0.8405\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4470 | Train Acc: 0.8356 | Val Loss: 0.4251 | Val Acc: 0.8468\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4272 | Train Acc: 0.8416 | Val Loss: 0.5772 | Val Acc: 0.7913\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4253 | Train Acc: 0.8416 | Val Loss: 0.4207 | Val Acc: 0.8461\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4107 | Train Acc: 0.8462 | Val Loss: 0.5249 | Val Acc: 0.8213\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.4077 | Train Acc: 0.8465 | Val Loss: 0.3978 | Val Acc: 0.8611\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.4021 | Train Acc: 0.8496 | Val Loss: 0.4697 | Val Acc: 0.8298\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.3985 | Train Acc: 0.8497 | Val Loss: 0.4634 | Val Acc: 0.8398\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.3945 | Train Acc: 0.8513 | Val Loss: 0.3973 | Val Acc: 0.8544\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3884 | Train Acc: 0.8563 | Val Loss: 0.4151 | Val Acc: 0.8475\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3831 | Train Acc: 0.8562 | Val Loss: 0.4031 | Val Acc: 0.8561\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3824 | Train Acc: 0.8574 | Val Loss: 0.4077 | Val Acc: 0.8564\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3786 | Train Acc: 0.8582 | Val Loss: 0.4142 | Val Acc: 0.8498\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3708 | Train Acc: 0.8614 | Val Loss: 0.4060 | Val Acc: 0.8584\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3657 | Train Acc: 0.8624 | Val Loss: 0.4528 | Val Acc: 0.8411\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3626 | Train Acc: 0.8638 | Val Loss: 0.4409 | Val Acc: 0.8482\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3584 | Train Acc: 0.8653 | Val Loss: 0.4359 | Val Acc: 0.8495\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3557 | Train Acc: 0.8657 | Val Loss: 0.4075 | Val Acc: 0.8517\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3587 | Train Acc: 0.8652 | Val Loss: 0.5332 | Val Acc: 0.8169\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3475 | Train Acc: 0.8673 | Val Loss: 0.5582 | Val Acc: 0.7982\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.3476 | Train Acc: 0.8721 | Val Loss: 0.3906 | Val Acc: 0.8604\n",
      "[Early Stopping] No improvement in 20 consecutive epochs. Stopping at epoch 22.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 7\n",
      "ACC: 0.8611 | MF1: 0.8061 | G-Mean: 0.8699\n",
      "[Class 0] Prec: 0.9300 | Rec: 0.9023 | F1: 0.9159 | GM: 0.9427\n",
      "[Class 1] Prec: 0.5135 | Rec: 0.4473 | F1: 0.4781 | GM: 0.6575\n",
      "[Class 2] Prec: 0.8887 | Rec: 0.9234 | F1: 0.9057 | GM: 0.9185\n",
      "[Class 3] Prec: 0.9299 | Rec: 0.9233 | F1: 0.9266 | GM: 0.9563\n",
      "[Class 4] Prec: 0.8064 | Rec: 0.8022 | F1: 0.8043 | GM: 0.8746\n",
      "\n",
      "===== Fold 2 =====\n",
      "[INFO] Total parameters BEFORE pruning: 83,789\n",
      "[INFO] Non-zero parameters AFTER pruning: 42,377\n",
      "[INFO] Pruned parameters: 41,412 (49.42%)\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5629 | Train Acc: 0.7947 | Val Loss: 0.7040 | Val Acc: 0.7508\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4656 | Train Acc: 0.8280 | Val Loss: 0.7072 | Val Acc: 0.7767\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4493 | Train Acc: 0.8370 | Val Loss: 0.4260 | Val Acc: 0.8428\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4347 | Train Acc: 0.8394 | Val Loss: 0.4743 | Val Acc: 0.8265\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4264 | Train Acc: 0.8450 | Val Loss: 0.4178 | Val Acc: 0.8472\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4214 | Train Acc: 0.8464 | Val Loss: 0.4602 | Val Acc: 0.8309\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4103 | Train Acc: 0.8497 | Val Loss: 0.4355 | Val Acc: 0.8368\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.4041 | Train Acc: 0.8515 | Val Loss: 0.4177 | Val Acc: 0.8458\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.3955 | Train Acc: 0.8543 | Val Loss: 0.4258 | Val Acc: 0.8403\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.3892 | Train Acc: 0.8567 | Val Loss: 0.4808 | Val Acc: 0.8326\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3877 | Train Acc: 0.8578 | Val Loss: 0.4018 | Val Acc: 0.8541\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3858 | Train Acc: 0.8571 | Val Loss: 0.4557 | Val Acc: 0.8385\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3796 | Train Acc: 0.8602 | Val Loss: 0.4394 | Val Acc: 0.8445\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3792 | Train Acc: 0.8604 | Val Loss: 0.3977 | Val Acc: 0.8568\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3756 | Train Acc: 0.8619 | Val Loss: 0.4220 | Val Acc: 0.8495\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3716 | Train Acc: 0.8633 | Val Loss: 0.5147 | Val Acc: 0.8090\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3703 | Train Acc: 0.8632 | Val Loss: 0.4056 | Val Acc: 0.8565\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3588 | Train Acc: 0.8657 | Val Loss: 0.5375 | Val Acc: 0.7921\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3578 | Train Acc: 0.8665 | Val Loss: 0.3855 | Val Acc: 0.8588\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3543 | Train Acc: 0.8688 | Val Loss: 0.3862 | Val Acc: 0.8612\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3463 | Train Acc: 0.8711 | Val Loss: 0.3856 | Val Acc: 0.8601\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.3391 | Train Acc: 0.8758 | Val Loss: 0.4241 | Val Acc: 0.8464\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.3450 | Train Acc: 0.8718 | Val Loss: 0.3749 | Val Acc: 0.8621\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.3357 | Train Acc: 0.8744 | Val Loss: 0.4278 | Val Acc: 0.8433\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.3274 | Train Acc: 0.8780 | Val Loss: 0.5031 | Val Acc: 0.8438\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.3261 | Train Acc: 0.8788 | Val Loss: 0.4450 | Val Acc: 0.8509\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.3193 | Train Acc: 0.8818 | Val Loss: 0.4618 | Val Acc: 0.8365\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.3126 | Train Acc: 0.8851 | Val Loss: 0.5114 | Val Acc: 0.8298\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.3106 | Train Acc: 0.8828 | Val Loss: 0.5459 | Val Acc: 0.8099\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.3029 | Train Acc: 0.8862 | Val Loss: 0.4259 | Val Acc: 0.8475\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.3003 | Train Acc: 0.8884 | Val Loss: 0.4332 | Val Acc: 0.8558\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.2908 | Train Acc: 0.8918 | Val Loss: 0.4215 | Val Acc: 0.8548\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.2883 | Train Acc: 0.8912 | Val Loss: 0.5453 | Val Acc: 0.8119\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.2835 | Train Acc: 0.8930 | Val Loss: 0.4689 | Val Acc: 0.8363\n",
      "[Fold 2 | Epoch 35] Train Loss: 0.2781 | Train Acc: 0.8947 | Val Loss: 0.4591 | Val Acc: 0.8522\n",
      "[Fold 2 | Epoch 36] Train Loss: 0.2702 | Train Acc: 0.8971 | Val Loss: 0.5211 | Val Acc: 0.8376\n",
      "[Fold 2 | Epoch 37] Train Loss: 0.2668 | Train Acc: 0.8999 | Val Loss: 0.5230 | Val Acc: 0.8209\n",
      "[Fold 2 | Epoch 38] Train Loss: 0.2661 | Train Acc: 0.8984 | Val Loss: 0.5894 | Val Acc: 0.8272\n",
      "[Early Stopping] No improvement in 20 consecutive epochs. Stopping at epoch 38.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 23\n",
      "ACC: 0.8621 | MF1: 0.8042 | G-Mean: 0.8708\n",
      "[Class 0] Prec: 0.9342 | Rec: 0.9129 | F1: 0.9234 | GM: 0.9480\n",
      "[Class 1] Prec: 0.5550 | Rec: 0.4165 | F1: 0.4759 | GM: 0.6368\n",
      "[Class 2] Prec: 0.9034 | Rec: 0.8979 | F1: 0.9006 | GM: 0.9134\n",
      "[Class 3] Prec: 0.8771 | Rec: 0.9312 | F1: 0.9033 | GM: 0.9562\n",
      "[Class 4] Prec: 0.7823 | Rec: 0.8563 | F1: 0.8176 | GM: 0.8998\n",
      "\n",
      "===== Fold 3 =====\n",
      "[INFO] Total parameters BEFORE pruning: 83,789\n",
      "[INFO] Non-zero parameters AFTER pruning: 42,377\n",
      "[INFO] Pruned parameters: 41,412 (49.42%)\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5585 | Train Acc: 0.7944 | Val Loss: 0.5299 | Val Acc: 0.7984\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4749 | Train Acc: 0.8251 | Val Loss: 0.4368 | Val Acc: 0.8352\n",
      "[Fold 3 | Epoch 3] Train Loss: 0.4487 | Train Acc: 0.8346 | Val Loss: 0.4433 | Val Acc: 0.8435\n",
      "[Fold 3 | Epoch 4] Train Loss: 0.4335 | Train Acc: 0.8409 | Val Loss: 0.4082 | Val Acc: 0.8557\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4321 | Train Acc: 0.8417 | Val Loss: 0.4239 | Val Acc: 0.8524\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4190 | Train Acc: 0.8449 | Val Loss: 0.3913 | Val Acc: 0.8592\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4125 | Train Acc: 0.8451 | Val Loss: 0.4688 | Val Acc: 0.8299\n",
      "[Fold 3 | Epoch 8] Train Loss: 0.4053 | Train Acc: 0.8501 | Val Loss: 0.4541 | Val Acc: 0.8338\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.3995 | Train Acc: 0.8491 | Val Loss: 0.4244 | Val Acc: 0.8428\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.3948 | Train Acc: 0.8533 | Val Loss: 0.4045 | Val Acc: 0.8555\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3915 | Train Acc: 0.8556 | Val Loss: 0.4410 | Val Acc: 0.8393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3 | Epoch 12] Train Loss: 0.3885 | Train Acc: 0.8555 | Val Loss: 0.3906 | Val Acc: 0.8548\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3865 | Train Acc: 0.8569 | Val Loss: 0.3746 | Val Acc: 0.8625\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3778 | Train Acc: 0.8595 | Val Loss: 0.4078 | Val Acc: 0.8505\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3806 | Train Acc: 0.8584 | Val Loss: 0.3906 | Val Acc: 0.8588\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3695 | Train Acc: 0.8632 | Val Loss: 0.4101 | Val Acc: 0.8474\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3684 | Train Acc: 0.8640 | Val Loss: 0.3840 | Val Acc: 0.8577\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3652 | Train Acc: 0.8643 | Val Loss: 0.4382 | Val Acc: 0.8449\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3606 | Train Acc: 0.8652 | Val Loss: 0.3780 | Val Acc: 0.8611\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.3539 | Train Acc: 0.8672 | Val Loss: 0.4307 | Val Acc: 0.8388\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.3502 | Train Acc: 0.8692 | Val Loss: 0.5560 | Val Acc: 0.7954\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.3532 | Train Acc: 0.8657 | Val Loss: 0.4425 | Val Acc: 0.8376\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.3444 | Train Acc: 0.8713 | Val Loss: 0.4574 | Val Acc: 0.8286\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.3357 | Train Acc: 0.8740 | Val Loss: 0.3890 | Val Acc: 0.8635\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.3370 | Train Acc: 0.8751 | Val Loss: 0.3988 | Val Acc: 0.8546\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.3305 | Train Acc: 0.8764 | Val Loss: 0.3988 | Val Acc: 0.8525\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.3208 | Train Acc: 0.8808 | Val Loss: 0.3821 | Val Acc: 0.8609\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.3215 | Train Acc: 0.8799 | Val Loss: 0.4557 | Val Acc: 0.8391\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.3171 | Train Acc: 0.8794 | Val Loss: 0.4009 | Val Acc: 0.8524\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.3100 | Train Acc: 0.8835 | Val Loss: 0.4325 | Val Acc: 0.8484\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.3070 | Train Acc: 0.8835 | Val Loss: 0.3962 | Val Acc: 0.8637\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.3037 | Train Acc: 0.8874 | Val Loss: 0.4100 | Val Acc: 0.8498\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.2968 | Train Acc: 0.8872 | Val Loss: 0.4177 | Val Acc: 0.8538\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.2936 | Train Acc: 0.8908 | Val Loss: 0.5641 | Val Acc: 0.8134\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.2904 | Train Acc: 0.8901 | Val Loss: 0.4194 | Val Acc: 0.8549\n",
      "[Fold 3 | Epoch 36] Train Loss: 0.2825 | Train Acc: 0.8925 | Val Loss: 0.4113 | Val Acc: 0.8554\n",
      "[Fold 3 | Epoch 37] Train Loss: 0.2788 | Train Acc: 0.8948 | Val Loss: 0.4595 | Val Acc: 0.8392\n",
      "[Fold 3 | Epoch 38] Train Loss: 0.2761 | Train Acc: 0.8961 | Val Loss: 0.4471 | Val Acc: 0.8494\n",
      "[Fold 3 | Epoch 39] Train Loss: 0.2713 | Train Acc: 0.8972 | Val Loss: 0.4395 | Val Acc: 0.8506\n",
      "[Fold 3 | Epoch 40] Train Loss: 0.2680 | Train Acc: 0.8990 | Val Loss: 0.5233 | Val Acc: 0.8293\n",
      "[Fold 3 | Epoch 41] Train Loss: 0.2581 | Train Acc: 0.9034 | Val Loss: 0.4365 | Val Acc: 0.8641\n",
      "[Fold 3 | Epoch 42] Train Loss: 0.2606 | Train Acc: 0.9014 | Val Loss: 0.4737 | Val Acc: 0.8418\n",
      "[Fold 3 | Epoch 43] Train Loss: 0.2529 | Train Acc: 0.9027 | Val Loss: 0.5166 | Val Acc: 0.8466\n",
      "[Fold 3 | Epoch 44] Train Loss: 0.2485 | Train Acc: 0.9048 | Val Loss: 0.5103 | Val Acc: 0.8439\n",
      "[Fold 3 | Epoch 45] Train Loss: 0.2463 | Train Acc: 0.9076 | Val Loss: 0.4682 | Val Acc: 0.8531\n",
      "[Fold 3 | Epoch 46] Train Loss: 0.2424 | Train Acc: 0.9063 | Val Loss: 0.4696 | Val Acc: 0.8484\n",
      "[Fold 3 | Epoch 47] Train Loss: 0.2364 | Train Acc: 0.9086 | Val Loss: 0.4735 | Val Acc: 0.8383\n",
      "[Fold 3 | Epoch 48] Train Loss: 0.2324 | Train Acc: 0.9127 | Val Loss: 0.4908 | Val Acc: 0.8544\n",
      "[Fold 3 | Epoch 49] Train Loss: 0.2316 | Train Acc: 0.9137 | Val Loss: 0.4833 | Val Acc: 0.8569\n",
      "[Fold 3 | Epoch 50] Train Loss: 0.2254 | Train Acc: 0.9160 | Val Loss: 0.5141 | Val Acc: 0.8412\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 41\n",
      "ACC: 0.8641 | MF1: 0.8144 | G-Mean: 0.8844\n",
      "[Class 0] Prec: 0.9302 | Rec: 0.8999 | F1: 0.9148 | GM: 0.9409\n",
      "[Class 1] Prec: 0.5123 | Rec: 0.5264 | F1: 0.5193 | GM: 0.7122\n",
      "[Class 2] Prec: 0.9125 | Rec: 0.8902 | F1: 0.9012 | GM: 0.9130\n",
      "[Class 3] Prec: 0.8873 | Rec: 0.9364 | F1: 0.9112 | GM: 0.9597\n",
      "[Class 4] Prec: 0.8085 | Rec: 0.8431 | F1: 0.8254 | GM: 0.8964\n",
      "\n",
      "===== Fold 4 =====\n",
      "[INFO] Total parameters BEFORE pruning: 83,789\n",
      "[INFO] Non-zero parameters AFTER pruning: 42,377\n",
      "[INFO] Pruned parameters: 41,412 (49.42%)\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5542 | Train Acc: 0.7910 | Val Loss: 0.5396 | Val Acc: 0.7969\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4572 | Train Acc: 0.8326 | Val Loss: 0.4586 | Val Acc: 0.8382\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4458 | Train Acc: 0.8372 | Val Loss: 0.4403 | Val Acc: 0.8449\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4267 | Train Acc: 0.8440 | Val Loss: 0.4920 | Val Acc: 0.8230\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4159 | Train Acc: 0.8464 | Val Loss: 0.4251 | Val Acc: 0.8416\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4064 | Train Acc: 0.8514 | Val Loss: 0.5227 | Val Acc: 0.8172\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.4027 | Train Acc: 0.8523 | Val Loss: 0.4394 | Val Acc: 0.8325\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.3970 | Train Acc: 0.8525 | Val Loss: 0.4462 | Val Acc: 0.8351\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.3913 | Train Acc: 0.8545 | Val Loss: 0.3933 | Val Acc: 0.8552\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.3874 | Train Acc: 0.8567 | Val Loss: 0.3898 | Val Acc: 0.8554\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.3860 | Train Acc: 0.8564 | Val Loss: 0.4047 | Val Acc: 0.8496\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3812 | Train Acc: 0.8562 | Val Loss: 0.4316 | Val Acc: 0.8448\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3739 | Train Acc: 0.8639 | Val Loss: 0.4418 | Val Acc: 0.8322\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3700 | Train Acc: 0.8607 | Val Loss: 0.4361 | Val Acc: 0.8313\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3642 | Train Acc: 0.8661 | Val Loss: 0.4400 | Val Acc: 0.8454\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3624 | Train Acc: 0.8656 | Val Loss: 0.3955 | Val Acc: 0.8544\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3582 | Train Acc: 0.8650 | Val Loss: 0.4821 | Val Acc: 0.8212\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3554 | Train Acc: 0.8678 | Val Loss: 0.4099 | Val Acc: 0.8577\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3482 | Train Acc: 0.8704 | Val Loss: 0.3977 | Val Acc: 0.8529\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3412 | Train Acc: 0.8730 | Val Loss: 0.6892 | Val Acc: 0.7938\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3382 | Train Acc: 0.8737 | Val Loss: 0.4683 | Val Acc: 0.8335\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.3389 | Train Acc: 0.8742 | Val Loss: 0.4109 | Val Acc: 0.8475\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.3342 | Train Acc: 0.8758 | Val Loss: 0.3814 | Val Acc: 0.8597\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.3257 | Train Acc: 0.8788 | Val Loss: 0.4038 | Val Acc: 0.8601\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.3233 | Train Acc: 0.8790 | Val Loss: 0.4410 | Val Acc: 0.8428\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.3195 | Train Acc: 0.8769 | Val Loss: 0.4210 | Val Acc: 0.8468\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.3183 | Train Acc: 0.8803 | Val Loss: 0.4265 | Val Acc: 0.8446\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.3083 | Train Acc: 0.8842 | Val Loss: 0.4061 | Val Acc: 0.8555\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.3009 | Train Acc: 0.8861 | Val Loss: 0.4769 | Val Acc: 0.8366\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.3035 | Train Acc: 0.8860 | Val Loss: 0.4124 | Val Acc: 0.8471\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.2921 | Train Acc: 0.8908 | Val Loss: 0.4551 | Val Acc: 0.8408\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.2907 | Train Acc: 0.8897 | Val Loss: 0.4871 | Val Acc: 0.8293\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.2845 | Train Acc: 0.8932 | Val Loss: 0.4600 | Val Acc: 0.8448\n",
      "[Fold 4 | Epoch 34] Train Loss: 0.2798 | Train Acc: 0.8952 | Val Loss: 0.4212 | Val Acc: 0.8552\n",
      "[Fold 4 | Epoch 35] Train Loss: 0.2804 | Train Acc: 0.8944 | Val Loss: 0.5833 | Val Acc: 0.8060\n",
      "[Fold 4 | Epoch 36] Train Loss: 0.2725 | Train Acc: 0.8981 | Val Loss: 0.4445 | Val Acc: 0.8532\n",
      "[Fold 4 | Epoch 37] Train Loss: 0.2672 | Train Acc: 0.9003 | Val Loss: 0.4353 | Val Acc: 0.8516\n",
      "[Fold 4 | Epoch 38] Train Loss: 0.2640 | Train Acc: 0.8987 | Val Loss: 0.7177 | Val Acc: 0.7572\n",
      "[Fold 4 | Epoch 39] Train Loss: 0.2555 | Train Acc: 0.9044 | Val Loss: 0.5149 | Val Acc: 0.8308\n",
      "[Early Stopping] No improvement in 20 consecutive epochs. Stopping at epoch 39.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 24\n",
      "ACC: 0.8601 | MF1: 0.8085 | G-Mean: 0.8684\n",
      "[Class 0] Prec: 0.9392 | Rec: 0.8942 | F1: 0.9161 | GM: 0.9394\n",
      "[Class 1] Prec: 0.5628 | Rec: 0.4700 | F1: 0.5122 | GM: 0.6752\n",
      "[Class 2] Prec: 0.8782 | Rec: 0.9278 | F1: 0.9023 | GM: 0.9165\n",
      "[Class 3] Prec: 0.9464 | Rec: 0.8461 | F1: 0.8934 | GM: 0.9167\n",
      "[Class 4] Prec: 0.7961 | Rec: 0.8419 | F1: 0.8184 | GM: 0.8942\n",
      "\n",
      "===== Fold 5 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Total parameters BEFORE pruning: 83,789\n",
      "[INFO] Non-zero parameters AFTER pruning: 42,377\n",
      "[INFO] Pruned parameters: 41,412 (49.42%)\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.5801 | Train Acc: 0.7853 | Val Loss: 0.4778 | Val Acc: 0.8272\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4783 | Train Acc: 0.8229 | Val Loss: 0.4465 | Val Acc: 0.8363\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4569 | Train Acc: 0.8318 | Val Loss: 0.4263 | Val Acc: 0.8545\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4402 | Train Acc: 0.8374 | Val Loss: 0.5106 | Val Acc: 0.8167\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4325 | Train Acc: 0.8392 | Val Loss: 0.3965 | Val Acc: 0.8506\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4206 | Train Acc: 0.8451 | Val Loss: 0.4051 | Val Acc: 0.8526\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.4165 | Train Acc: 0.8457 | Val Loss: 0.3920 | Val Acc: 0.8511\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.4100 | Train Acc: 0.8474 | Val Loss: 0.4003 | Val Acc: 0.8486\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.4065 | Train Acc: 0.8486 | Val Loss: 0.4261 | Val Acc: 0.8381\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.4057 | Train Acc: 0.8490 | Val Loss: 0.3948 | Val Acc: 0.8558\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.3957 | Train Acc: 0.8531 | Val Loss: 0.3784 | Val Acc: 0.8587\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3978 | Train Acc: 0.8513 | Val Loss: 0.4259 | Val Acc: 0.8391\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3917 | Train Acc: 0.8559 | Val Loss: 0.3625 | Val Acc: 0.8710\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3834 | Train Acc: 0.8564 | Val Loss: 0.3892 | Val Acc: 0.8532\n",
      "[Fold 5 | Epoch 15] Train Loss: 0.3760 | Train Acc: 0.8598 | Val Loss: 0.3687 | Val Acc: 0.8608\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3767 | Train Acc: 0.8601 | Val Loss: 0.3768 | Val Acc: 0.8595\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3686 | Train Acc: 0.8611 | Val Loss: 0.3742 | Val Acc: 0.8598\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3694 | Train Acc: 0.8634 | Val Loss: 0.4369 | Val Acc: 0.8416\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3589 | Train Acc: 0.8651 | Val Loss: 0.3595 | Val Acc: 0.8629\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3546 | Train Acc: 0.8686 | Val Loss: 0.3810 | Val Acc: 0.8621\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.3483 | Train Acc: 0.8702 | Val Loss: 0.4085 | Val Acc: 0.8546\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.3458 | Train Acc: 0.8718 | Val Loss: 0.3875 | Val Acc: 0.8638\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.3381 | Train Acc: 0.8745 | Val Loss: 0.4043 | Val Acc: 0.8492\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.3367 | Train Acc: 0.8729 | Val Loss: 0.4217 | Val Acc: 0.8542\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.3339 | Train Acc: 0.8759 | Val Loss: 0.5544 | Val Acc: 0.7987\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.3217 | Train Acc: 0.8798 | Val Loss: 0.4285 | Val Acc: 0.8594\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.3219 | Train Acc: 0.8790 | Val Loss: 0.4051 | Val Acc: 0.8498\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.3158 | Train Acc: 0.8798 | Val Loss: 0.3657 | Val Acc: 0.8618\n",
      "[Early Stopping] No improvement in 20 consecutive epochs. Stopping at epoch 28.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 13\n",
      "ACC: 0.8710 | MF1: 0.8106 | G-Mean: 0.8702\n",
      "[Class 0] Prec: 0.9135 | Rec: 0.9312 | F1: 0.9223 | GM: 0.9553\n",
      "[Class 1] Prec: 0.5284 | Rec: 0.4307 | F1: 0.4745 | GM: 0.6470\n",
      "[Class 2] Prec: 0.8845 | Rec: 0.9326 | F1: 0.9079 | GM: 0.9189\n",
      "[Class 3] Prec: 0.9289 | Rec: 0.9002 | F1: 0.9144 | GM: 0.9443\n",
      "[Class 4] Prec: 0.8596 | Rec: 0.8095 | F1: 0.8338 | GM: 0.8857\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8637 | MF1: 0.8089 | G-Mean: 0.8728\n",
      "[Class 0] Prec: 0.9293 | Rec: 0.9081 | F1: 0.9186 | GM: 0.9453\n",
      "[Class 1] Prec: 0.5335 | Rec: 0.4577 | F1: 0.4927 | GM: 0.6660\n",
      "[Class 2] Prec: 0.8930 | Rec: 0.9145 | F1: 0.9036 | GM: 0.9162\n",
      "[Class 3] Prec: 0.9124 | Rec: 0.9071 | F1: 0.9098 | GM: 0.9466\n",
      "[Class 4] Prec: 0.8094 | Rec: 0.8304 | F1: 0.8198 | GM: 0.8901\n",
      "Confusion Matrix:\n",
      "[[ 5966   339   127    17   121]\n",
      " [  293  1146   472     6   587]\n",
      " [   68   277 13685   348   587]\n",
      " [    6     0   388  3877     3]\n",
      " [   87   386   652     1  5512]]\n"
     ]
    }
   ],
   "source": [
    "#p7_2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ==== Load and Normalize Data ====\n",
    "df = pd.read_csv(\"pruned_dataset.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=49)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "    # === Build and Prune Model ===\n",
    "    model_unpruned = FinalNetwork(C=8, num_classes=num_classes, layers=7, genotype=searched_genotype).to(device)\n",
    "    total_params_before = sum(p.numel() for p in model_unpruned.parameters())\n",
    "    print(f\"[INFO] Total parameters BEFORE pruning: {total_params_before:,}\")\n",
    "\n",
    "    model = prune_model_entropy(model_unpruned, prune_ratio=0.5)\n",
    "    nonzero_params_after = sum((p != 0).sum().item() for p in model.parameters())\n",
    "    zero_params = total_params_before - nonzero_params_after\n",
    "    pruned_ratio = 100 * zero_params / total_params_before\n",
    "    print(f\"[INFO] Non-zero parameters AFTER pruning: {nonzero_params_after:,}\")\n",
    "    print(f\"[INFO] Pruned parameters: {zero_params:,} ({pruned_ratio:.2f}%)\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0055)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Dataloader\n",
    "    X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "    X_val, y_val = X_all[val_idx], y_all[val_idx]\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "    no_improve_counter = 0  # ← EARLY STOPPING COUNTER\n",
    "\n",
    "    for epoch in range(50):  # Max epochs\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            no_improve_counter = 0  # reset counter\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(\n",
    "                np.array(val_true), np.array(val_pred), num_classes\n",
    "            )\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "        else:\n",
    "            no_improve_counter += 1\n",
    "            if no_improve_counter >= 15:\n",
    "                print(f\"[Early Stopping] No improvement in 20 consecutive epochs. Stopping at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe3784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[INFO] Total parameters BEFORE pruning: 94,813\n",
      "[INFO] Non-zero parameters AFTER pruning: 47,889\n",
      "[INFO] Pruned parameters: 46,924 (49.49%)\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5657 | Train Acc: 0.7915 | Val Loss: 0.4886 | Val Acc: 0.8181\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4837 | Train Acc: 0.8217 | Val Loss: 0.5204 | Val Acc: 0.7990\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4581 | Train Acc: 0.8326 | Val Loss: 0.4442 | Val Acc: 0.8499\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4487 | Train Acc: 0.8348 | Val Loss: 0.5055 | Val Acc: 0.8069\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4393 | Train Acc: 0.8388 | Val Loss: 0.4291 | Val Acc: 0.8554\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4318 | Train Acc: 0.8419 | Val Loss: 0.4160 | Val Acc: 0.8550\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.4264 | Train Acc: 0.8433 | Val Loss: 0.4008 | Val Acc: 0.8505\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.4211 | Train Acc: 0.8455 | Val Loss: 0.3976 | Val Acc: 0.8532\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.4134 | Train Acc: 0.8461 | Val Loss: 0.4130 | Val Acc: 0.8525\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.4120 | Train Acc: 0.8491 | Val Loss: 0.4150 | Val Acc: 0.8499\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.4032 | Train Acc: 0.8525 | Val Loss: 0.3990 | Val Acc: 0.8594\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3989 | Train Acc: 0.8520 | Val Loss: 0.4219 | Val Acc: 0.8510\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3988 | Train Acc: 0.8521 | Val Loss: 0.3754 | Val Acc: 0.8627\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3914 | Train Acc: 0.8558 | Val Loss: 0.4145 | Val Acc: 0.8554\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3913 | Train Acc: 0.8558 | Val Loss: 0.3845 | Val Acc: 0.8634\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3874 | Train Acc: 0.8580 | Val Loss: 0.3877 | Val Acc: 0.8582\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3819 | Train Acc: 0.8599 | Val Loss: 0.4978 | Val Acc: 0.8216\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3784 | Train Acc: 0.8579 | Val Loss: 0.3880 | Val Acc: 0.8617\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3750 | Train Acc: 0.8602 | Val Loss: 0.3767 | Val Acc: 0.8677\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3723 | Train Acc: 0.8615 | Val Loss: 0.3928 | Val Acc: 0.8565\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3705 | Train Acc: 0.8633 | Val Loss: 0.3962 | Val Acc: 0.8560\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.3652 | Train Acc: 0.8657 | Val Loss: 0.3984 | Val Acc: 0.8570\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.3609 | Train Acc: 0.8649 | Val Loss: 0.4073 | Val Acc: 0.8580\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.3622 | Train Acc: 0.8623 | Val Loss: 0.4806 | Val Acc: 0.8335\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.3508 | Train Acc: 0.8686 | Val Loss: 0.3911 | Val Acc: 0.8554\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.3473 | Train Acc: 0.8698 | Val Loss: 0.3838 | Val Acc: 0.8620\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.3426 | Train Acc: 0.8714 | Val Loss: 0.4102 | Val Acc: 0.8479\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.3452 | Train Acc: 0.8702 | Val Loss: 0.4121 | Val Acc: 0.8454\n",
      "[Fold 1 | Epoch 29] Train Loss: 0.3356 | Train Acc: 0.8735 | Val Loss: 0.4102 | Val Acc: 0.8548\n",
      "[Fold 1 | Epoch 30] Train Loss: 0.3312 | Train Acc: 0.8774 | Val Loss: 0.4233 | Val Acc: 0.8497\n",
      "[Fold 1 | Epoch 31] Train Loss: 0.3285 | Train Acc: 0.8760 | Val Loss: 0.4245 | Val Acc: 0.8442\n",
      "[Fold 1 | Epoch 32] Train Loss: 0.3216 | Train Acc: 0.8808 | Val Loss: 0.4501 | Val Acc: 0.8435\n",
      "[Fold 1 | Epoch 33] Train Loss: 0.3200 | Train Acc: 0.8780 | Val Loss: 0.4266 | Val Acc: 0.8514\n",
      "[Fold 1 | Epoch 34] Train Loss: 0.3136 | Train Acc: 0.8830 | Val Loss: 0.4704 | Val Acc: 0.8421\n",
      "[Early Stopping] No improvement in 15 consecutive epochs. Stopping at epoch 34.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 19\n",
      "ACC: 0.8677 | MF1: 0.8127 | G-Mean: 0.8744\n",
      "[Class 0] Prec: 0.9456 | Rec: 0.9029 | F1: 0.9237 | GM: 0.9444\n",
      "[Class 1] Prec: 0.5340 | Rec: 0.4527 | F1: 0.4900 | GM: 0.6628\n",
      "[Class 2] Prec: 0.8928 | Rec: 0.9204 | F1: 0.9064 | GM: 0.9192\n",
      "[Class 3] Prec: 0.9296 | Rec: 0.9230 | F1: 0.9263 | GM: 0.9561\n",
      "[Class 4] Prec: 0.8033 | Rec: 0.8317 | F1: 0.8173 | GM: 0.8894\n",
      "\n",
      "===== Fold 2 =====\n",
      "[INFO] Total parameters BEFORE pruning: 94,813\n",
      "[INFO] Non-zero parameters AFTER pruning: 47,889\n",
      "[INFO] Pruned parameters: 46,924 (49.49%)\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5485 | Train Acc: 0.7988 | Val Loss: 0.5124 | Val Acc: 0.8030\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4733 | Train Acc: 0.8259 | Val Loss: 0.6852 | Val Acc: 0.7423\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4496 | Train Acc: 0.8357 | Val Loss: 0.4056 | Val Acc: 0.8502\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4400 | Train Acc: 0.8381 | Val Loss: 0.4670 | Val Acc: 0.8278\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4323 | Train Acc: 0.8400 | Val Loss: 0.4334 | Val Acc: 0.8413\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4247 | Train Acc: 0.8457 | Val Loss: 0.4359 | Val Acc: 0.8378\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4205 | Train Acc: 0.8469 | Val Loss: 0.4377 | Val Acc: 0.8382\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.4144 | Train Acc: 0.8477 | Val Loss: 0.3974 | Val Acc: 0.8545\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.4071 | Train Acc: 0.8504 | Val Loss: 0.4666 | Val Acc: 0.8265\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.4044 | Train Acc: 0.8514 | Val Loss: 0.4330 | Val Acc: 0.8462\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3946 | Train Acc: 0.8563 | Val Loss: 0.4155 | Val Acc: 0.8436\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3943 | Train Acc: 0.8564 | Val Loss: 0.4113 | Val Acc: 0.8505\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3887 | Train Acc: 0.8584 | Val Loss: 0.4321 | Val Acc: 0.8505\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3891 | Train Acc: 0.8554 | Val Loss: 0.3894 | Val Acc: 0.8584\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3870 | Train Acc: 0.8566 | Val Loss: 0.4362 | Val Acc: 0.8403\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3764 | Train Acc: 0.8608 | Val Loss: 0.4325 | Val Acc: 0.8385\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3760 | Train Acc: 0.8611 | Val Loss: 0.3974 | Val Acc: 0.8574\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3760 | Train Acc: 0.8587 | Val Loss: 0.3928 | Val Acc: 0.8612\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3664 | Train Acc: 0.8657 | Val Loss: 0.3755 | Val Acc: 0.8618\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3678 | Train Acc: 0.8650 | Val Loss: 0.4352 | Val Acc: 0.8383\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3569 | Train Acc: 0.8667 | Val Loss: 0.4082 | Val Acc: 0.8524\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.3579 | Train Acc: 0.8662 | Val Loss: 0.3747 | Val Acc: 0.8589\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.3580 | Train Acc: 0.8671 | Val Loss: 0.4224 | Val Acc: 0.8441\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.3527 | Train Acc: 0.8687 | Val Loss: 0.3930 | Val Acc: 0.8591\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.3467 | Train Acc: 0.8708 | Val Loss: 0.4883 | Val Acc: 0.8290\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.3406 | Train Acc: 0.8738 | Val Loss: 0.4353 | Val Acc: 0.8423\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.3357 | Train Acc: 0.8759 | Val Loss: 0.4354 | Val Acc: 0.8373\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.3328 | Train Acc: 0.8764 | Val Loss: 0.4334 | Val Acc: 0.8461\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.3288 | Train Acc: 0.8785 | Val Loss: 0.4260 | Val Acc: 0.8422\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.3212 | Train Acc: 0.8803 | Val Loss: 0.4289 | Val Acc: 0.8399\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.3189 | Train Acc: 0.8824 | Val Loss: 0.4133 | Val Acc: 0.8534\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.3157 | Train Acc: 0.8807 | Val Loss: 0.4121 | Val Acc: 0.8501\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.3070 | Train Acc: 0.8851 | Val Loss: 0.4504 | Val Acc: 0.8466\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.3011 | Train Acc: 0.8882 | Val Loss: 0.4266 | Val Acc: 0.8448\n",
      "[Early Stopping] No improvement in 15 consecutive epochs. Stopping at epoch 34.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 19\n",
      "ACC: 0.8618 | MF1: 0.8073 | G-Mean: 0.8736\n",
      "[Class 0] Prec: 0.9306 | Rec: 0.8990 | F1: 0.9145 | GM: 0.9409\n",
      "[Class 1] Prec: 0.5181 | Rec: 0.4508 | F1: 0.4821 | GM: 0.6603\n",
      "[Class 2] Prec: 0.9063 | Rec: 0.9045 | F1: 0.9054 | GM: 0.9177\n",
      "[Class 3] Prec: 0.9214 | Rec: 0.9245 | F1: 0.9230 | GM: 0.9560\n",
      "[Class 4] Prec: 0.7797 | Rec: 0.8457 | F1: 0.8114 | GM: 0.8933\n",
      "\n",
      "===== Fold 3 =====\n",
      "[INFO] Total parameters BEFORE pruning: 94,813\n",
      "[INFO] Non-zero parameters AFTER pruning: 47,889\n",
      "[INFO] Pruned parameters: 46,924 (49.49%)\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5584 | Train Acc: 0.7923 | Val Loss: 0.4471 | Val Acc: 0.8351\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4678 | Train Acc: 0.8290 | Val Loss: 0.4784 | Val Acc: 0.8272\n",
      "[Fold 3 | Epoch 3] Train Loss: 0.4465 | Train Acc: 0.8352 | Val Loss: 0.4242 | Val Acc: 0.8484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3 | Epoch 4] Train Loss: 0.4388 | Train Acc: 0.8380 | Val Loss: 0.4121 | Val Acc: 0.8512\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4243 | Train Acc: 0.8438 | Val Loss: 0.5080 | Val Acc: 0.8139\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4175 | Train Acc: 0.8468 | Val Loss: 0.4012 | Val Acc: 0.8484\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4105 | Train Acc: 0.8460 | Val Loss: 0.4039 | Val Acc: 0.8449\n",
      "[Fold 3 | Epoch 8] Train Loss: 0.4059 | Train Acc: 0.8510 | Val Loss: 0.4460 | Val Acc: 0.8335\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.4049 | Train Acc: 0.8497 | Val Loss: 0.4458 | Val Acc: 0.8474\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.3966 | Train Acc: 0.8527 | Val Loss: 0.4818 | Val Acc: 0.8300\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3919 | Train Acc: 0.8543 | Val Loss: 0.4124 | Val Acc: 0.8471\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3887 | Train Acc: 0.8549 | Val Loss: 0.4202 | Val Acc: 0.8433\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3855 | Train Acc: 0.8574 | Val Loss: 0.3982 | Val Acc: 0.8565\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3833 | Train Acc: 0.8570 | Val Loss: 0.4218 | Val Acc: 0.8474\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3812 | Train Acc: 0.8598 | Val Loss: 0.4053 | Val Acc: 0.8525\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3750 | Train Acc: 0.8607 | Val Loss: 0.3870 | Val Acc: 0.8574\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3705 | Train Acc: 0.8630 | Val Loss: 0.3948 | Val Acc: 0.8532\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3686 | Train Acc: 0.8602 | Val Loss: 0.3841 | Val Acc: 0.8588\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3596 | Train Acc: 0.8677 | Val Loss: 0.4186 | Val Acc: 0.8452\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.3561 | Train Acc: 0.8668 | Val Loss: 0.4131 | Val Acc: 0.8459\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.3498 | Train Acc: 0.8685 | Val Loss: 0.4418 | Val Acc: 0.8472\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.3478 | Train Acc: 0.8703 | Val Loss: 0.3989 | Val Acc: 0.8542\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.3507 | Train Acc: 0.8685 | Val Loss: 0.3908 | Val Acc: 0.8608\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.3454 | Train Acc: 0.8698 | Val Loss: 0.4216 | Val Acc: 0.8413\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.3382 | Train Acc: 0.8713 | Val Loss: 0.4745 | Val Acc: 0.8290\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.3349 | Train Acc: 0.8754 | Val Loss: 0.4301 | Val Acc: 0.8443\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.3307 | Train Acc: 0.8755 | Val Loss: 0.4090 | Val Acc: 0.8534\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.3257 | Train Acc: 0.8786 | Val Loss: 0.4646 | Val Acc: 0.8325\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.3188 | Train Acc: 0.8802 | Val Loss: 0.4370 | Val Acc: 0.8369\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.3126 | Train Acc: 0.8837 | Val Loss: 0.4380 | Val Acc: 0.8536\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.3117 | Train Acc: 0.8815 | Val Loss: 0.3954 | Val Acc: 0.8592\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.3034 | Train Acc: 0.8845 | Val Loss: 0.5301 | Val Acc: 0.8245\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.3046 | Train Acc: 0.8841 | Val Loss: 0.5098 | Val Acc: 0.8279\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.2971 | Train Acc: 0.8880 | Val Loss: 0.5034 | Val Acc: 0.8126\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.2855 | Train Acc: 0.8935 | Val Loss: 0.4157 | Val Acc: 0.8486\n",
      "[Fold 3 | Epoch 36] Train Loss: 0.2874 | Train Acc: 0.8917 | Val Loss: 0.4354 | Val Acc: 0.8413\n",
      "[Fold 3 | Epoch 37] Train Loss: 0.2827 | Train Acc: 0.8935 | Val Loss: 0.4319 | Val Acc: 0.8471\n",
      "[Fold 3 | Epoch 38] Train Loss: 0.2721 | Train Acc: 0.8971 | Val Loss: 0.4298 | Val Acc: 0.8538\n",
      "[Early Stopping] No improvement in 15 consecutive epochs. Stopping at epoch 38.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 23\n",
      "ACC: 0.8608 | MF1: 0.7943 | G-Mean: 0.8589\n",
      "[Class 0] Prec: 0.8724 | Rec: 0.9383 | F1: 0.9041 | GM: 0.9532\n",
      "[Class 1] Prec: 0.6143 | Rec: 0.3359 | F1: 0.4343 | GM: 0.5747\n",
      "[Class 2] Prec: 0.9087 | Rec: 0.8996 | F1: 0.9042 | GM: 0.9157\n",
      "[Class 3] Prec: 0.9118 | Rec: 0.9073 | F1: 0.9095 | GM: 0.9470\n",
      "[Class 4] Prec: 0.7741 | Rec: 0.8701 | F1: 0.8193 | GM: 0.9041\n",
      "\n",
      "===== Fold 4 =====\n",
      "[INFO] Total parameters BEFORE pruning: 94,813\n",
      "[INFO] Non-zero parameters AFTER pruning: 47,889\n",
      "[INFO] Pruned parameters: 46,924 (49.49%)\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5927 | Train Acc: 0.7812 | Val Loss: 0.5776 | Val Acc: 0.7845\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4814 | Train Acc: 0.8236 | Val Loss: 0.4585 | Val Acc: 0.8378\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4546 | Train Acc: 0.8332 | Val Loss: 0.4329 | Val Acc: 0.8379\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4442 | Train Acc: 0.8362 | Val Loss: 0.4942 | Val Acc: 0.8106\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4349 | Train Acc: 0.8390 | Val Loss: 0.5211 | Val Acc: 0.8084\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4242 | Train Acc: 0.8437 | Val Loss: 0.4015 | Val Acc: 0.8577\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.4201 | Train Acc: 0.8436 | Val Loss: 0.4054 | Val Acc: 0.8502\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.4151 | Train Acc: 0.8450 | Val Loss: 0.3960 | Val Acc: 0.8618\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.4055 | Train Acc: 0.8486 | Val Loss: 0.4028 | Val Acc: 0.8545\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.4008 | Train Acc: 0.8513 | Val Loss: 0.3999 | Val Acc: 0.8496\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.3975 | Train Acc: 0.8518 | Val Loss: 0.4253 | Val Acc: 0.8396\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3949 | Train Acc: 0.8523 | Val Loss: 0.4375 | Val Acc: 0.8389\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3929 | Train Acc: 0.8532 | Val Loss: 0.4389 | Val Acc: 0.8351\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3895 | Train Acc: 0.8555 | Val Loss: 0.3978 | Val Acc: 0.8567\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3849 | Train Acc: 0.8549 | Val Loss: 0.4126 | Val Acc: 0.8456\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3788 | Train Acc: 0.8574 | Val Loss: 0.4519 | Val Acc: 0.8305\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3761 | Train Acc: 0.8594 | Val Loss: 0.4088 | Val Acc: 0.8494\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3722 | Train Acc: 0.8625 | Val Loss: 0.3995 | Val Acc: 0.8488\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3667 | Train Acc: 0.8628 | Val Loss: 0.3973 | Val Acc: 0.8522\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3627 | Train Acc: 0.8628 | Val Loss: 0.4168 | Val Acc: 0.8552\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3588 | Train Acc: 0.8668 | Val Loss: 0.3883 | Val Acc: 0.8597\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.3602 | Train Acc: 0.8632 | Val Loss: 0.4102 | Val Acc: 0.8465\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.3602 | Train Acc: 0.8657 | Val Loss: 0.3858 | Val Acc: 0.8591\n",
      "[Early Stopping] No improvement in 15 consecutive epochs. Stopping at epoch 23.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 8\n",
      "ACC: 0.8618 | MF1: 0.7926 | G-Mean: 0.8581\n",
      "[Class 0] Prec: 0.9215 | Rec: 0.9081 | F1: 0.9148 | GM: 0.9444\n",
      "[Class 1] Prec: 0.5500 | Rec: 0.3430 | F1: 0.4225 | GM: 0.5796\n",
      "[Class 2] Prec: 0.8955 | Rec: 0.9126 | F1: 0.9040 | GM: 0.9157\n",
      "[Class 3] Prec: 0.8926 | Rec: 0.9390 | F1: 0.9152 | GM: 0.9610\n",
      "[Class 4] Prec: 0.7787 | Rec: 0.8364 | F1: 0.8065 | GM: 0.8895\n",
      "\n",
      "===== Fold 5 =====\n",
      "[INFO] Total parameters BEFORE pruning: 94,813\n",
      "[INFO] Non-zero parameters AFTER pruning: 47,889\n",
      "[INFO] Pruned parameters: 46,924 (49.49%)\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.5877 | Train Acc: 0.7826 | Val Loss: 0.6288 | Val Acc: 0.7825\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4914 | Train Acc: 0.8213 | Val Loss: 0.5557 | Val Acc: 0.8227\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4652 | Train Acc: 0.8307 | Val Loss: 0.5110 | Val Acc: 0.8130\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4492 | Train Acc: 0.8371 | Val Loss: 0.4682 | Val Acc: 0.8298\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4385 | Train Acc: 0.8412 | Val Loss: 0.4047 | Val Acc: 0.8538\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4309 | Train Acc: 0.8439 | Val Loss: 0.4966 | Val Acc: 0.8056\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.4187 | Train Acc: 0.8480 | Val Loss: 0.4392 | Val Acc: 0.8332\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.4149 | Train Acc: 0.8481 | Val Loss: 0.4036 | Val Acc: 0.8422\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.4114 | Train Acc: 0.8502 | Val Loss: 0.4452 | Val Acc: 0.8371\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.4075 | Train Acc: 0.8529 | Val Loss: 0.4536 | Val Acc: 0.8368\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.4018 | Train Acc: 0.8533 | Val Loss: 0.4064 | Val Acc: 0.8408\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3995 | Train Acc: 0.8514 | Val Loss: 0.4093 | Val Acc: 0.8476\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3938 | Train Acc: 0.8550 | Val Loss: 0.4420 | Val Acc: 0.8365\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3904 | Train Acc: 0.8561 | Val Loss: 0.3671 | Val Acc: 0.8601\n",
      "[Fold 5 | Epoch 15] Train Loss: 0.3908 | Train Acc: 0.8546 | Val Loss: 0.4652 | Val Acc: 0.8249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 16] Train Loss: 0.3845 | Train Acc: 0.8594 | Val Loss: 0.4278 | Val Acc: 0.8426\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3866 | Train Acc: 0.8573 | Val Loss: 0.4106 | Val Acc: 0.8426\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3806 | Train Acc: 0.8593 | Val Loss: 0.3871 | Val Acc: 0.8524\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3745 | Train Acc: 0.8587 | Val Loss: 0.3759 | Val Acc: 0.8597\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3706 | Train Acc: 0.8638 | Val Loss: 0.4185 | Val Acc: 0.8454\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.3626 | Train Acc: 0.8636 | Val Loss: 0.4270 | Val Acc: 0.8512\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.3640 | Train Acc: 0.8658 | Val Loss: 0.4384 | Val Acc: 0.8386\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.3583 | Train Acc: 0.8689 | Val Loss: 0.4064 | Val Acc: 0.8471\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.3599 | Train Acc: 0.8678 | Val Loss: 0.4138 | Val Acc: 0.8482\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.3504 | Train Acc: 0.8700 | Val Loss: 0.3692 | Val Acc: 0.8621\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.3474 | Train Acc: 0.8720 | Val Loss: 0.4132 | Val Acc: 0.8492\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.3464 | Train Acc: 0.8716 | Val Loss: 0.3976 | Val Acc: 0.8458\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.3489 | Train Acc: 0.8697 | Val Loss: 0.4394 | Val Acc: 0.8456\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.3394 | Train Acc: 0.8734 | Val Loss: 0.4474 | Val Acc: 0.8389\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.3348 | Train Acc: 0.8761 | Val Loss: 0.3780 | Val Acc: 0.8629\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.3302 | Train Acc: 0.8779 | Val Loss: 0.3758 | Val Acc: 0.8617\n",
      "[Fold 5 | Epoch 32] Train Loss: 0.3296 | Train Acc: 0.8792 | Val Loss: 0.4069 | Val Acc: 0.8411\n",
      "[Fold 5 | Epoch 33] Train Loss: 0.3272 | Train Acc: 0.8776 | Val Loss: 0.4411 | Val Acc: 0.8415\n",
      "[Fold 5 | Epoch 34] Train Loss: 0.3161 | Train Acc: 0.8833 | Val Loss: 0.4132 | Val Acc: 0.8557\n",
      "[Fold 5 | Epoch 35] Train Loss: 0.3187 | Train Acc: 0.8815 | Val Loss: 0.3877 | Val Acc: 0.8524\n",
      "[Fold 5 | Epoch 36] Train Loss: 0.3184 | Train Acc: 0.8815 | Val Loss: 0.3946 | Val Acc: 0.8526\n",
      "[Fold 5 | Epoch 37] Train Loss: 0.3066 | Train Acc: 0.8862 | Val Loss: 0.4199 | Val Acc: 0.8569\n",
      "[Fold 5 | Epoch 38] Train Loss: 0.3073 | Train Acc: 0.8842 | Val Loss: 0.3989 | Val Acc: 0.8521\n",
      "[Fold 5 | Epoch 39] Train Loss: 0.3004 | Train Acc: 0.8895 | Val Loss: 0.4649 | Val Acc: 0.8438\n",
      "[Fold 5 | Epoch 40] Train Loss: 0.2993 | Train Acc: 0.8893 | Val Loss: 0.4744 | Val Acc: 0.8486\n",
      "[Fold 5 | Epoch 41] Train Loss: 0.2945 | Train Acc: 0.8907 | Val Loss: 0.4250 | Val Acc: 0.8554\n",
      "[Fold 5 | Epoch 42] Train Loss: 0.2919 | Train Acc: 0.8876 | Val Loss: 0.4867 | Val Acc: 0.8465\n",
      "[Fold 5 | Epoch 43] Train Loss: 0.2842 | Train Acc: 0.8950 | Val Loss: 0.4242 | Val Acc: 0.8415\n",
      "[Fold 5 | Epoch 44] Train Loss: 0.2796 | Train Acc: 0.8955 | Val Loss: 0.4252 | Val Acc: 0.8515\n",
      "[Fold 5 | Epoch 45] Train Loss: 0.2812 | Train Acc: 0.8940 | Val Loss: 0.4286 | Val Acc: 0.8545\n",
      "[Early Stopping] No improvement in 15 consecutive epochs. Stopping at epoch 45.\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 30\n",
      "ACC: 0.8629 | MF1: 0.8084 | G-Mean: 0.8769\n",
      "[Class 0] Prec: 0.9233 | Rec: 0.9254 | F1: 0.9244 | GM: 0.9533\n",
      "[Class 1] Prec: 0.4722 | Rec: 0.4932 | F1: 0.4825 | GM: 0.6867\n",
      "[Class 2] Prec: 0.9046 | Rec: 0.9154 | F1: 0.9100 | GM: 0.9213\n",
      "[Class 3] Prec: 0.9158 | Rec: 0.9092 | F1: 0.9125 | GM: 0.9481\n",
      "[Class 4] Prec: 0.8311 | Rec: 0.7954 | F1: 0.8128 | GM: 0.8751\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8630 | MF1: 0.8036 | G-Mean: 0.8690\n",
      "[Class 0] Prec: 0.9177 | Rec: 0.9148 | F1: 0.9162 | GM: 0.9473\n",
      "[Class 1] Prec: 0.5274 | Rec: 0.4157 | F1: 0.4649 | GM: 0.6354\n",
      "[Class 2] Prec: 0.9015 | Rec: 0.9105 | F1: 0.9060 | GM: 0.9180\n",
      "[Class 3] Prec: 0.9139 | Rec: 0.9209 | F1: 0.9174 | GM: 0.9538\n",
      "[Class 4] Prec: 0.7922 | Rec: 0.8361 | F1: 0.8135 | GM: 0.8906\n",
      "Confusion Matrix:\n",
      "[[ 6010   317   111     8   124]\n",
      " [  351  1041   438     6   668]\n",
      " [   93   230 13626   354   662]\n",
      " [    7     0   329  3936     2]\n",
      " [   88   386   611     3  5550]]\n"
     ]
    }
   ],
   "source": [
    "#p9_2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ==== Load and Normalize Data ====\n",
    "df = pd.read_csv(\"pruned_dataset.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "    # === Build and Prune Model ===\n",
    "    model_unpruned = FinalNetwork(C=8, num_classes=num_classes, layers=9, genotype=searched_genotype).to(device)\n",
    "    total_params_before = sum(p.numel() for p in model_unpruned.parameters())\n",
    "    print(f\"[INFO] Total parameters BEFORE pruning: {total_params_before:,}\")\n",
    "\n",
    "    model = prune_model_entropy(model_unpruned, prune_ratio=0.5)\n",
    "    nonzero_params_after = sum((p != 0).sum().item() for p in model.parameters())\n",
    "    zero_params = total_params_before - nonzero_params_after\n",
    "    pruned_ratio = 100 * zero_params / total_params_before\n",
    "    print(f\"[INFO] Non-zero parameters AFTER pruning: {nonzero_params_after:,}\")\n",
    "    print(f\"[INFO] Pruned parameters: {zero_params:,} ({pruned_ratio:.2f}%)\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0055)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Dataloader\n",
    "    X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "    X_val, y_val = X_all[val_idx], y_all[val_idx]\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "    no_improve_counter = 0  # ← EARLY STOPPING COUNTER\n",
    "\n",
    "    for epoch in range(50):  # Max epochs\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            no_improve_counter = 0  # reset counter\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(\n",
    "                np.array(val_true), np.array(val_pred), num_classes\n",
    "            )\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "        else:\n",
    "            no_improve_counter += 1\n",
    "            if no_improve_counter >= 15:\n",
    "                print(f\"[Early Stopping] No improvement in 15 consecutive epochs. Stopping at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25de4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
