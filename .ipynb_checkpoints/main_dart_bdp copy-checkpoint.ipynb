{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239ebdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "from data_loader_darts import get_dataloaders_simple\n",
    "# from darts_search_bdp import train_darts_search_bdp\n",
    "from darts_search_bdp import train_darts_search_bdp\n",
    "from model_build import FinalNetwork\n",
    "from cell_plot import plot_cell\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c286838",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_final_model(model, train_loader, val_loader, device, epochs=25):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.025, momentum=0.9, weight_decay=3e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    best_acc = 0\n",
    "    train_loss_list, val_loss_list, train_acc_list, val_acc_list = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            x = x.squeeze(-1)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "                val_total += y.size(0)\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        val_loss_list.append(val_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_final_model_78.pt\")\n",
    "\n",
    "        scheduler.step()\n",
    "        print(f\"[Final Train Epoch {epoch+1}] Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss_list, label='Train Loss')\n",
    "    plt.plot(val_loss_list, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss Curve')\n",
    "    plt.savefig('final_loss.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc_list, label='Train Acc')\n",
    "    plt.plot(val_acc_list, label='Val Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.savefig('final_accuracy.png')\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device).squeeze(-1)\n",
    "            logits = model(x)\n",
    "            pred = logits.argmax(dim=1).cpu().numpy()\n",
    "            y_true.extend(y.numpy())\n",
    "            y_pred.extend(pred)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"\\nConfusion Matrix on Validation:\")\n",
    "    print(cm)\n",
    "    pd.DataFrame(cm).to_csv(\"confusion_matrix78.csv\", index=False)\n",
    "    print(\"[\\u2713] Saved confusion matrix to confusion_matrix.csv\")\n",
    "\n",
    "    pd.DataFrame({\"y_true\": y_true, \"y_pred\": y_pred}).to_csv(\"val_predictions78.csv\", index=False)\n",
    "    print(\"[\\u2713] Saved predictions to val_predictions.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48d0748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading 60/40 split data...\n",
      "[DEBUG] Loaded ./PSG/SC4001E0.npz → 841 samples\n",
      "[DEBUG] Loaded ./PSG/SC4002E0.npz → 1127 samples\n",
      "[DEBUG] Loaded ./PSG/SC4011E0.npz → 1103 samples\n",
      "[DEBUG] Loaded ./PSG/SC4012E0.npz → 1186 samples\n",
      "[DEBUG] Loaded ./PSG/SC4021E0.npz → 1025 samples\n",
      "[DEBUG] Loaded ./PSG/SC4022E0.npz → 1009 samples\n",
      "[DEBUG] Loaded ./PSG/SC4031E0.npz → 952 samples\n",
      "[DEBUG] Loaded ./PSG/SC4032E0.npz → 911 samples\n",
      "[DEBUG] Loaded ./PSG/SC4041E0.npz → 1235 samples\n",
      "[DEBUG] Loaded ./PSG/SC4042E0.npz → 1200 samples\n",
      "[DEBUG] Loaded ./PSG/SC4051E0.npz → 672 samples\n",
      "[DEBUG] Loaded ./PSG/SC4052E0.npz → 1246 samples\n",
      "[DEBUG] Loaded ./PSG/SC4061E0.npz → 843 samples\n",
      "[DEBUG] Loaded ./PSG/SC4062E0.npz → 1016 samples\n",
      "[DEBUG] Loaded ./PSG/SC4071E0.npz → 976 samples\n",
      "[DEBUG] Loaded ./PSG/SC4072E0.npz → 1273 samples\n",
      "[DEBUG] Loaded ./PSG/SC4081E0.npz → 1134 samples\n",
      "[DEBUG] Loaded ./PSG/SC4082E0.npz → 1054 samples\n",
      "[DEBUG] Loaded ./PSG/SC4091E0.npz → 1132 samples\n",
      "[DEBUG] Loaded ./PSG/SC4092E0.npz → 1105 samples\n",
      "[DEBUG] Loaded ./PSG/SC4101E0.npz → 1104 samples\n",
      "[DEBUG] Loaded ./PSG/SC4102E0.npz → 1092 samples\n",
      "[DEBUG] Loaded ./PSG/SC4111E0.npz → 928 samples\n",
      "[DEBUG] Loaded ./PSG/SC4112E0.npz → 802 samples\n",
      "[DEBUG] Loaded ./PSG/SC4121E0.npz → 1052 samples\n",
      "[DEBUG] Loaded ./PSG/SC4122E0.npz → 977 samples\n",
      "[DEBUG] Loaded ./PSG/SC4131E0.npz → 1028 samples\n",
      "[DEBUG] Loaded ./PSG/SC4141E0.npz → 1004 samples\n",
      "[DEBUG] Loaded ./PSG/SC4142E0.npz → 952 samples\n",
      "[DEBUG] Loaded ./PSG/SC4151E0.npz → 952 samples\n",
      "[DEBUG] Loaded ./PSG/SC4152E0.npz → 1762 samples\n",
      "[DEBUG] Loaded ./PSG/SC4161E0.npz → 1144 samples\n",
      "[DEBUG] Loaded ./PSG/SC4162E0.npz → 1003 samples\n",
      "[DEBUG] Loaded ./PSG/SC4171E0.npz → 1002 samples\n",
      "[DEBUG] Loaded ./PSG/SC4172E0.npz → 1773 samples\n",
      "[DEBUG] Loaded ./PSG/SC4181E0.npz → 964 samples\n",
      "[DEBUG] Loaded ./PSG/SC4182E0.npz → 920 samples\n",
      "[DEBUG] Loaded ./PSG/SC4191E0.npz → 1535 samples\n",
      "[DEBUG] Loaded ./PSG/SC4192E0.npz → 1274 samples\n",
      "[INFO] DARTS will run on 25384 train samples and 16924 val samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Set random seed\n",
    "set_seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 2. Load data\n",
    "print(\"[INFO] Loading 60/40 split data...\")\n",
    "train_loader, val_loader, num_classes = get_dataloaders_simple(batch_size=32)\n",
    "print(f\"[INFO] DARTS will run on {len(train_loader.dataset.y)} train samples and {len(val_loader.dataset.y)} val samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d3954e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running DARTS search with BDP...\n",
      "\n",
      "[Epoch 1/30] Starting...\n",
      "[Epoch 1] Train Loss: 0.7079 | Acc: 0.5730 || Val Loss: 0.8832 | Acc: 0.6766\n",
      "Precision: 0.6577 | Recall: 0.5815 | F1: 0.5482 | Time: 1667.62s\n",
      "[Checkpoint] New best model saved at epoch 1 with Val Acc = 0.6766\n",
      "\n",
      "[Epoch 2/30] Starting...\n",
      "[Epoch 2] Train Loss: 0.5939 | Acc: 0.6656 || Val Loss: 0.7753 | Acc: 0.7167\n",
      "Precision: 0.6569 | Recall: 0.5946 | F1: 0.5924 | Time: 1671.47s\n",
      "[Checkpoint] New best model saved at epoch 2 with Val Acc = 0.7167\n",
      "\n",
      "[Epoch 3/30] Starting...\n",
      "[Epoch 3] Train Loss: 0.5366 | Acc: 0.6961 || Val Loss: 0.8359 | Acc: 0.6872\n",
      "Precision: 0.6324 | Recall: 0.6301 | F1: 0.5802 | Time: 1653.25s\n",
      "\n",
      "[Epoch 4/30] Starting...\n",
      "[Epoch 4] Train Loss: 0.5081 | Acc: 0.7133 || Val Loss: 0.6896 | Acc: 0.7502\n",
      "Precision: 0.6949 | Recall: 0.6343 | F1: 0.6330 | Time: 1655.48s\n",
      "[Checkpoint] New best model saved at epoch 4 with Val Acc = 0.7502\n",
      "\n",
      "[Epoch 5/30] Starting...\n",
      "[Epoch 5] Train Loss: 0.4888 | Acc: 0.7260 || Val Loss: 0.8048 | Acc: 0.6925\n",
      "Precision: 0.6851 | Recall: 0.5739 | F1: 0.5841 | Time: 1653.34s\n",
      "[Annealable Pruning] Applied at Epoch 5 with T = 1.2218\n",
      "[Prune Epoch 5] Pruned 846 train, 846 val\n",
      "                     Remaining train: 24538 | val: 16078\n",
      "\n",
      "[Epoch 6/30] Starting...\n",
      "[Epoch 6] Train Loss: 0.4618 | Acc: 0.7365 || Val Loss: 0.6905 | Acc: 0.7433\n",
      "Precision: 0.5908 | Recall: 0.6394 | F1: 0.6125 | Time: 1578.22s\n",
      "\n",
      "[Epoch 7/30] Starting...\n",
      "[Epoch 7] Train Loss: 0.4287 | Acc: 0.7542 || Val Loss: 0.6715 | Acc: 0.7460\n",
      "Precision: 0.6342 | Recall: 0.6514 | F1: 0.6261 | Time: 1585.21s\n",
      "\n",
      "[Epoch 8/30] Starting...\n",
      "[Epoch 8] Train Loss: 0.4131 | Acc: 0.7612 || Val Loss: 0.6932 | Acc: 0.7431\n",
      "Precision: 0.6919 | Recall: 0.6747 | F1: 0.6755 | Time: 1566.42s\n",
      "\n",
      "[Epoch 9/30] Starting...\n",
      "[Epoch 9] Train Loss: 0.3953 | Acc: 0.7733 || Val Loss: 0.5954 | Acc: 0.7748\n",
      "Precision: 0.7853 | Recall: 0.6639 | F1: 0.6441 | Time: 1565.94s\n",
      "[Checkpoint] New best model saved at epoch 9 with Val Acc = 0.7748\n",
      "\n",
      "[Epoch 10/30] Starting...\n",
      "[Epoch 10] Train Loss: 0.3849 | Acc: 0.7831 || Val Loss: 0.6103 | Acc: 0.7662\n",
      "Precision: 0.7357 | Recall: 0.6613 | F1: 0.6687 | Time: 1567.76s\n",
      "[Annealable Pruning] Applied at Epoch 10 with T = 0.9454\n",
      "[Prune Epoch 10] Pruned 846 train, 846 val\n",
      "                     Remaining train: 23692 | val: 15349\n",
      "\n",
      "[Epoch 11/30] Starting...\n",
      "[Epoch 11] Train Loss: 0.3684 | Acc: 0.7855 || Val Loss: 0.5621 | Acc: 0.7857\n",
      "Precision: 0.7549 | Recall: 0.6912 | F1: 0.6883 | Time: 1498.31s\n",
      "[Checkpoint] New best model saved at epoch 11 with Val Acc = 0.7857\n",
      "\n",
      "[Epoch 12/30] Starting...\n",
      "[Epoch 12] Train Loss: 0.3517 | Acc: 0.7988 || Val Loss: 0.5276 | Acc: 0.8068\n",
      "Precision: 0.7539 | Recall: 0.7225 | F1: 0.7327 | Time: 1503.81s\n",
      "[Checkpoint] New best model saved at epoch 12 with Val Acc = 0.8068\n",
      "\n",
      "[Epoch 13/30] Starting...\n",
      "[Epoch 13] Train Loss: 0.3544 | Acc: 0.7981 || Val Loss: 0.5050 | Acc: 0.8161\n",
      "Precision: 0.7619 | Recall: 0.7240 | F1: 0.7292 | Time: 1501.10s\n",
      "[Checkpoint] New best model saved at epoch 13 with Val Acc = 0.8161\n",
      "\n",
      "[Epoch 14/30] Starting...\n",
      "[Epoch 14] Train Loss: 0.3429 | Acc: 0.8077 || Val Loss: 0.6184 | Acc: 0.7836\n",
      "Precision: 0.7334 | Recall: 0.6705 | F1: 0.6755 | Time: 1502.13s\n",
      "\n",
      "[Epoch 15/30] Starting...\n",
      "[Epoch 15] Train Loss: 0.3360 | Acc: 0.8092 || Val Loss: 0.5060 | Acc: 0.8111\n",
      "Precision: 0.7672 | Recall: 0.7257 | F1: 0.7231 | Time: 1498.30s\n",
      "[Annealable Pruning] Applied at Epoch 15 with T = 0.7315\n",
      "[Prune Epoch 15] Pruned 846 train, 846 val\n",
      "                     Remaining train: 22846 | val: 14695\n",
      "\n",
      "[Epoch 16/30] Starting...\n",
      "[Epoch 16] Train Loss: 0.3237 | Acc: 0.8112 || Val Loss: 0.4923 | Acc: 0.8204\n",
      "Precision: 0.7733 | Recall: 0.7365 | F1: 0.7511 | Time: 1455.57s\n",
      "[Checkpoint] New best model saved at epoch 16 with Val Acc = 0.8204\n",
      "\n",
      "[Epoch 17/30] Starting...\n",
      "[Epoch 17] Train Loss: 0.3174 | Acc: 0.8167 || Val Loss: 0.4922 | Acc: 0.8114\n",
      "Precision: 0.7962 | Recall: 0.7134 | F1: 0.7076 | Time: 1453.87s\n",
      "\n",
      "[Epoch 18/30] Starting...\n",
      "[Epoch 18] Train Loss: 0.3168 | Acc: 0.8170 || Val Loss: 0.4756 | Acc: 0.8258\n",
      "Precision: 0.7593 | Recall: 0.7623 | F1: 0.7578 | Time: 1456.24s\n",
      "[Checkpoint] New best model saved at epoch 18 with Val Acc = 0.8258\n",
      "\n",
      "[Epoch 19/30] Starting...\n",
      "[Epoch 19] Train Loss: 0.3096 | Acc: 0.8211 || Val Loss: 0.5013 | Acc: 0.8076\n",
      "Precision: 0.7821 | Recall: 0.7093 | F1: 0.7102 | Time: 1438.03s\n",
      "\n",
      "[Epoch 20/30] Starting...\n",
      "[Epoch 20] Train Loss: 0.3045 | Acc: 0.8274 || Val Loss: 0.5096 | Acc: 0.8050\n",
      "Precision: 0.7642 | Recall: 0.7614 | F1: 0.7577 | Time: 1440.75s\n",
      "[Annealable Pruning] Applied at Epoch 20 with T = 0.5660\n",
      "[Prune Epoch 20] Pruned 846 train, 846 val\n",
      "                     Remaining train: 22000 | val: 14118\n",
      "\n",
      "[Epoch 21/30] Starting...\n",
      "[Epoch 21] Train Loss: 0.3018 | Acc: 0.8295 || Val Loss: 0.4730 | Acc: 0.8332\n",
      "Precision: 0.7845 | Recall: 0.7518 | F1: 0.7552 | Time: 1380.80s\n",
      "[Checkpoint] New best model saved at epoch 21 with Val Acc = 0.8332\n",
      "\n",
      "[Epoch 22/30] Starting...\n",
      "[Epoch 22] Train Loss: 0.2988 | Acc: 0.8270 || Val Loss: 0.4524 | Acc: 0.8403\n",
      "Precision: 0.7835 | Recall: 0.7576 | F1: 0.7619 | Time: 1389.33s\n",
      "[Checkpoint] New best model saved at epoch 22 with Val Acc = 0.8403\n",
      "\n",
      "[Epoch 23/30] Starting...\n",
      "[Epoch 23] Train Loss: 0.2896 | Acc: 0.8348 || Val Loss: 0.4510 | Acc: 0.8410\n",
      "Precision: 0.7773 | Recall: 0.7570 | F1: 0.7563 | Time: 1382.85s\n",
      "[Checkpoint] New best model saved at epoch 23 with Val Acc = 0.8410\n",
      "\n",
      "[Epoch 24/30] Starting...\n",
      "[Epoch 24] Train Loss: 0.2918 | Acc: 0.8333 || Val Loss: 0.4624 | Acc: 0.8364\n",
      "Precision: 0.7899 | Recall: 0.7642 | F1: 0.7747 | Time: 1401.87s\n",
      "\n",
      "[Epoch 25/30] Starting...\n",
      "[Epoch 25] Train Loss: 0.2818 | Acc: 0.8384 || Val Loss: 0.4608 | Acc: 0.8418\n",
      "Precision: 0.7963 | Recall: 0.7706 | F1: 0.7822 | Time: 1396.85s\n",
      "[Checkpoint] New best model saved at epoch 25 with Val Acc = 0.8418\n",
      "\n",
      "[Epoch 26/30] Starting...\n",
      "[Epoch 26] Train Loss: 0.2789 | Acc: 0.8368 || Val Loss: 0.4592 | Acc: 0.8331\n",
      "Precision: 0.7733 | Recall: 0.7592 | F1: 0.7626 | Time: 1385.53s\n",
      "\n",
      "[Epoch 27/30] Starting...\n",
      "[Epoch 27] Train Loss: 0.2801 | Acc: 0.8430 || Val Loss: 0.4368 | Acc: 0.8469\n",
      "Precision: 0.7924 | Recall: 0.7773 | F1: 0.7824 | Time: 1401.57s\n",
      "[Checkpoint] New best model saved at epoch 27 with Val Acc = 0.8469\n",
      "\n",
      "[Epoch 28/30] Starting...\n",
      "[Epoch 28] Train Loss: 0.2750 | Acc: 0.8444 || Val Loss: 0.4383 | Acc: 0.8416\n",
      "Precision: 0.7829 | Recall: 0.7602 | F1: 0.7603 | Time: 1400.05s\n",
      "\n",
      "[Epoch 29/30] Starting...\n",
      "[Epoch 29] Train Loss: 0.2718 | Acc: 0.8441 || Val Loss: 0.4352 | Acc: 0.8464\n",
      "Precision: 0.7940 | Recall: 0.7698 | F1: 0.7751 | Time: 1382.68s\n",
      "\n",
      "[Epoch 30/30] Starting...\n",
      "[Epoch 30] Train Loss: 0.2662 | Acc: 0.8480 || Val Loss: 0.4377 | Acc: 0.8451\n",
      "Precision: 0.7890 | Recall: 0.7702 | F1: 0.7735 | Time: 1381.95s\n",
      "\n",
      "Best model saved to 'best_model20.pth' with Val Acc = 0.8469\n",
      "\n",
      "[INFO] Training metrics saved to 'search_metrics_log.csv'\n",
      "\n",
      "Final Searched Genotype:\n",
      " Genotype(normal=[('sep_conv_1x5', 0), ('sep_conv_1x5', 1), ('max_pool_3x3', 0), ('max_pool_3x3', 2), ('max_pool_3x3', 0), ('max_pool_3x3', 3), ('max_pool_3x3', 0), ('max_pool_3x3', 4), ('max_pool_3x3', 5), ('max_pool_3x3', 0)], normal_concat=[2, 3, 4], reduce=[('avg_pool_3x3', 1), ('avg_pool_3x3', 0), ('avg_pool_3x3', 1), ('max_pool_3x3', 2), ('avg_pool_3x3', 1), ('max_pool_3x3', 3), ('max_pool_3x3', 4), ('avg_pool_3x3', 1), ('max_pool_3x3', 5), ('max_pool_3x3', 4)], reduce_concat=[2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 3. Run DARTS search with pruning\n",
    "print(\"[INFO] Running DARTS search with BDP...\")\n",
    "searched_genotype, pruned_train_loader, pruned_val_loader = train_darts_search_bdp(\n",
    "    train_loader, val_loader, num_classes,\n",
    "    epochs=30, prune_every=5 , pt=0.05, pv=0.05,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13fd3c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pygraphviz in /home/work/.local/lib/python3.10/site-packages (1.14)\n",
      "\u001b[33mWARNING: Error parsing dependencies of devscripts: Invalid version: '2.22.1ubuntu1'\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "[INFO] Visualizing searched cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/Duc/NASEEG1_Final/NASEEG/SleepC/sleep_nas/cell_plot.py:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "!pip install pygraphviz\n",
    "\n",
    "# 4. Visualize searched cells-----------------------------------------\n",
    "print(\"[INFO] Visualizing searched cells...\")\n",
    "\n",
    "plot_cell(searched_genotype, 'normal')\n",
    "plot_cell(searched_genotype, 'reduce')\n",
    "\n",
    "# === Xuất biến searched_genotype ra file txt ===\n",
    "with open(\"searched_genotype_20.txt\", \"w\") as f:\n",
    "    f.write(str(searched_genotype))\n",
    "\n",
    "print(\"✅ Đã lưu searched_genotype vào 'searched_genotype.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774adc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running 5-Fold Cross Validation on pruned data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 5. Prepare data for cross-validation\n",
    "print(\"[INFO] Running 5-Fold Cross Validation on pruned data...\")\n",
    "\n",
    "# Gộp dữ liệu từ train và val\n",
    "X_all = torch.cat([pruned_train_loader.dataset.X, pruned_val_loader.dataset.X], dim=0)\n",
    "y_all = torch.cat([pruned_train_loader.dataset.y, pruned_val_loader.dataset.y], dim=0)\n",
    "\n",
    "# Tạo dataset\n",
    "dataset = TensorDataset(X_all, y_all)\n",
    "\n",
    "# === Xuất ra CSV ===\n",
    "# Nếu dùng GPU, chuyển về CPU\n",
    "if X_all.is_cuda:\n",
    "    X_all = X_all.cpu()\n",
    "    y_all = y_all.cpu()\n",
    "\n",
    "# Chuyển về numpy\n",
    "X_np = X_all.numpy()\n",
    "y_np = y_all.numpy().reshape(-1, 1)\n",
    "\n",
    "# Ghép X và y thành một mảng\n",
    "data_np = np.hstack((X_np, y_np))\n",
    "\n",
    "# Tạo DataFrame với cột feature_0, feature_1, ..., label\n",
    "num_features = X_np.shape[1]\n",
    "column_names = [f\"feature_{i}\" for i in range(num_features)] + [\"label\"]\n",
    "df = pd.DataFrame(data_np, columns=column_names)\n",
    "\n",
    "# Lưu file CSV\n",
    "df.to_csv(\"pruned_dataset.csv\", index=False)\n",
    "print(\"✅ Đã lưu dữ liệu vào 'pruned_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cfbe344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1/5 ==========\n",
      "[Fold 1 | Epoch 1] Train Acc: 0.7718 | Eval Acc: 0.8011\n",
      "[Fold 1 | Epoch 2] Train Acc: 0.8199 | Eval Acc: 0.8158\n",
      "[Fold 1 | Epoch 3] Train Acc: 0.8316 | Eval Acc: 0.8459\n",
      "[Fold 1 | Epoch 4] Train Acc: 0.8349 | Eval Acc: 0.7838\n",
      "[Fold 1 | Epoch 5] Train Acc: 0.8363 | Eval Acc: 0.8497\n",
      "[Fold 1 | Epoch 6] Train Acc: 0.8413 | Eval Acc: 0.8407\n",
      "[Fold 1 | Epoch 7] Train Acc: 0.8435 | Eval Acc: 0.8256\n",
      "[Fold 1 | Epoch 8] Train Acc: 0.8419 | Eval Acc: 0.8427\n",
      "[Fold 1 | Epoch 9] Train Acc: 0.8459 | Eval Acc: 0.8396\n",
      "[Fold 1 | Epoch 10] Train Acc: 0.8454 | Eval Acc: 0.8297\n",
      "[Fold 1 | Epoch 11] Train Acc: 0.8471 | Eval Acc: 0.8444\n",
      "[Fold 1 | Epoch 12] Train Acc: 0.8501 | Eval Acc: 0.8570\n",
      "[Fold 1 | Epoch 13] Train Acc: 0.8514 | Eval Acc: 0.8551\n",
      "[Fold 1 | Epoch 14] Train Acc: 0.8512 | Eval Acc: 0.8494\n",
      "[Fold 1 | Epoch 15] Train Acc: 0.8537 | Eval Acc: 0.8547\n",
      "[Fold 1 | Epoch 16] Train Acc: 0.8504 | Eval Acc: 0.8600\n",
      "[Fold 1 | Epoch 17] Train Acc: 0.8564 | Eval Acc: 0.8587\n",
      "[Fold 1 | Epoch 18] Train Acc: 0.8561 | Eval Acc: 0.8632\n",
      "[Fold 1 | Epoch 19] Train Acc: 0.8568 | Eval Acc: 0.8570\n",
      "[Fold 1 | Epoch 20] Train Acc: 0.8593 | Eval Acc: 0.8461\n",
      "[Fold 1 | Epoch 21] Train Acc: 0.8594 | Eval Acc: 0.8548\n",
      "[Fold 1 | Epoch 22] Train Acc: 0.8602 | Eval Acc: 0.8573\n",
      "[Fold 1 | Epoch 23] Train Acc: 0.8606 | Eval Acc: 0.8509\n",
      "[Fold 1 | Epoch 24] Train Acc: 0.8616 | Eval Acc: 0.8585\n",
      "[Fold 1 | Epoch 25] Train Acc: 0.8609 | Eval Acc: 0.8511\n",
      "[Fold 1 | Epoch 26] Train Acc: 0.8633 | Eval Acc: 0.8566\n",
      "[Fold 1 | Epoch 27] Train Acc: 0.8644 | Eval Acc: 0.8570\n",
      "[Fold 1 | Epoch 28] Train Acc: 0.8671 | Eval Acc: 0.8476\n",
      "[Fold 1 | Epoch 29] Train Acc: 0.8668 | Eval Acc: 0.8412\n",
      "[Fold 1 | Epoch 30] Train Acc: 0.8701 | Eval Acc: 0.8509\n",
      "[Fold 1 | Epoch 31] Train Acc: 0.8698 | Eval Acc: 0.8477\n",
      "[Fold 1 | Epoch 32] Train Acc: 0.8684 | Eval Acc: 0.8534\n",
      "[Fold 1 | Epoch 33] Train Acc: 0.8720 | Eval Acc: 0.8488\n",
      "[EarlyStopping] No improvement in 15 epochs. Stopping at epoch 33.\n",
      "[Fold 1] Best Val Acc: 0.8632 at epoch 18\n",
      "\n",
      "========== Fold 2/5 ==========\n",
      "[Fold 2 | Epoch 1] Train Acc: 0.7833 | Eval Acc: 0.7908\n",
      "[Fold 2 | Epoch 2] Train Acc: 0.8230 | Eval Acc: 0.7914\n",
      "[Fold 2 | Epoch 3] Train Acc: 0.8289 | Eval Acc: 0.8380\n",
      "[Fold 2 | Epoch 4] Train Acc: 0.8339 | Eval Acc: 0.7993\n",
      "[Fold 2 | Epoch 5] Train Acc: 0.8356 | Eval Acc: 0.8432\n",
      "[Fold 2 | Epoch 6] Train Acc: 0.8373 | Eval Acc: 0.8203\n",
      "[Fold 2 | Epoch 7] Train Acc: 0.8401 | Eval Acc: 0.8534\n",
      "[Fold 2 | Epoch 8] Train Acc: 0.8433 | Eval Acc: 0.8501\n",
      "[Fold 2 | Epoch 9] Train Acc: 0.8451 | Eval Acc: 0.8488\n",
      "[Fold 2 | Epoch 10] Train Acc: 0.8477 | Eval Acc: 0.8459\n",
      "[Fold 2 | Epoch 11] Train Acc: 0.8504 | Eval Acc: 0.8480\n",
      "[Fold 2 | Epoch 12] Train Acc: 0.8486 | Eval Acc: 0.8340\n",
      "[Fold 2 | Epoch 13] Train Acc: 0.8520 | Eval Acc: 0.8231\n",
      "[Fold 2 | Epoch 14] Train Acc: 0.8524 | Eval Acc: 0.8512\n",
      "[Fold 2 | Epoch 15] Train Acc: 0.8530 | Eval Acc: 0.8463\n",
      "[Fold 2 | Epoch 16] Train Acc: 0.8553 | Eval Acc: 0.8475\n",
      "[Fold 2 | Epoch 17] Train Acc: 0.8542 | Eval Acc: 0.8414\n",
      "[Fold 2 | Epoch 18] Train Acc: 0.8581 | Eval Acc: 0.8526\n",
      "[Fold 2 | Epoch 19] Train Acc: 0.8583 | Eval Acc: 0.8430\n",
      "[Fold 2 | Epoch 20] Train Acc: 0.8618 | Eval Acc: 0.8461\n",
      "[Fold 2 | Epoch 21] Train Acc: 0.8587 | Eval Acc: 0.8433\n",
      "[Fold 2 | Epoch 22] Train Acc: 0.8610 | Eval Acc: 0.8493\n",
      "[EarlyStopping] No improvement in 15 epochs. Stopping at epoch 22.\n",
      "[Fold 2] Best Val Acc: 0.8534 at epoch 7\n",
      "\n",
      "========== Fold 3/5 ==========\n",
      "[Fold 3 | Epoch 1] Train Acc: 0.7853 | Eval Acc: 0.8133\n",
      "[Fold 3 | Epoch 2] Train Acc: 0.8218 | Eval Acc: 0.8321\n",
      "[Fold 3 | Epoch 3] Train Acc: 0.8297 | Eval Acc: 0.8131\n",
      "[Fold 3 | Epoch 4] Train Acc: 0.8342 | Eval Acc: 0.8394\n",
      "[Fold 3 | Epoch 5] Train Acc: 0.8367 | Eval Acc: 0.8311\n",
      "[Fold 3 | Epoch 6] Train Acc: 0.8410 | Eval Acc: 0.8194\n",
      "[Fold 3 | Epoch 7] Train Acc: 0.8431 | Eval Acc: 0.8415\n",
      "[Fold 3 | Epoch 8] Train Acc: 0.8462 | Eval Acc: 0.8394\n",
      "[Fold 3 | Epoch 9] Train Acc: 0.8454 | Eval Acc: 0.8397\n",
      "[Fold 3 | Epoch 10] Train Acc: 0.8484 | Eval Acc: 0.7853\n",
      "[Fold 3 | Epoch 11] Train Acc: 0.8485 | Eval Acc: 0.8043\n",
      "[Fold 3 | Epoch 12] Train Acc: 0.8500 | Eval Acc: 0.8088\n",
      "[Fold 3 | Epoch 13] Train Acc: 0.8512 | Eval Acc: 0.8455\n",
      "[Fold 3 | Epoch 14] Train Acc: 0.8528 | Eval Acc: 0.8458\n",
      "[Fold 3 | Epoch 15] Train Acc: 0.8521 | Eval Acc: 0.8462\n",
      "[Fold 3 | Epoch 16] Train Acc: 0.8549 | Eval Acc: 0.8444\n",
      "[Fold 3 | Epoch 17] Train Acc: 0.8554 | Eval Acc: 0.8512\n",
      "[Fold 3 | Epoch 18] Train Acc: 0.8586 | Eval Acc: 0.8529\n",
      "[Fold 3 | Epoch 19] Train Acc: 0.8572 | Eval Acc: 0.8534\n",
      "[Fold 3 | Epoch 20] Train Acc: 0.8597 | Eval Acc: 0.8530\n",
      "[Fold 3 | Epoch 21] Train Acc: 0.8626 | Eval Acc: 0.8534\n",
      "[Fold 3 | Epoch 22] Train Acc: 0.8620 | Eval Acc: 0.8493\n",
      "[Fold 3 | Epoch 23] Train Acc: 0.8592 | Eval Acc: 0.8227\n",
      "[Fold 3 | Epoch 24] Train Acc: 0.8627 | Eval Acc: 0.8487\n",
      "[Fold 3 | Epoch 25] Train Acc: 0.8639 | Eval Acc: 0.8315\n",
      "[Fold 3 | Epoch 26] Train Acc: 0.8652 | Eval Acc: 0.8412\n",
      "[Fold 3 | Epoch 27] Train Acc: 0.8653 | Eval Acc: 0.8322\n",
      "[Fold 3 | Epoch 28] Train Acc: 0.8654 | Eval Acc: 0.8549\n",
      "[Fold 3 | Epoch 29] Train Acc: 0.8679 | Eval Acc: 0.8058\n",
      "[Fold 3 | Epoch 30] Train Acc: 0.8731 | Eval Acc: 0.8476\n",
      "[Fold 3 | Epoch 31] Train Acc: 0.8718 | Eval Acc: 0.8032\n",
      "[Fold 3 | Epoch 32] Train Acc: 0.8744 | Eval Acc: 0.8549\n",
      "[Fold 3 | Epoch 33] Train Acc: 0.8739 | Eval Acc: 0.8463\n",
      "[Fold 3 | Epoch 34] Train Acc: 0.8759 | Eval Acc: 0.8494\n",
      "[Fold 3 | Epoch 35] Train Acc: 0.8771 | Eval Acc: 0.7958\n",
      "[Fold 3 | Epoch 36] Train Acc: 0.8787 | Eval Acc: 0.8353\n",
      "[Fold 3 | Epoch 37] Train Acc: 0.8766 | Eval Acc: 0.8058\n",
      "[Fold 3 | Epoch 38] Train Acc: 0.8798 | Eval Acc: 0.8250\n",
      "[Fold 3 | Epoch 39] Train Acc: 0.8810 | Eval Acc: 0.8443\n",
      "[Fold 3 | Epoch 40] Train Acc: 0.8826 | Eval Acc: 0.8461\n",
      "[Fold 3 | Epoch 41] Train Acc: 0.8845 | Eval Acc: 0.8144\n",
      "[Fold 3 | Epoch 42] Train Acc: 0.8830 | Eval Acc: 0.8378\n",
      "[Fold 3 | Epoch 43] Train Acc: 0.8864 | Eval Acc: 0.8419\n",
      "[EarlyStopping] No improvement in 15 epochs. Stopping at epoch 43.\n",
      "[Fold 3] Best Val Acc: 0.8549 at epoch 28\n",
      "\n",
      "========== Fold 4/5 ==========\n",
      "[Fold 4 | Epoch 1] Train Acc: 0.7743 | Eval Acc: 0.7883\n",
      "[Fold 4 | Epoch 2] Train Acc: 0.8218 | Eval Acc: 0.8420\n",
      "[Fold 4 | Epoch 3] Train Acc: 0.8308 | Eval Acc: 0.7922\n",
      "[Fold 4 | Epoch 4] Train Acc: 0.8337 | Eval Acc: 0.8430\n",
      "[Fold 4 | Epoch 5] Train Acc: 0.8393 | Eval Acc: 0.8458\n",
      "[Fold 4 | Epoch 6] Train Acc: 0.8384 | Eval Acc: 0.8359\n",
      "[Fold 4 | Epoch 7] Train Acc: 0.8419 | Eval Acc: 0.8372\n",
      "[Fold 4 | Epoch 8] Train Acc: 0.8438 | Eval Acc: 0.8537\n",
      "[Fold 4 | Epoch 9] Train Acc: 0.8446 | Eval Acc: 0.8441\n",
      "[Fold 4 | Epoch 10] Train Acc: 0.8471 | Eval Acc: 0.8513\n",
      "[Fold 4 | Epoch 11] Train Acc: 0.8494 | Eval Acc: 0.8559\n",
      "[Fold 4 | Epoch 12] Train Acc: 0.8487 | Eval Acc: 0.8528\n",
      "[Fold 4 | Epoch 13] Train Acc: 0.8484 | Eval Acc: 0.8535\n",
      "[Fold 4 | Epoch 14] Train Acc: 0.8513 | Eval Acc: 0.8580\n",
      "[Fold 4 | Epoch 15] Train Acc: 0.8531 | Eval Acc: 0.8404\n",
      "[Fold 4 | Epoch 16] Train Acc: 0.8517 | Eval Acc: 0.8460\n",
      "[Fold 4 | Epoch 17] Train Acc: 0.8532 | Eval Acc: 0.8481\n",
      "[Fold 4 | Epoch 18] Train Acc: 0.8585 | Eval Acc: 0.8491\n",
      "[Fold 4 | Epoch 19] Train Acc: 0.8574 | Eval Acc: 0.8549\n",
      "[Fold 4 | Epoch 20] Train Acc: 0.8564 | Eval Acc: 0.8438\n",
      "[Fold 4 | Epoch 21] Train Acc: 0.8586 | Eval Acc: 0.8604\n",
      "[Fold 4 | Epoch 22] Train Acc: 0.8615 | Eval Acc: 0.8553\n",
      "[Fold 4 | Epoch 23] Train Acc: 0.8621 | Eval Acc: 0.8485\n",
      "[Fold 4 | Epoch 24] Train Acc: 0.8617 | Eval Acc: 0.8512\n",
      "[Fold 4 | Epoch 25] Train Acc: 0.8662 | Eval Acc: 0.8527\n",
      "[Fold 4 | Epoch 26] Train Acc: 0.8655 | Eval Acc: 0.8202\n",
      "[Fold 4 | Epoch 27] Train Acc: 0.8665 | Eval Acc: 0.8431\n",
      "[Fold 4 | Epoch 28] Train Acc: 0.8690 | Eval Acc: 0.8210\n",
      "[Fold 4 | Epoch 29] Train Acc: 0.8703 | Eval Acc: 0.8557\n",
      "[Fold 4 | Epoch 30] Train Acc: 0.8716 | Eval Acc: 0.8239\n",
      "[Fold 4 | Epoch 31] Train Acc: 0.8733 | Eval Acc: 0.8555\n",
      "[Fold 4 | Epoch 32] Train Acc: 0.8723 | Eval Acc: 0.8550\n",
      "[Fold 4 | Epoch 33] Train Acc: 0.8732 | Eval Acc: 0.8221\n",
      "[Fold 4 | Epoch 34] Train Acc: 0.8758 | Eval Acc: 0.8480\n",
      "[Fold 4 | Epoch 35] Train Acc: 0.8764 | Eval Acc: 0.8368\n",
      "[Fold 4 | Epoch 36] Train Acc: 0.8780 | Eval Acc: 0.8496\n",
      "[EarlyStopping] No improvement in 15 epochs. Stopping at epoch 36.\n",
      "[Fold 4] Best Val Acc: 0.8604 at epoch 21\n",
      "\n",
      "========== Fold 5/5 ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 1] Train Acc: 0.7794 | Eval Acc: 0.8035\n",
      "[Fold 5 | Epoch 2] Train Acc: 0.8171 | Eval Acc: 0.8016\n",
      "[Fold 5 | Epoch 3] Train Acc: 0.8295 | Eval Acc: 0.8328\n",
      "[Fold 5 | Epoch 4] Train Acc: 0.8342 | Eval Acc: 0.8451\n",
      "[Fold 5 | Epoch 5] Train Acc: 0.8347 | Eval Acc: 0.8481\n",
      "[Fold 5 | Epoch 6] Train Acc: 0.8394 | Eval Acc: 0.8556\n",
      "[Fold 5 | Epoch 7] Train Acc: 0.8382 | Eval Acc: 0.8369\n",
      "[Fold 5 | Epoch 8] Train Acc: 0.8409 | Eval Acc: 0.8420\n",
      "[Fold 5 | Epoch 9] Train Acc: 0.8433 | Eval Acc: 0.8506\n",
      "[Fold 5 | Epoch 10] Train Acc: 0.8466 | Eval Acc: 0.8563\n",
      "[Fold 5 | Epoch 11] Train Acc: 0.8461 | Eval Acc: 0.8232\n",
      "[Fold 5 | Epoch 12] Train Acc: 0.8484 | Eval Acc: 0.8552\n",
      "[Fold 5 | Epoch 13] Train Acc: 0.8476 | Eval Acc: 0.8344\n",
      "[Fold 5 | Epoch 14] Train Acc: 0.8507 | Eval Acc: 0.8557\n",
      "[Fold 5 | Epoch 15] Train Acc: 0.8507 | Eval Acc: 0.8372\n",
      "[Fold 5 | Epoch 16] Train Acc: 0.8528 | Eval Acc: 0.8276\n",
      "[Fold 5 | Epoch 17] Train Acc: 0.8564 | Eval Acc: 0.8523\n",
      "[Fold 5 | Epoch 18] Train Acc: 0.8528 | Eval Acc: 0.8508\n",
      "[Fold 5 | Epoch 19] Train Acc: 0.8558 | Eval Acc: 0.8452\n",
      "[Fold 5 | Epoch 20] Train Acc: 0.8566 | Eval Acc: 0.8490\n",
      "[Fold 5 | Epoch 21] Train Acc: 0.8593 | Eval Acc: 0.8456\n",
      "[Fold 5 | Epoch 22] Train Acc: 0.8579 | Eval Acc: 0.8498\n",
      "[Fold 5 | Epoch 23] Train Acc: 0.8634 | Eval Acc: 0.8516\n",
      "[Fold 5 | Epoch 24] Train Acc: 0.8638 | Eval Acc: 0.8564\n",
      "[Fold 5 | Epoch 25] Train Acc: 0.8640 | Eval Acc: 0.8249\n",
      "[Fold 5 | Epoch 26] Train Acc: 0.8638 | Eval Acc: 0.8469\n",
      "[Fold 5 | Epoch 27] Train Acc: 0.8642 | Eval Acc: 0.8328\n",
      "[Fold 5 | Epoch 28] Train Acc: 0.8672 | Eval Acc: 0.8541\n",
      "[Fold 5 | Epoch 29] Train Acc: 0.8656 | Eval Acc: 0.8038\n",
      "[Fold 5 | Epoch 30] Train Acc: 0.8678 | Eval Acc: 0.8466\n",
      "[Fold 5 | Epoch 31] Train Acc: 0.8688 | Eval Acc: 0.8557\n",
      "[Fold 5 | Epoch 32] Train Acc: 0.8724 | Eval Acc: 0.8481\n",
      "[Fold 5 | Epoch 33] Train Acc: 0.8731 | Eval Acc: 0.8408\n",
      "[Fold 5 | Epoch 34] Train Acc: 0.8714 | Eval Acc: 0.8472\n",
      "[Fold 5 | Epoch 35] Train Acc: 0.8763 | Eval Acc: 0.8376\n",
      "[Fold 5 | Epoch 36] Train Acc: 0.8735 | Eval Acc: 0.8498\n",
      "[Fold 5 | Epoch 37] Train Acc: 0.8813 | Eval Acc: 0.8469\n",
      "[Fold 5 | Epoch 38] Train Acc: 0.8779 | Eval Acc: 0.8563\n",
      "[Fold 5 | Epoch 39] Train Acc: 0.8825 | Eval Acc: 0.8523\n",
      "[EarlyStopping] No improvement in 15 epochs. Stopping at epoch 39.\n",
      "[Fold 5] Best Val Acc: 0.8564 at epoch 24\n",
      "\n",
      "===== FINAL 5-FOLD EVALUATION =====\n",
      "ACC: 0.8577 | MF1: 0.7851 | G-Mean: 0.4461\n",
      "[Class 0] Prec: 0.9231 | Rec: 0.9081 | F1: 0.9155 | GM: 0.9081\n",
      "[Class 1] Prec: 0.5295 | Rec: 0.3124 | F1: 0.3929 | GM: 0.3124\n",
      "[Class 2] Prec: 0.8878 | Rec: 0.9124 | F1: 0.8999 | GM: 0.9124\n",
      "[Class 3] Prec: 0.9216 | Rec: 0.8897 | F1: 0.9054 | GM: 0.8897\n",
      "[Class 4] Prec: 0.7651 | Rec: 0.8643 | F1: 0.8117 | GM: 0.8643\n",
      "Confusion Matrix:\n",
      "[[ 6060   305   115    16   177]\n",
      " [  312   789   568     7   850]\n",
      " [   88   178 14136   329   763]\n",
      " [   16     0   493  4147     5]\n",
      " [   89   218   610     1  5846]]\n",
      "Total Samples: 36118\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from genotypes import Genotype  # Đảm bảo bạn có class này\n",
    "from model_build import FinalNetwork\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 10  # <-- sửa nếu bạn có số class khác\n",
    "\n",
    "# === 1. Load dữ liệu từ CSV ===\n",
    "df = pd.read_csv(\"pruned_dataset.csv\")\n",
    "X_np = df.drop(\"label\", axis=1).values.astype(\"float32\")\n",
    "y_np = df[\"label\"].values.astype(\"int64\")\n",
    "\n",
    "X_all = torch.tensor(X_np)\n",
    "y_all = torch.tensor(y_np)\n",
    "\n",
    "# === 2. Load searched_genotype từ txt ===\n",
    "with open(\"searched_genotype_20.txt\", \"r\") as f:\n",
    "    genotype_str = f.read()\n",
    "searched_genotype = eval(genotype_str)\n",
    "\n",
    "# === 3. Chia train/test theo tỉ lệ 80/20 ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.2, random_state=42, stratify=y_all\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=64)\n",
    "\n",
    "# === 4. Huấn luyện với early stopping ===\n",
    "model = FinalNetwork(C=8, num_classes=num_classes, layers=7, genotype=searched_genotype).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_epoch = 0\n",
    "best_pred, best_true = [], []\n",
    "patience = 15\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    train_true, train_pred = [], []\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_true.extend(y.cpu().numpy())\n",
    "        train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(train_true, train_pred)\n",
    "\n",
    "    # === Đánh giá\n",
    "    model.eval()\n",
    "    val_true, val_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            output = model(x)\n",
    "            val_true.extend(y.cpu().numpy())\n",
    "            val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Train Acc: {train_acc:.4f} | Eval Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch + 1\n",
    "        best_pred = val_pred\n",
    "        best_true = val_true\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "\n",
    "    if no_improve >= patience:\n",
    "        print(f\"[EarlyStopping] No improvement in {patience} epochs. Stopping at epoch {epoch+1}.\")\n",
    "        break\n",
    "\n",
    "print(f\"✅ Best Val Acc: {best_val_acc:.4f} at epoch {best_epoch}\")\n",
    "\n",
    "# === Final Evaluation ===\n",
    "def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    gmeans = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        recall_c = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        gmeans.append(recall_c)\n",
    "\n",
    "    mgm = np.sqrt(np.prod(gmeans)) if np.all(np.array(gmeans) > 0) else 0.0\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, mf1, mgm, prec, rec, f1s, gmeans, cm\n",
    "\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(\n",
    "    np.array(best_true), np.array(best_pred), num_classes\n",
    ")\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Total Samples:\", cm.sum())\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import numpy as np\n",
    "# import torch.nn as nn\n",
    "\n",
    "# def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "#     acc = accuracy_score(y_true, y_pred)\n",
    "#     mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "#     prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "#     rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "#     f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "#     gmeans = []\n",
    "#     for c in range(num_classes):\n",
    "#         tp = np.sum((y_pred == c) & (y_true == c))\n",
    "#         fn = np.sum((y_pred != c) & (y_true == c))\n",
    "#         recall_c = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "#         gmeans.append(recall_c)\n",
    "\n",
    "#     mgm = np.sqrt(np.prod(gmeans)) if np.all(np.array(gmeans) > 0) else 0.0\n",
    "#     cm = confusion_matrix(y_true, y_pred)\n",
    "#     return acc, mf1, mgm, prec, rec, f1s, gmeans, cm\n",
    "\n",
    "# # === 5-Fold Training with Early Stopping ===\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# all_y_true, all_y_pred = [], []\n",
    "\n",
    "# for fold, (train_idx, test_idx) in enumerate(kf.split(X_all)):\n",
    "#     print(f\"\\n========== Fold {fold + 1}/5 ==========\")\n",
    "\n",
    "#     X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "#     X_test, y_test = X_all[test_idx], y_all[test_idx]\n",
    "\n",
    "#     train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "#     test_loader  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64)\n",
    "\n",
    "#     model = FinalNetwork(C=8, num_classes=num_classes, layers=7, genotype=searched_genotype).to(device)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#     best_val_acc = 0.0\n",
    "#     best_epoch = 0\n",
    "#     best_pred, best_true = [], []\n",
    "\n",
    "#     patience = 15\n",
    "#     no_improve = 0\n",
    "\n",
    "#     for epoch in range(50):\n",
    "#         model.train()\n",
    "#         train_true, train_pred = [], []\n",
    "\n",
    "#         for x, y in train_loader:\n",
    "#             x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             output = model(x)\n",
    "#             loss = criterion(output, y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             train_true.extend(y.cpu().numpy())\n",
    "#             train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "#         train_acc = accuracy_score(train_true, train_pred)\n",
    "\n",
    "#         # === Evaluation\n",
    "#         model.eval()\n",
    "#         val_true, val_pred = [], []\n",
    "#         with torch.no_grad():\n",
    "#             for x, y in test_loader:\n",
    "#                 x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "#                 output = model(x)\n",
    "#                 val_true.extend(y.cpu().numpy())\n",
    "#                 val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "#         val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "#         print(f\"[Fold {fold+1} | Epoch {epoch+1}] Train Acc: {train_acc:.4f} | Eval Acc: {val_acc:.4f}\")\n",
    "\n",
    "#         if val_acc > best_val_acc:\n",
    "#             best_val_acc = val_acc\n",
    "#             best_epoch = epoch + 1\n",
    "#             best_pred = val_pred\n",
    "#             best_true = val_true\n",
    "#             no_improve = 0\n",
    "#         else:\n",
    "#             no_improve += 1\n",
    "\n",
    "#         if no_improve >= patience:\n",
    "#             print(f\"[EarlyStopping] No improvement in {patience} epochs. Stopping at epoch {epoch+1}.\")\n",
    "#             break\n",
    "\n",
    "#     print(f\"[Fold {fold+1}] Best Val Acc: {best_val_acc:.4f} at epoch {best_epoch}\")\n",
    "#     all_y_true.extend(best_true)\n",
    "#     all_y_pred.extend(best_pred)\n",
    "\n",
    "# # === Final Evaluation\n",
    "# acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(\n",
    "#     np.array(all_y_true), np.array(all_y_pred), num_classes\n",
    "# )\n",
    "\n",
    "# print(\"\\n===== FINAL 5-FOLD EVALUATION =====\")\n",
    "# print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "# for i in range(num_classes):\n",
    "#     print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(cm)\n",
    "# print(\"Total Samples:\", cm.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d874404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Full Training ==========\n",
      "[Epoch 1] Train Acc: 0.7890 | Eval Acc: 0.7289\n",
      "[Epoch 2] Train Acc: 0.8247 | Eval Acc: 0.8299\n",
      "[Epoch 3] Train Acc: 0.8299 | Eval Acc: 0.8302\n",
      "[Epoch 4] Train Acc: 0.8366 | Eval Acc: 0.8445\n",
      "[Epoch 5] Train Acc: 0.8399 | Eval Acc: 0.8249\n",
      "[Epoch 6] Train Acc: 0.8429 | Eval Acc: 0.8524\n",
      "[Epoch 7] Train Acc: 0.8407 | Eval Acc: 0.8519\n",
      "[Epoch 8] Train Acc: 0.8443 | Eval Acc: 0.8540\n",
      "[Epoch 9] Train Acc: 0.8474 | Eval Acc: 0.8560\n",
      "[Epoch 10] Train Acc: 0.8498 | Eval Acc: 0.8536\n",
      "[Epoch 11] Train Acc: 0.8476 | Eval Acc: 0.8487\n",
      "[Epoch 12] Train Acc: 0.8512 | Eval Acc: 0.8556\n",
      "[Epoch 13] Train Acc: 0.8523 | Eval Acc: 0.8488\n",
      "[Epoch 14] Train Acc: 0.8520 | Eval Acc: 0.8358\n",
      "[Epoch 15] Train Acc: 0.8520 | Eval Acc: 0.8669\n",
      "[Epoch 16] Train Acc: 0.8551 | Eval Acc: 0.8571\n",
      "[Epoch 17] Train Acc: 0.8544 | Eval Acc: 0.8404\n",
      "[Epoch 18] Train Acc: 0.8557 | Eval Acc: 0.8731\n",
      "[Epoch 19] Train Acc: 0.8561 | Eval Acc: 0.8750\n",
      "[Epoch 20] Train Acc: 0.8603 | Eval Acc: 0.8664\n",
      "[Epoch 21] Train Acc: 0.8578 | Eval Acc: 0.8698\n",
      "[Epoch 22] Train Acc: 0.8626 | Eval Acc: 0.8673\n",
      "[Epoch 23] Train Acc: 0.8593 | Eval Acc: 0.8694\n",
      "[Epoch 24] Train Acc: 0.8636 | Eval Acc: 0.8760\n",
      "[Epoch 25] Train Acc: 0.8629 | Eval Acc: 0.8590\n",
      "[Epoch 26] Train Acc: 0.8665 | Eval Acc: 0.8844\n",
      "[Epoch 27] Train Acc: 0.8660 | Eval Acc: 0.8752\n",
      "[Epoch 28] Train Acc: 0.8661 | Eval Acc: 0.8551\n",
      "[Epoch 29] Train Acc: 0.8676 | Eval Acc: 0.8728\n",
      "[Epoch 30] Train Acc: 0.8693 | Eval Acc: 0.8740\n",
      "[Epoch 31] Train Acc: 0.8703 | Eval Acc: 0.8775\n",
      "[Epoch 32] Train Acc: 0.8705 | Eval Acc: 0.8749\n",
      "[Epoch 33] Train Acc: 0.8711 | Eval Acc: 0.8785\n",
      "[Epoch 34] Train Acc: 0.8746 | Eval Acc: 0.8921\n",
      "[Epoch 35] Train Acc: 0.8739 | Eval Acc: 0.8748\n",
      "[Epoch 36] Train Acc: 0.8762 | Eval Acc: 0.8879\n",
      "[Epoch 37] Train Acc: 0.8786 | Eval Acc: 0.8894\n",
      "[Epoch 38] Train Acc: 0.8779 | Eval Acc: 0.8911\n",
      "[Epoch 39] Train Acc: 0.8802 | Eval Acc: 0.8798\n",
      "[Epoch 40] Train Acc: 0.8813 | Eval Acc: 0.8912\n",
      "[Epoch 41] Train Acc: 0.8810 | Eval Acc: 0.8964\n",
      "[Epoch 42] Train Acc: 0.8796 | Eval Acc: 0.8967\n",
      "[Epoch 43] Train Acc: 0.8857 | Eval Acc: 0.8997\n",
      "[Epoch 44] Train Acc: 0.8866 | Eval Acc: 0.8975\n",
      "[Epoch 45] Train Acc: 0.8877 | Eval Acc: 0.9050\n",
      "[Epoch 46] Train Acc: 0.8868 | Eval Acc: 0.9004\n",
      "[Epoch 47] Train Acc: 0.8881 | Eval Acc: 0.8887\n",
      "[Epoch 48] Train Acc: 0.8887 | Eval Acc: 0.8916\n",
      "[Epoch 49] Train Acc: 0.8882 | Eval Acc: 0.9059\n",
      "[Epoch 50] Train Acc: 0.8922 | Eval Acc: 0.8484\n",
      "[Final Model] Best Val Acc: 0.9059 at epoch 49\n",
      "\n",
      "===== FINAL FULL DATA EVALUATION =====\n",
      "ACC: 0.9059 | MF1: 0.8577 | G-Mean: 0.6143\n",
      "[Class 0] Prec: 0.9747 | Rec: 0.9354 | F1: 0.9547 | GM: 0.9354\n",
      "[Class 1] Prec: 0.7298 | Rec: 0.4802 | F1: 0.5793 | GM: 0.4802\n",
      "[Class 2] Prec: 0.9177 | Rec: 0.9323 | F1: 0.9250 | GM: 0.9323\n",
      "[Class 3] Prec: 0.9039 | Rec: 0.9625 | F1: 0.9323 | GM: 0.9625\n",
      "[Class 4] Prec: 0.8616 | Rec: 0.9361 | F1: 0.8973 | GM: 0.9361\n",
      "Confusion Matrix:\n",
      "[[ 6242   223    82     8   118]\n",
      " [  132  1213   690     4   487]\n",
      " [   22   152 14445   464   411]\n",
      " [    2     0   172  4486     1]\n",
      " [    6    74   351     1  6332]]\n",
      "Total Samples: 36118\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import copy\n",
    "\n",
    "# # === Entropy-based pruning ===\n",
    "# def compute_filter_entropy(weight_tensor):\n",
    "#     entropy_list = []\n",
    "#     for filt in weight_tensor:\n",
    "#         filt_flat = filt.view(filt.size(0), -1)\n",
    "#         norms = torch.norm(filt_flat, dim=1) + 1e-6\n",
    "#         p = norms / norms.sum()\n",
    "#         entropy = -torch.sum(p * torch.log2(p))\n",
    "#         entropy_list.append(entropy.item())\n",
    "#     return entropy_list\n",
    "\n",
    "# def prune_model_entropy(model, prune_ratio=0.5):\n",
    "#     for name, module in model.named_modules():\n",
    "#         if isinstance(module, nn.Conv1d):\n",
    "#             weight = module.weight.data.detach().cpu()\n",
    "#             entropy = compute_filter_entropy(weight)\n",
    "#             entropy_tensor = torch.tensor(entropy)\n",
    "#             k = int((1 - prune_ratio) * len(entropy))\n",
    "#             topk_indices = torch.topk(entropy_tensor, k=k).indices\n",
    "#             mask = torch.zeros_like(entropy_tensor)\n",
    "#             mask[topk_indices] = 1.0\n",
    "#             full_mask = mask[:, None, None].expand_as(weight).to(module.weight.device)\n",
    "#             module.weight.data *= full_mask\n",
    "#     return model\n",
    "\n",
    "# def count_pruned_weights(model):\n",
    "#     total, nonzero = 0, 0\n",
    "#     for module in model.modules():\n",
    "#         if isinstance(module, (nn.Conv1d, nn.Linear)):\n",
    "#             w = module.weight.data\n",
    "#             total += w.numel()\n",
    "#             nonzero += w.nonzero().size(0)\n",
    "#     zero = total - nonzero\n",
    "#     print(f\"[INFO] Total weights: {total}\")\n",
    "#     print(f\"[INFO] Non-zero weights: {nonzero}\")\n",
    "#     print(f\"[INFO] Pruned weights: {zero}\")\n",
    "#     print(f\"[INFO] Pruned ratio: {100 * zero / total:.2f}%\")\n",
    "\n",
    "# # === Evaluation ===\n",
    "# def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "#     acc = accuracy_score(y_true, y_pred)\n",
    "#     mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "#     prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "#     rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "#     f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "#     gmeans = []\n",
    "#     for c in range(num_classes):\n",
    "#         tp = np.sum((y_pred == c) & (y_true == c))\n",
    "#         fn = np.sum((y_pred != c) & (y_true == c))\n",
    "#         recall_c = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "#         gmeans.append(recall_c)\n",
    "\n",
    "#     mgm = np.sqrt(np.prod(gmeans)) if np.all(np.array(gmeans) > 0) else 0.0\n",
    "#     cm = confusion_matrix(y_true, y_pred)\n",
    "#     return acc, mf1, mgm, prec, rec, f1s, gmeans, cm\n",
    "\n",
    "# # === Main logic starts here ===\n",
    "# # Giả sử bạn đã có các biến:\n",
    "# # X_all, y_all (Tensor); FinalNetwork (class); searched_genotype; num_classes; device\n",
    "\n",
    "# print(\"\\n[INFO] Creating and pruning model...\")\n",
    "# model = FinalNetwork(C=8, num_classes=num_classes, layers=7, genotype=searched_genotype).to(device)\n",
    "\n",
    "# print(\"\\n[INFO] BEFORE PRUNING:\")\n",
    "# count_pruned_weights(model)\n",
    "\n",
    "# model = prune_model_entropy(model, prune_ratio=0.5)\n",
    "\n",
    "# print(\"\\n[INFO] AFTER PRUNING:\")\n",
    "# count_pruned_weights(model)\n",
    "\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# all_y_true, all_y_pred = [], []\n",
    "\n",
    "# for fold, (train_idx, test_idx) in enumerate(kf.split(X_all)):\n",
    "#     print(f\"\\n========== Fold {fold + 1}/5 ==========\")\n",
    "#     X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "#     X_test, y_test = X_all[test_idx], y_all[test_idx]\n",
    "\n",
    "#     train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "#     test_loader  = DataLoader(TensorDataset(X_test,  y_test),  batch_size=64)\n",
    "\n",
    "#     model_fold = copy.deepcopy(model)\n",
    "#     optimizer = torch.optim.Adam(model_fold.parameters(), lr=0.005)\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#     best_val_acc = 0.0\n",
    "#     best_epoch = 0\n",
    "#     best_pred, best_true = [], []\n",
    "#     patience = 15\n",
    "#     no_improve = 0\n",
    "\n",
    "#     for epoch in range(50):\n",
    "#         model_fold.train()\n",
    "#         for x, y in train_loader:\n",
    "#             x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             output = model_fold(x)\n",
    "#             loss = criterion(output, y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#         model_fold.eval()\n",
    "#         val_true, val_pred = [], []\n",
    "#         with torch.no_grad():\n",
    "#             for x, y in test_loader:\n",
    "#                 x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "#                 output = model_fold(x)\n",
    "#                 val_true.extend(y.cpu().numpy())\n",
    "#                 val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "#         val_acc = accuracy_score(val_true, val_pred)\n",
    "#         print(f\"[Fold {fold+1} | Epoch {epoch+1}] Eval Acc: {val_acc:.4f}\")\n",
    "\n",
    "#         if val_acc > best_val_acc:\n",
    "#             best_val_acc = val_acc\n",
    "#             best_epoch = epoch + 1\n",
    "#             best_pred = val_pred\n",
    "#             best_true = val_true\n",
    "#             no_improve = 0\n",
    "#         else:\n",
    "#             no_improve += 1\n",
    "\n",
    "#         if no_improve >= patience:\n",
    "#             print(f\"[EarlyStopping] No improvement in {patience} epochs. Stopping at epoch {epoch+1}.\")\n",
    "#             break\n",
    "\n",
    "#     print(f\"[Fold {fold+1}] Best Val Acc: {best_val_acc:.4f} at epoch {best_epoch}\")\n",
    "#     all_y_true.extend(best_true)\n",
    "#     all_y_pred.extend(best_pred)\n",
    "\n",
    "#     # === In kết quả cho từng fold\n",
    "#     acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(best_true), np.array(best_pred), num_classes)\n",
    "#     print(f\"\\n[Fold {fold+1} Evaluation]\")\n",
    "#     print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "#     for i in range(num_classes):\n",
    "#         print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "#     print(\"Confusion Matrix:\")\n",
    "#     print(cm)\n",
    "\n",
    "# # === Final Evaluation\n",
    "# acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_y_true), np.array(all_y_pred), num_classes)\n",
    "# print(\"\\n===== FINAL 5-FOLD EVALUATION AFTER PRUNING =====\")\n",
    "# print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "# for i in range(num_classes):\n",
    "#     print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(cm)\n",
    "# print(\"Total Samples:\", cm.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471319a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 5. Prepare data for cross-validation\n",
    "print(\"[INFO] Running 5-Fold Cross Validation on pruned data...\")\n",
    "\n",
    "# Gộp dữ liệu từ train và val\n",
    "X_all = torch.cat([pruned_train_loader.dataset.X, pruned_val_loader.dataset.X], dim=0)\n",
    "y_all = torch.cat([pruned_train_loader.dataset.y, pruned_val_loader.dataset.y], dim=0)\n",
    "\n",
    "# Tạo dataset\n",
    "dataset = TensorDataset(X_all, y_all)\n",
    "\n",
    "# === Xuất ra CSV ===\n",
    "# Nếu dùng GPU, chuyển về CPU\n",
    "if X_all.is_cuda:\n",
    "    X_all = X_all.cpu()\n",
    "    y_all = y_all.cpu()\n",
    "\n",
    "# Chuyển về numpy\n",
    "X_np = X_all.numpy()\n",
    "y_np = y_all.numpy().reshape(-1, 1)\n",
    "\n",
    "# Ghép X và y thành một mảng\n",
    "data_np = np.hstack((X_np, y_np))\n",
    "\n",
    "# Tạo DataFrame với cột feature_0, feature_1, ..., label\n",
    "num_features = X_np.shape[1]\n",
    "column_names = [f\"feature_{i}\" for i in range(num_features)] + [\"label\"]\n",
    "df = pd.DataFrame(data_np, columns=column_names)\n",
    "\n",
    "# Lưu file CSV\n",
    "df.to_csv(\"pruned_dataset.csv\", index=False)\n",
    "print(\"✅ Đã lưu dữ liệu vào 'pruned_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88588d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.5 (NGC 24.09/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
