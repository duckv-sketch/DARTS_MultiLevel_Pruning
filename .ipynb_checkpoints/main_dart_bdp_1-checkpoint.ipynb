{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0171405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "from data_loader_darts import get_dataloaders_simple\n",
    "# from darts_search_bdp import train_darts_search_bdp\n",
    "from darts_search_bdp import train_darts_search_bdp\n",
    "from model_build import FinalNetwork\n",
    "from cell_plot import plot_cell\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48d0748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading 50/50 split data...\n",
      "[DEBUG] Loaded ./PSG/SC4001E0.npz → 841 samples\n",
      "[DEBUG] Loaded ./PSG/SC4002E0.npz → 1127 samples\n",
      "[DEBUG] Loaded ./PSG/SC4011E0.npz → 1103 samples\n",
      "[DEBUG] Loaded ./PSG/SC4012E0.npz → 1186 samples\n",
      "[DEBUG] Loaded ./PSG/SC4021E0.npz → 1025 samples\n",
      "[DEBUG] Loaded ./PSG/SC4022E0.npz → 1009 samples\n",
      "[DEBUG] Loaded ./PSG/SC4031E0.npz → 952 samples\n",
      "[DEBUG] Loaded ./PSG/SC4032E0.npz → 911 samples\n",
      "[DEBUG] Loaded ./PSG/SC4041E0.npz → 1235 samples\n",
      "[DEBUG] Loaded ./PSG/SC4042E0.npz → 1200 samples\n",
      "[DEBUG] Loaded ./PSG/SC4051E0.npz → 672 samples\n",
      "[DEBUG] Loaded ./PSG/SC4052E0.npz → 1246 samples\n",
      "[DEBUG] Loaded ./PSG/SC4061E0.npz → 843 samples\n",
      "[DEBUG] Loaded ./PSG/SC4062E0.npz → 1016 samples\n",
      "[DEBUG] Loaded ./PSG/SC4071E0.npz → 976 samples\n",
      "[DEBUG] Loaded ./PSG/SC4072E0.npz → 1273 samples\n",
      "[DEBUG] Loaded ./PSG/SC4081E0.npz → 1134 samples\n",
      "[DEBUG] Loaded ./PSG/SC4082E0.npz → 1054 samples\n",
      "[DEBUG] Loaded ./PSG/SC4091E0.npz → 1132 samples\n",
      "[DEBUG] Loaded ./PSG/SC4092E0.npz → 1105 samples\n",
      "[DEBUG] Loaded ./PSG/SC4101E0.npz → 1104 samples\n",
      "[DEBUG] Loaded ./PSG/SC4102E0.npz → 1092 samples\n",
      "[DEBUG] Loaded ./PSG/SC4111E0.npz → 928 samples\n",
      "[DEBUG] Loaded ./PSG/SC4112E0.npz → 802 samples\n",
      "[DEBUG] Loaded ./PSG/SC4121E0.npz → 1052 samples\n",
      "[DEBUG] Loaded ./PSG/SC4122E0.npz → 977 samples\n",
      "[DEBUG] Loaded ./PSG/SC4131E0.npz → 1028 samples\n",
      "[DEBUG] Loaded ./PSG/SC4141E0.npz → 1004 samples\n",
      "[DEBUG] Loaded ./PSG/SC4142E0.npz → 952 samples\n",
      "[DEBUG] Loaded ./PSG/SC4151E0.npz → 952 samples\n",
      "[DEBUG] Loaded ./PSG/SC4152E0.npz → 1762 samples\n",
      "[DEBUG] Loaded ./PSG/SC4161E0.npz → 1144 samples\n",
      "[DEBUG] Loaded ./PSG/SC4162E0.npz → 1003 samples\n",
      "[DEBUG] Loaded ./PSG/SC4171E0.npz → 1002 samples\n",
      "[DEBUG] Loaded ./PSG/SC4172E0.npz → 1773 samples\n",
      "[DEBUG] Loaded ./PSG/SC4181E0.npz → 964 samples\n",
      "[DEBUG] Loaded ./PSG/SC4182E0.npz → 920 samples\n",
      "[DEBUG] Loaded ./PSG/SC4191E0.npz → 1535 samples\n",
      "[DEBUG] Loaded ./PSG/SC4192E0.npz → 1274 samples\n",
      "[INFO] DARTS will run on 21154 train samples and 21154 val samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Set random seed\n",
    "set_seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 2. Load data\n",
    "print(\"[INFO] Loading 50/50 split data...\")\n",
    "train_loader, val_loader, num_classes = get_dataloaders_simple(batch_size=32)\n",
    "print(f\"[INFO] DARTS will run on {len(train_loader.dataset.y)} train samples and {len(val_loader.dataset.y)} val samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d3954e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running DARTS search with BDP...\n",
      "\n",
      "[Epoch 1/25] Starting...\n",
      "[Epoch 1] Train Loss: 1.0660 | Acc: 0.5704 || Val Loss: 1.0277 | Acc: 0.5929\n",
      "\n",
      "[Epoch 2/25] Starting...\n",
      "[Epoch 2] Train Loss: 0.8630 | Acc: 0.6669 || Val Loss: 0.7655 | Acc: 0.6751\n",
      "\n",
      "[Epoch 3/25] Starting...\n",
      "[Epoch 3] Train Loss: 0.7609 | Acc: 0.7169 || Val Loss: 0.7263 | Acc: 0.7390\n",
      "\n",
      "[Epoch 4/25] Starting...\n",
      "[Epoch 4] Train Loss: 0.6786 | Acc: 0.7443 || Val Loss: 0.6234 | Acc: 0.7743\n",
      "\n",
      "[Epoch 5/25] Starting...\n",
      "[Epoch 5] Train Loss: 0.6301 | Acc: 0.7639 || Val Loss: 0.8818 | Acc: 0.6819\n",
      "[Annealable Pruning] T = 1.2218\n",
      "[Prune Epoch 5] Pruned 1057 train, 1057 val\n",
      "[After Prune] Remaining train samples: 20097, val samples: 20097\n",
      "\n",
      "[Epoch 6/25] Starting...\n",
      "[Epoch 6] Train Loss: 0.6176 | Acc: 0.7682 || Val Loss: 0.5769 | Acc: 0.7913\n",
      "\n",
      "[Epoch 7/25] Starting...\n",
      "[Epoch 7] Train Loss: 0.5778 | Acc: 0.7850 || Val Loss: 0.6124 | Acc: 0.7707\n",
      "\n",
      "[Epoch 8/25] Starting...\n",
      "[Epoch 8] Train Loss: 0.5711 | Acc: 0.7888 || Val Loss: 0.5566 | Acc: 0.7910\n",
      "\n",
      "[Epoch 9/25] Starting...\n",
      "[Epoch 9] Train Loss: 0.5693 | Acc: 0.7898 || Val Loss: 0.8004 | Acc: 0.6741\n",
      "\n",
      "[Epoch 10/25] Starting...\n",
      "[Epoch 10] Train Loss: 0.5782 | Acc: 0.7851 || Val Loss: 0.6181 | Acc: 0.7688\n",
      "[Annealable Pruning] T = 0.9454\n",
      "[Prune Epoch 10] Pruned 1057 train, 1057 val\n",
      "[After Prune] Remaining train samples: 19063, val samples: 19169\n",
      "\n",
      "[Epoch 11/25] Starting...\n",
      "[Epoch 11] Train Loss: 0.5474 | Acc: 0.7948 || Val Loss: 0.5868 | Acc: 0.7934\n",
      "\n",
      "[Epoch 12/25] Starting...\n",
      "[Epoch 12] Train Loss: 0.5333 | Acc: 0.8031 || Val Loss: 0.5248 | Acc: 0.8050\n",
      "\n",
      "[Epoch 13/25] Starting...\n",
      "[Epoch 13] Train Loss: 0.5222 | Acc: 0.8089 || Val Loss: 0.5351 | Acc: 0.8093\n",
      "\n",
      "[Epoch 14/25] Starting...\n",
      "[Epoch 14] Train Loss: 0.5109 | Acc: 0.8121 || Val Loss: 0.5130 | Acc: 0.8104\n",
      "\n",
      "[Epoch 15/25] Starting...\n",
      "[Epoch 15] Train Loss: 0.5169 | Acc: 0.8090 || Val Loss: 0.5257 | Acc: 0.8105\n",
      "[Annealable Pruning] T = 0.7315\n",
      "[Prune Epoch 15] Pruned 1057 train, 1057 val\n",
      "[After Prune] Remaining train samples: 18050, val samples: 18427\n",
      "\n",
      "[Epoch 16/25] Starting...\n",
      "[Epoch 16] Train Loss: 0.5050 | Acc: 0.8148 || Val Loss: 0.5147 | Acc: 0.8076\n",
      "\n",
      "[Epoch 17/25] Starting...\n",
      "[Epoch 17] Train Loss: 0.4980 | Acc: 0.8167 || Val Loss: 0.4899 | Acc: 0.8237\n",
      "\n",
      "[Epoch 18/25] Starting...\n",
      "[Epoch 18] Train Loss: 0.4905 | Acc: 0.8188 || Val Loss: 0.4789 | Acc: 0.8295\n",
      "\n",
      "[Epoch 19/25] Starting...\n",
      "[Epoch 19] Train Loss: 0.4819 | Acc: 0.8206 || Val Loss: 0.4790 | Acc: 0.8238\n",
      "\n",
      "[Epoch 20/25] Starting...\n",
      "[Epoch 20] Train Loss: 0.4801 | Acc: 0.8223 || Val Loss: 0.4744 | Acc: 0.8303\n",
      "[Annealable Pruning] T = 0.5660\n",
      "[Prune Epoch 20] Pruned 1057 train, 1057 val\n",
      "[After Prune] Remaining train samples: 17062, val samples: 17897\n",
      "\n",
      "[Epoch 21/25] Starting...\n",
      "[Epoch 21] Train Loss: 0.4761 | Acc: 0.8255 || Val Loss: 0.4900 | Acc: 0.8220\n",
      "\n",
      "[Epoch 22/25] Starting...\n",
      "[Epoch 22] Train Loss: 0.4675 | Acc: 0.8275 || Val Loss: 0.4711 | Acc: 0.8296\n",
      "\n",
      "[Epoch 23/25] Starting...\n",
      "[Epoch 23] Train Loss: 0.4630 | Acc: 0.8291 || Val Loss: 0.4692 | Acc: 0.8317\n",
      "\n",
      "[Epoch 24/25] Starting...\n",
      "[Epoch 24] Train Loss: 0.4586 | Acc: 0.8308 || Val Loss: 0.4628 | Acc: 0.8342\n",
      "\n",
      "[Epoch 25/25] Starting...\n",
      "[Epoch 25] Train Loss: 0.4571 | Acc: 0.8330 || Val Loss: 0.4628 | Acc: 0.8315\n",
      "[INFO] Metrics saved to 'search_metrics_log.csv'\n",
      "\n",
      "Final Searched Genotype:\n",
      " Genotype(normal=[('sep_conv_1x5', 0), ('sep_conv_1x5', 1), ('sep_conv_1x5', 0), ('max_pool_3x3', 2), ('max_pool_3x3', 2), ('max_pool_3x3', 3), ('sep_conv_1x5', 0), ('sep_conv_1x5', 1), ('sep_conv_1x5', 1), ('max_pool_3x3', 5), ('dil_conv_1x5', 0), ('dil_conv_1x5', 0)], normal_concat=[0, 1, 2, 3, 4], reduce=[('sep_conv_1x3', 0), ('sep_conv_1x5', 1), ('dil_conv_1x5', 0), ('dil_conv_1x5', 2), ('max_pool_3x3', 0), ('max_pool_3x3', 3), ('max_pool_3x3', 0), ('max_pool_3x3', 4), ('max_pool_3x3', 5), ('max_pool_3x3', 0)], reduce_concat=[0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 3. Run DARTS search with pruning\n",
    "print(\"[INFO] Running DARTS search with BDP...\")\n",
    "searched_genotype, pruned_train_loader, pruned_val_loader = train_darts_search_bdp(\n",
    "    train_loader, val_loader, num_classes,\n",
    "    epochs=25, prune_every=5, pt=0.05, pv=0.05,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e27bb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Genotype = namedtuple('Genotype', 'normal normal_concat reduce reduce_concat')\n",
    "\n",
    "searched_genotype = Genotype(\n",
    "    normal=[\n",
    "        ('sep_conv_1x5', 0),\n",
    "        ('sep_conv_1x5', 1),\n",
    "        ('sep_conv_1x5', 0),\n",
    "        ('max_pool_3x3', 2),\n",
    "        ('max_pool_3x3', 2),\n",
    "        ('max_pool_3x3', 3),\n",
    "        ('sep_conv_1x5', 0),\n",
    "        ('sep_conv_1x5', 1),\n",
    "        ('sep_conv_1x5', 1),\n",
    "        ('max_pool_3x3', 5),\n",
    "        ('dil_conv_1x5', 0),\n",
    "        ('dil_conv_1x5', 0)\n",
    "    ],\n",
    "    normal_concat=[0, 1, 2, 3, 4],\n",
    "\n",
    "    reduce=[\n",
    "        ('sep_conv_1x3', 0),\n",
    "        ('sep_conv_1x5', 1),\n",
    "        ('dil_conv_1x5', 0),\n",
    "        ('dil_conv_1x5', 2),\n",
    "        ('max_pool_3x3', 0),\n",
    "        ('max_pool_3x3', 3),\n",
    "        ('max_pool_3x3', 0),\n",
    "        ('max_pool_3x3', 4),\n",
    "        ('max_pool_3x3', 5),\n",
    "        ('avg_pool_3x3', 0)\n",
    "    ],\n",
    "    reduce_concat=[0, 1, 2, 3, 4]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "774adc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running 5-Fold Cross Validation on pruned data...\n",
      "✅ Đã lưu dữ liệu gốc (KHÔNG chuẩn hóa) vào 'pruned_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"[INFO] Running 5-Fold Cross Validation on pruned data...\")\n",
    "\n",
    "# === Hàm trích xuất toàn bộ dữ liệu từ DataLoader ===\n",
    "def extract_from_loader(loader):\n",
    "    X_list, y_list = [], []\n",
    "    for x, y in loader:\n",
    "        X_list.append(x.cpu())\n",
    "        y_list.append(y.cpu())\n",
    "    return torch.cat(X_list, dim=0), torch.cat(y_list, dim=0)\n",
    "\n",
    "# === Trích xuất X, y từ train và val loader ===\n",
    "X_train_all, y_train_all = extract_from_loader(pruned_train_loader)\n",
    "X_val_all,   y_val_all   = extract_from_loader(pruned_val_loader)\n",
    "\n",
    "# Gộp train + val\n",
    "X_all = torch.cat([X_train_all, X_val_all], dim=0)  # shape: (N, C, T) hoặc (N, T)\n",
    "y_all = torch.cat([y_train_all, y_val_all], dim=0)  # shape: (N,)\n",
    "\n",
    "# === Chuyển về numpy ===\n",
    "X_np = X_all.numpy()\n",
    "y_np = y_all.numpy().reshape(-1, 1)\n",
    "\n",
    "# === Reshape X về (N, D) nếu cần (flatten nếu có chiều phụ) ===\n",
    "if X_np.ndim > 2:\n",
    "    X_np = X_np.reshape(X_np.shape[0], -1)  # (N, D)\n",
    "\n",
    "# ❌ KHÔNG chuẩn hóa, giữ nguyên raw X_np\n",
    "\n",
    "# === Ghép lại X và y ===\n",
    "data_np = np.hstack((X_np, y_np))  # shape: (N, D+1)\n",
    "\n",
    "# === Tạo DataFrame và lưu CSV ===\n",
    "num_features = X_np.shape[1]\n",
    "column_names = [f\"feature_{i}\" for i in range(num_features)] + [\"label\"]\n",
    "df = pd.DataFrame(data_np, columns=column_names)\n",
    "\n",
    "df.to_csv(\"pruned_dataset3.csv\", index=False)\n",
    "print(\"✅ Đã lưu dữ liệu gốc (KHÔNG chuẩn hóa) vào 'pruned_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c319e687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Số lượng mẫu theo từng lớp:\n",
      "  Lớp 0: 6338 mẫu\n",
      "  Lớp 1: 2503 mẫu\n",
      "  Lớp 2: 14941 mẫu\n",
      "  Lớp 3: 4440 mẫu\n",
      "  Lớp 4: 6643 mẫu\n"
     ]
    }
   ],
   "source": [
    " df= pd.read_csv(\"pruned_dataset3.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "unique, counts = np.unique(y_np, return_counts=True)\n",
    "print(\"\\n[INFO] Số lượng mẫu theo từng lớp:\")\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"  Lớp {label}: {count} mẫu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01cec369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 https://deb.nodesource.com/node_20.x nodistro InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Reading package lists... Done\u001b[33m\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "171 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Note, selecting 'libgraphviz-dev' instead of 'graphviz-dev'\n",
      "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
      "libgraphviz-dev is already the newest version (2.42.2-6ubuntu0.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 171 not upgraded.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pygraphviz\n",
      "  Downloading pygraphviz-1.14.tar.gz (106 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pygraphviz\n",
      "  Building wheel for pygraphviz (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pygraphviz: filename=pygraphviz-1.14-cp310-cp310-linux_x86_64.whl size=168674 sha256=076585350cd5f30df76e3f0724db748f4413b53c909b29634faae15a4433c5ee\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vk28zoi1/wheels/61/ab/cd/e24a22c32830b8b4948c8887d8714d399f0f806f206a034698\n",
      "Successfully built pygraphviz\n",
      "\u001b[33mWARNING: Error parsing dependencies of devscripts: Invalid version: '2.22.1ubuntu1'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pygraphviz\n",
      "Successfully installed pygraphviz-1.14\n",
      "[INFO] Visualizing searched cells...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/Duc/NASEEG1_Final/NASEEG/SleepC/sleep_nas/cell_plot.py:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "!sudo apt update\n",
    "!sudo apt install -y graphviz graphviz-dev\n",
    "!pip install pygraphviz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4. Visualize searched cells\n",
    "print(\"[INFO] Visualizing searched cells...\")\n",
    "plot_cell(searched_genotype, 'normal')\n",
    "plot_cell(searched_genotype, 'reduce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab8fb068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5527 | Train Acc: 0.7928 | Val Loss: 0.4692 | Val Acc: 0.8295\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4655 | Train Acc: 0.8275 | Val Loss: 0.4299 | Val Acc: 0.8365\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4366 | Train Acc: 0.8393 | Val Loss: 0.6169 | Val Acc: 0.7817\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4255 | Train Acc: 0.8408 | Val Loss: 0.4270 | Val Acc: 0.8331\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4085 | Train Acc: 0.8512 | Val Loss: 0.4289 | Val Acc: 0.8391\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4060 | Train Acc: 0.8500 | Val Loss: 0.3818 | Val Acc: 0.8566\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.3974 | Train Acc: 0.8525 | Val Loss: 0.3797 | Val Acc: 0.8564\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.3919 | Train Acc: 0.8541 | Val Loss: 0.5062 | Val Acc: 0.7945\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.3864 | Train Acc: 0.8552 | Val Loss: 0.3691 | Val Acc: 0.8628\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.3805 | Train Acc: 0.8563 | Val Loss: 0.3862 | Val Acc: 0.8563\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3707 | Train Acc: 0.8622 | Val Loss: 0.3708 | Val Acc: 0.8587\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3697 | Train Acc: 0.8623 | Val Loss: 0.4026 | Val Acc: 0.8476\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3639 | Train Acc: 0.8652 | Val Loss: 0.3920 | Val Acc: 0.8527\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3578 | Train Acc: 0.8648 | Val Loss: 0.3699 | Val Acc: 0.8585\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3455 | Train Acc: 0.8707 | Val Loss: 0.4087 | Val Acc: 0.8513\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3373 | Train Acc: 0.8741 | Val Loss: 0.3870 | Val Acc: 0.8509\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3346 | Train Acc: 0.8765 | Val Loss: 0.4113 | Val Acc: 0.8491\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3218 | Train Acc: 0.8801 | Val Loss: 0.4216 | Val Acc: 0.8379\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3108 | Train Acc: 0.8825 | Val Loss: 0.4202 | Val Acc: 0.8471\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3020 | Train Acc: 0.8871 | Val Loss: 0.4501 | Val Acc: 0.8200\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.2972 | Train Acc: 0.8899 | Val Loss: 0.3847 | Val Acc: 0.8556\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.2871 | Train Acc: 0.8922 | Val Loss: 0.4195 | Val Acc: 0.8517\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.2730 | Train Acc: 0.8976 | Val Loss: 0.4249 | Val Acc: 0.8494\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.2659 | Train Acc: 0.9008 | Val Loss: 0.4497 | Val Acc: 0.8339\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.2594 | Train Acc: 0.9033 | Val Loss: 0.4029 | Val Acc: 0.8570\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.2485 | Train Acc: 0.9062 | Val Loss: 0.4861 | Val Acc: 0.8319\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.2380 | Train Acc: 0.9108 | Val Loss: 0.4154 | Val Acc: 0.8618\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.2354 | Train Acc: 0.9106 | Val Loss: 0.4856 | Val Acc: 0.8486\n",
      "[Fold 1 | Epoch 29] Train Loss: 0.2218 | Train Acc: 0.9152 | Val Loss: 0.4058 | Val Acc: 0.8519\n",
      "[Fold 1 | Epoch 30] Train Loss: 0.2110 | Train Acc: 0.9190 | Val Loss: 0.5908 | Val Acc: 0.7978\n",
      "[Fold 1 | Epoch 31] Train Loss: 0.2092 | Train Acc: 0.9218 | Val Loss: 0.4089 | Val Acc: 0.8586\n",
      "[Fold 1 | Epoch 32] Train Loss: 0.1987 | Train Acc: 0.9237 | Val Loss: 0.4587 | Val Acc: 0.8516\n",
      "[Fold 1 | Epoch 33] Train Loss: 0.2016 | Train Acc: 0.9238 | Val Loss: 0.4651 | Val Acc: 0.8536\n",
      "[Fold 1 | Epoch 34] Train Loss: 0.1795 | Train Acc: 0.9322 | Val Loss: 0.5078 | Val Acc: 0.8478\n",
      "[Fold 1 | Epoch 35] Train Loss: 0.1781 | Train Acc: 0.9320 | Val Loss: 0.4871 | Val Acc: 0.8498\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 9\n",
      "ACC: 0.8628 | MF1: 0.8156 | G-Mean: 0.8768\n",
      "[Class 0] Prec: 0.9637 | Rec: 0.8760 | F1: 0.9178 | GM: 0.9325\n",
      "[Class 1] Prec: 0.5491 | Rec: 0.5524 | F1: 0.5508 | GM: 0.7302\n",
      "[Class 2] Prec: 0.8877 | Rec: 0.9190 | F1: 0.9031 | GM: 0.9162\n",
      "[Class 3] Prec: 0.9538 | Rec: 0.8050 | F1: 0.8731 | GM: 0.8947\n",
      "[Class 4] Prec: 0.7931 | Rec: 0.8774 | F1: 0.8331 | GM: 0.9105\n",
      "\n",
      "===== Fold 2 =====\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5587 | Train Acc: 0.7911 | Val Loss: 0.4628 | Val Acc: 0.8270\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4669 | Train Acc: 0.8260 | Val Loss: 0.4563 | Val Acc: 0.8367\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4441 | Train Acc: 0.8349 | Val Loss: 0.4405 | Val Acc: 0.8494\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4335 | Train Acc: 0.8379 | Val Loss: 0.4234 | Val Acc: 0.8467\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4174 | Train Acc: 0.8445 | Val Loss: 0.5912 | Val Acc: 0.7931\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4061 | Train Acc: 0.8487 | Val Loss: 0.5028 | Val Acc: 0.8114\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4002 | Train Acc: 0.8507 | Val Loss: 0.3916 | Val Acc: 0.8560\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.3888 | Train Acc: 0.8581 | Val Loss: 0.3897 | Val Acc: 0.8550\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.3884 | Train Acc: 0.8570 | Val Loss: 0.4088 | Val Acc: 0.8494\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.3824 | Train Acc: 0.8595 | Val Loss: 0.4370 | Val Acc: 0.8433\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3729 | Train Acc: 0.8630 | Val Loss: 0.4067 | Val Acc: 0.8493\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3684 | Train Acc: 0.8618 | Val Loss: 0.4605 | Val Acc: 0.8374\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3566 | Train Acc: 0.8673 | Val Loss: 0.4093 | Val Acc: 0.8543\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3578 | Train Acc: 0.8688 | Val Loss: 0.4229 | Val Acc: 0.8466\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3428 | Train Acc: 0.8719 | Val Loss: 0.4241 | Val Acc: 0.8498\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3368 | Train Acc: 0.8742 | Val Loss: 0.4389 | Val Acc: 0.8367\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3341 | Train Acc: 0.8771 | Val Loss: 0.3875 | Val Acc: 0.8590\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3232 | Train Acc: 0.8799 | Val Loss: 0.4414 | Val Acc: 0.8477\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3156 | Train Acc: 0.8820 | Val Loss: 0.3867 | Val Acc: 0.8646\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3083 | Train Acc: 0.8838 | Val Loss: 0.4086 | Val Acc: 0.8590\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3000 | Train Acc: 0.8899 | Val Loss: 0.4479 | Val Acc: 0.8534\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.2921 | Train Acc: 0.8907 | Val Loss: 0.4031 | Val Acc: 0.8623\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.2806 | Train Acc: 0.8942 | Val Loss: 0.3980 | Val Acc: 0.8665\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.2711 | Train Acc: 0.8999 | Val Loss: 0.3924 | Val Acc: 0.8694\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.2633 | Train Acc: 0.9001 | Val Loss: 0.4150 | Val Acc: 0.8632\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.2460 | Train Acc: 0.9083 | Val Loss: 0.4189 | Val Acc: 0.8652\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.2432 | Train Acc: 0.9089 | Val Loss: 0.4193 | Val Acc: 0.8675\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.2369 | Train Acc: 0.9105 | Val Loss: 0.5707 | Val Acc: 0.8428\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.2200 | Train Acc: 0.9179 | Val Loss: 0.4522 | Val Acc: 0.8521\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.2181 | Train Acc: 0.9169 | Val Loss: 0.4771 | Val Acc: 0.8506\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.2058 | Train Acc: 0.9232 | Val Loss: 0.4642 | Val Acc: 0.8678\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.1957 | Train Acc: 0.9263 | Val Loss: 0.4463 | Val Acc: 0.8659\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.1844 | Train Acc: 0.9313 | Val Loss: 0.5264 | Val Acc: 0.8484\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.1837 | Train Acc: 0.9325 | Val Loss: 0.6263 | Val Acc: 0.8444\n",
      "[Fold 2 | Epoch 35] Train Loss: 0.1795 | Train Acc: 0.9351 | Val Loss: 0.5257 | Val Acc: 0.8521\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 24\n",
      "ACC: 0.8694 | MF1: 0.8300 | G-Mean: 0.8938\n",
      "[Class 0] Prec: 0.9413 | Rec: 0.9119 | F1: 0.9264 | GM: 0.9490\n",
      "[Class 1] Prec: 0.6016 | Rec: 0.5739 | F1: 0.5874 | GM: 0.7458\n",
      "[Class 2] Prec: 0.9203 | Rec: 0.8833 | F1: 0.9014 | GM: 0.9117\n",
      "[Class 3] Prec: 0.8924 | Rec: 0.9128 | F1: 0.9025 | GM: 0.9479\n",
      "[Class 4] Prec: 0.7854 | Rec: 0.8852 | F1: 0.8323 | GM: 0.9145\n",
      "\n",
      "===== Fold 3 =====\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5671 | Train Acc: 0.7872 | Val Loss: 0.4766 | Val Acc: 0.8229\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4623 | Train Acc: 0.8273 | Val Loss: 0.4476 | Val Acc: 0.8412\n",
      "[Fold 3 | Epoch 3] Train Loss: 0.4443 | Train Acc: 0.8345 | Val Loss: 0.4116 | Val Acc: 0.8533\n",
      "[Fold 3 | Epoch 4] Train Loss: 0.4218 | Train Acc: 0.8430 | Val Loss: 0.4342 | Val Acc: 0.8402\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4143 | Train Acc: 0.8469 | Val Loss: 0.4380 | Val Acc: 0.8392\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4022 | Train Acc: 0.8495 | Val Loss: 0.4075 | Val Acc: 0.8593\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.3964 | Train Acc: 0.8525 | Val Loss: 0.4337 | Val Acc: 0.8420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3 | Epoch 8] Train Loss: 0.3923 | Train Acc: 0.8556 | Val Loss: 0.4481 | Val Acc: 0.8341\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.3839 | Train Acc: 0.8586 | Val Loss: 0.4714 | Val Acc: 0.8193\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.3742 | Train Acc: 0.8594 | Val Loss: 0.4139 | Val Acc: 0.8493\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3712 | Train Acc: 0.8602 | Val Loss: 0.4660 | Val Acc: 0.8196\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3621 | Train Acc: 0.8644 | Val Loss: 0.4948 | Val Acc: 0.8146\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3536 | Train Acc: 0.8665 | Val Loss: 0.3935 | Val Acc: 0.8537\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3535 | Train Acc: 0.8673 | Val Loss: 0.4118 | Val Acc: 0.8553\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3394 | Train Acc: 0.8701 | Val Loss: 0.4906 | Val Acc: 0.8339\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3367 | Train Acc: 0.8719 | Val Loss: 0.4046 | Val Acc: 0.8575\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3263 | Train Acc: 0.8770 | Val Loss: 0.4283 | Val Acc: 0.8430\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3176 | Train Acc: 0.8822 | Val Loss: 0.4521 | Val Acc: 0.8417\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3071 | Train Acc: 0.8837 | Val Loss: 0.4586 | Val Acc: 0.8455\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.2982 | Train Acc: 0.8887 | Val Loss: 0.4305 | Val Acc: 0.8487\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.2959 | Train Acc: 0.8884 | Val Loss: 0.3925 | Val Acc: 0.8622\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.2862 | Train Acc: 0.8904 | Val Loss: 0.4387 | Val Acc: 0.8529\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.2765 | Train Acc: 0.8967 | Val Loss: 0.4414 | Val Acc: 0.8587\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.2702 | Train Acc: 0.8996 | Val Loss: 0.4929 | Val Acc: 0.8385\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.2627 | Train Acc: 0.9004 | Val Loss: 0.4914 | Val Acc: 0.8579\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.2499 | Train Acc: 0.9060 | Val Loss: 0.4758 | Val Acc: 0.8501\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.2411 | Train Acc: 0.9072 | Val Loss: 0.4361 | Val Acc: 0.8646\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.2355 | Train Acc: 0.9121 | Val Loss: 0.4751 | Val Acc: 0.8626\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.2254 | Train Acc: 0.9144 | Val Loss: 0.4703 | Val Acc: 0.8590\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.2221 | Train Acc: 0.9150 | Val Loss: 0.4695 | Val Acc: 0.8659\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.2095 | Train Acc: 0.9212 | Val Loss: 0.4503 | Val Acc: 0.8632\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.2018 | Train Acc: 0.9232 | Val Loss: 0.5463 | Val Acc: 0.8529\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.2039 | Train Acc: 0.9228 | Val Loss: 0.4897 | Val Acc: 0.8577\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.1879 | Train Acc: 0.9287 | Val Loss: 0.5025 | Val Acc: 0.8567\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.1898 | Train Acc: 0.9280 | Val Loss: 0.5125 | Val Acc: 0.8619\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 30\n",
      "ACC: 0.8659 | MF1: 0.8238 | G-Mean: 0.8815\n",
      "[Class 0] Prec: 0.9567 | Rec: 0.8927 | F1: 0.9236 | GM: 0.9408\n",
      "[Class 1] Prec: 0.6236 | Rec: 0.5478 | F1: 0.5832 | GM: 0.7306\n",
      "[Class 2] Prec: 0.8951 | Rec: 0.9049 | F1: 0.9000 | GM: 0.9122\n",
      "[Class 3] Prec: 0.9350 | Rec: 0.8284 | F1: 0.8785 | GM: 0.9064\n",
      "[Class 4] Prec: 0.7779 | Rec: 0.8975 | F1: 0.8334 | GM: 0.9173\n",
      "\n",
      "===== Fold 4 =====\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5528 | Train Acc: 0.7933 | Val Loss: 0.6094 | Val Acc: 0.7720\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4637 | Train Acc: 0.8271 | Val Loss: 0.6376 | Val Acc: 0.7776\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4393 | Train Acc: 0.8364 | Val Loss: 0.4555 | Val Acc: 0.8313\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4219 | Train Acc: 0.8440 | Val Loss: 0.5503 | Val Acc: 0.7964\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4146 | Train Acc: 0.8454 | Val Loss: 0.4036 | Val Acc: 0.8533\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4075 | Train Acc: 0.8481 | Val Loss: 0.4837 | Val Acc: 0.8338\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.3957 | Train Acc: 0.8543 | Val Loss: 0.4762 | Val Acc: 0.8128\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.3864 | Train Acc: 0.8557 | Val Loss: 0.3913 | Val Acc: 0.8549\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.3824 | Train Acc: 0.8586 | Val Loss: 0.4370 | Val Acc: 0.8377\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.3744 | Train Acc: 0.8610 | Val Loss: 0.4799 | Val Acc: 0.8183\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.3697 | Train Acc: 0.8621 | Val Loss: 0.3820 | Val Acc: 0.8620\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3579 | Train Acc: 0.8672 | Val Loss: 0.5210 | Val Acc: 0.8021\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3534 | Train Acc: 0.8702 | Val Loss: 0.4796 | Val Acc: 0.8189\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3475 | Train Acc: 0.8705 | Val Loss: 0.4009 | Val Acc: 0.8597\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3362 | Train Acc: 0.8771 | Val Loss: 0.4307 | Val Acc: 0.8430\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3328 | Train Acc: 0.8770 | Val Loss: 0.3970 | Val Acc: 0.8542\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3286 | Train Acc: 0.8768 | Val Loss: 0.4410 | Val Acc: 0.8430\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3215 | Train Acc: 0.8796 | Val Loss: 0.4328 | Val Acc: 0.8467\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3096 | Train Acc: 0.8844 | Val Loss: 0.5305 | Val Acc: 0.8200\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.2961 | Train Acc: 0.8891 | Val Loss: 0.3978 | Val Acc: 0.8590\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.2933 | Train Acc: 0.8895 | Val Loss: 0.4303 | Val Acc: 0.8530\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.2826 | Train Acc: 0.8958 | Val Loss: 0.4389 | Val Acc: 0.8468\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.2781 | Train Acc: 0.8962 | Val Loss: 0.4343 | Val Acc: 0.8576\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.2627 | Train Acc: 0.9030 | Val Loss: 0.5353 | Val Acc: 0.8186\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.2619 | Train Acc: 0.9029 | Val Loss: 0.4248 | Val Acc: 0.8559\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.2498 | Train Acc: 0.9082 | Val Loss: 0.4290 | Val Acc: 0.8563\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.2428 | Train Acc: 0.9088 | Val Loss: 0.4599 | Val Acc: 0.8470\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.2329 | Train Acc: 0.9134 | Val Loss: 0.5094 | Val Acc: 0.8556\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.2319 | Train Acc: 0.9141 | Val Loss: 0.4762 | Val Acc: 0.8580\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.2170 | Train Acc: 0.9189 | Val Loss: 0.5401 | Val Acc: 0.8467\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.2137 | Train Acc: 0.9203 | Val Loss: 0.4952 | Val Acc: 0.8550\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.2000 | Train Acc: 0.9271 | Val Loss: 0.5356 | Val Acc: 0.8339\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.2029 | Train Acc: 0.9244 | Val Loss: 0.5059 | Val Acc: 0.8563\n",
      "[Fold 4 | Epoch 34] Train Loss: 0.1918 | Train Acc: 0.9271 | Val Loss: 0.4748 | Val Acc: 0.8576\n",
      "[Fold 4 | Epoch 35] Train Loss: 0.1864 | Train Acc: 0.9307 | Val Loss: 0.4973 | Val Acc: 0.8530\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 11\n",
      "ACC: 0.8620 | MF1: 0.8075 | G-Mean: 0.8770\n",
      "[Class 0] Prec: 0.9204 | Rec: 0.9015 | F1: 0.9108 | GM: 0.9409\n",
      "[Class 1] Prec: 0.5688 | Rec: 0.4536 | F1: 0.5047 | GM: 0.6650\n",
      "[Class 2] Prec: 0.9179 | Rec: 0.8771 | F1: 0.8970 | GM: 0.9089\n",
      "[Class 3] Prec: 0.8510 | Rec: 0.9393 | F1: 0.8930 | GM: 0.9572\n",
      "[Class 4] Prec: 0.7866 | Rec: 0.8829 | F1: 0.8320 | GM: 0.9131\n",
      "\n",
      "===== Fold 5 =====\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.5543 | Train Acc: 0.7958 | Val Loss: 0.5564 | Val Acc: 0.7908\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4580 | Train Acc: 0.8295 | Val Loss: 0.8891 | Val Acc: 0.7360\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4426 | Train Acc: 0.8361 | Val Loss: 0.5140 | Val Acc: 0.8143\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4296 | Train Acc: 0.8443 | Val Loss: 0.4338 | Val Acc: 0.8405\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4164 | Train Acc: 0.8471 | Val Loss: 0.4533 | Val Acc: 0.8252\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4056 | Train Acc: 0.8486 | Val Loss: 0.4179 | Val Acc: 0.8461\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.3972 | Train Acc: 0.8527 | Val Loss: 0.4751 | Val Acc: 0.8313\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.3949 | Train Acc: 0.8539 | Val Loss: 0.4627 | Val Acc: 0.8321\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.3882 | Train Acc: 0.8567 | Val Loss: 0.4104 | Val Acc: 0.8488\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.3762 | Train Acc: 0.8615 | Val Loss: 0.4409 | Val Acc: 0.8390\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.3735 | Train Acc: 0.8618 | Val Loss: 0.4199 | Val Acc: 0.8463\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3656 | Train Acc: 0.8637 | Val Loss: 0.4067 | Val Acc: 0.8529\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3583 | Train Acc: 0.8673 | Val Loss: 0.3869 | Val Acc: 0.8606\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3487 | Train Acc: 0.8699 | Val Loss: 0.4232 | Val Acc: 0.8418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 15] Train Loss: 0.3390 | Train Acc: 0.8749 | Val Loss: 0.4185 | Val Acc: 0.8493\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3355 | Train Acc: 0.8753 | Val Loss: 0.4299 | Val Acc: 0.8473\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3246 | Train Acc: 0.8787 | Val Loss: 0.4078 | Val Acc: 0.8544\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3183 | Train Acc: 0.8824 | Val Loss: 0.4586 | Val Acc: 0.8292\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3084 | Train Acc: 0.8871 | Val Loss: 0.4022 | Val Acc: 0.8573\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.2986 | Train Acc: 0.8876 | Val Loss: 0.3963 | Val Acc: 0.8665\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.2922 | Train Acc: 0.8919 | Val Loss: 0.5587 | Val Acc: 0.8104\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.2814 | Train Acc: 0.8967 | Val Loss: 0.4603 | Val Acc: 0.8464\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.2754 | Train Acc: 0.8975 | Val Loss: 0.4455 | Val Acc: 0.8590\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.2653 | Train Acc: 0.9010 | Val Loss: 0.4601 | Val Acc: 0.8547\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.2587 | Train Acc: 0.9043 | Val Loss: 0.5157 | Val Acc: 0.8322\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.2487 | Train Acc: 0.9080 | Val Loss: 0.4463 | Val Acc: 0.8553\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.2358 | Train Acc: 0.9131 | Val Loss: 0.5572 | Val Acc: 0.8263\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.2350 | Train Acc: 0.9131 | Val Loss: 0.4223 | Val Acc: 0.8653\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.2198 | Train Acc: 0.9173 | Val Loss: 0.5699 | Val Acc: 0.8453\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.2155 | Train Acc: 0.9179 | Val Loss: 0.4558 | Val Acc: 0.8533\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.2126 | Train Acc: 0.9206 | Val Loss: 0.6055 | Val Acc: 0.8245\n",
      "[Fold 5 | Epoch 32] Train Loss: 0.1994 | Train Acc: 0.9257 | Val Loss: 0.5503 | Val Acc: 0.8346\n",
      "[Fold 5 | Epoch 33] Train Loss: 0.1912 | Train Acc: 0.9275 | Val Loss: 0.4635 | Val Acc: 0.8648\n",
      "[Fold 5 | Epoch 34] Train Loss: 0.1805 | Train Acc: 0.9315 | Val Loss: 0.5310 | Val Acc: 0.8587\n",
      "[Fold 5 | Epoch 35] Train Loss: 0.1776 | Train Acc: 0.9332 | Val Loss: 0.4898 | Val Acc: 0.8570\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 20\n",
      "ACC: 0.8665 | MF1: 0.8175 | G-Mean: 0.8706\n",
      "[Class 0] Prec: 0.9232 | Rec: 0.9104 | F1: 0.9167 | GM: 0.9459\n",
      "[Class 1] Prec: 0.6630 | Rec: 0.4745 | F1: 0.5531 | GM: 0.6823\n",
      "[Class 2] Prec: 0.8697 | Rec: 0.9310 | F1: 0.8993 | GM: 0.9141\n",
      "[Class 3] Prec: 0.9491 | Rec: 0.8252 | F1: 0.8828 | GM: 0.9054\n",
      "[Class 4] Prec: 0.8134 | Rec: 0.8588 | F1: 0.8355 | GM: 0.9053\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8653 | MF1: 0.8192 | G-Mean: 0.8804\n",
      "[Class 0] Prec: 0.9402 | Rec: 0.8985 | F1: 0.9189 | GM: 0.9419\n",
      "[Class 1] Prec: 0.5986 | Rec: 0.5214 | F1: 0.5573 | GM: 0.7122\n",
      "[Class 2] Prec: 0.8974 | Rec: 0.9030 | F1: 0.9002 | GM: 0.9127\n",
      "[Class 3] Prec: 0.9119 | Rec: 0.8624 | F1: 0.8864 | GM: 0.9230\n",
      "[Class 4] Prec: 0.7908 | Rec: 0.8805 | F1: 0.8333 | GM: 0.9123\n",
      "Confusion Matrix:\n",
      "[[ 5695   363   116     8   156]\n",
      " [  230  1305   388     4   576]\n",
      " [   69   210 13491   358   813]\n",
      " [    4     1   604  3829     2]\n",
      " [   59   301   434     0  5849]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from model_build import FinalNetwork\n",
    "import seaborn as sns\n",
    "# ==== Load and Normalize Data ====\n",
    "\n",
    "df = pd.read_csv(\"pruned_dataset3.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "# Z-score normalization\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== Evaluation Metric Function ====\n",
    "def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    gmeans = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        tn = np.sum((y_pred != c) & (y_true != c))\n",
    "        fp = np.sum((y_pred == c) & (y_true != c))\n",
    "        gm = np.sqrt((tp / (tp + fn + 1e-6)) * (tn / (tn + fp + 1e-6)))\n",
    "        gmeans.append(gm)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, mf1, np.mean(gmeans), prec, rec, f1s, gmeans, cm\n",
    "\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "    X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "    X_val, y_val = X_all[val_idx], y_all[val_idx]\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "\n",
    "    model = FinalNetwork(C=8, num_classes=num_classes, layers=7, genotype=searched_genotype).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "\n",
    "    for epoch in range(35):  # You can change this to 50 or more\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b89059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Entropy-based pruning ===\n",
    "def compute_filter_entropy(weight_tensor):\n",
    "    entropy_list = []\n",
    "    for filt in weight_tensor:\n",
    "        filt_flat = filt.view(filt.size(0), -1)\n",
    "        norms = torch.norm(filt_flat, dim=1) + 1e-6\n",
    "        p = norms / norms.sum()\n",
    "        entropy = -torch.sum(p * torch.log2(p))\n",
    "        entropy_list.append(entropy.item())\n",
    "    return entropy_list\n",
    "\n",
    "def prune_model_entropy(model, prune_ratio=0.5):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv1d):\n",
    "            weight = module.weight.data.detach().cpu()\n",
    "            entropy = compute_filter_entropy(weight)\n",
    "            entropy_tensor = torch.tensor(entropy)\n",
    "            k = int((1 - prune_ratio) * len(entropy))\n",
    "            topk_indices = torch.topk(entropy_tensor, k=k).indices\n",
    "            mask = torch.zeros_like(entropy_tensor)\n",
    "            mask[topk_indices] = 1.0\n",
    "            full_mask = mask[:, None, None].expand_as(weight).to(module.weight.device)\n",
    "            module.weight.data *= full_mask\n",
    "    return model\n",
    "\n",
    "def count_pruned_weights(model):\n",
    "    total, nonzero = 0, 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, (nn.Conv1d, nn.Linear)):\n",
    "            w = module.weight.data\n",
    "            total += w.numel()\n",
    "            nonzero += w.nonzero().size(0)\n",
    "    zero = total - nonzero\n",
    "    print(f\"[INFO] Total weights: {total}\")\n",
    "    print(f\"[INFO] Non-zero weights: {nonzero}\")\n",
    "    print(f\"[INFO] Pruned weights: {zero}\")\n",
    "    print(f\"[INFO] Pruned ratio: {100 * zero / total:.2f}%\")\n",
    "\n",
    "def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    gmeans = []\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        recall_c = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        gmeans.append(recall_c)\n",
    "\n",
    "    mgm = np.sqrt(np.prod(gmeans)) if np.all(np.array(gmeans) > 0) else 0.0\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, mf1, mgm, prec, rec, f1s, gmeans, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c806cef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[INFO] Total parameters BEFORE pruning: 83,789\n",
      "[INFO] Non-zero parameters AFTER pruning: 42,377\n",
      "[INFO] Pruned parameters: 41,412 (49.42%)\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5563 | Train Acc: 0.7889 | Val Loss: 0.6750 | Val Acc: 0.7598\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4789 | Train Acc: 0.8202 | Val Loss: 0.4674 | Val Acc: 0.8263\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4606 | Train Acc: 0.8298 | Val Loss: 0.5882 | Val Acc: 0.7781\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4428 | Train Acc: 0.8355 | Val Loss: 0.4680 | Val Acc: 0.8243\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4296 | Train Acc: 0.8408 | Val Loss: 0.4058 | Val Acc: 0.8501\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4219 | Train Acc: 0.8459 | Val Loss: 0.4700 | Val Acc: 0.8346\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.4104 | Train Acc: 0.8491 | Val Loss: 0.4327 | Val Acc: 0.8438\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.4068 | Train Acc: 0.8483 | Val Loss: 0.4164 | Val Acc: 0.8467\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.4023 | Train Acc: 0.8509 | Val Loss: 0.4268 | Val Acc: 0.8431\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.3936 | Train Acc: 0.8564 | Val Loss: 0.4303 | Val Acc: 0.8477\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3930 | Train Acc: 0.8529 | Val Loss: 0.3899 | Val Acc: 0.8592\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3864 | Train Acc: 0.8563 | Val Loss: 0.5121 | Val Acc: 0.8139\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3811 | Train Acc: 0.8567 | Val Loss: 0.4380 | Val Acc: 0.8566\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3781 | Train Acc: 0.8604 | Val Loss: 0.4333 | Val Acc: 0.8384\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3717 | Train Acc: 0.8609 | Val Loss: 0.3747 | Val Acc: 0.8613\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3631 | Train Acc: 0.8649 | Val Loss: 0.3863 | Val Acc: 0.8616\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3653 | Train Acc: 0.8634 | Val Loss: 0.3832 | Val Acc: 0.8607\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3534 | Train Acc: 0.8692 | Val Loss: 0.4105 | Val Acc: 0.8496\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3511 | Train Acc: 0.8710 | Val Loss: 0.4133 | Val Acc: 0.8507\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3413 | Train Acc: 0.8739 | Val Loss: 0.4223 | Val Acc: 0.8513\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3414 | Train Acc: 0.8732 | Val Loss: 0.4056 | Val Acc: 0.8470\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.3341 | Train Acc: 0.8753 | Val Loss: 0.3986 | Val Acc: 0.8560\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.3311 | Train Acc: 0.8753 | Val Loss: 0.4168 | Val Acc: 0.8490\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.3188 | Train Acc: 0.8805 | Val Loss: 0.4105 | Val Acc: 0.8589\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.3178 | Train Acc: 0.8801 | Val Loss: 0.3758 | Val Acc: 0.8652\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.3107 | Train Acc: 0.8866 | Val Loss: 0.4434 | Val Acc: 0.8434\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.3098 | Train Acc: 0.8842 | Val Loss: 0.4784 | Val Acc: 0.8255\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.3017 | Train Acc: 0.8851 | Val Loss: 0.4162 | Val Acc: 0.8533\n",
      "[Fold 1 | Epoch 29] Train Loss: 0.2927 | Train Acc: 0.8909 | Val Loss: 0.3904 | Val Acc: 0.8610\n",
      "[Fold 1 | Epoch 30] Train Loss: 0.2863 | Train Acc: 0.8926 | Val Loss: 0.6592 | Val Acc: 0.7678\n",
      "[Fold 1 | Epoch 31] Train Loss: 0.2842 | Train Acc: 0.8943 | Val Loss: 0.4034 | Val Acc: 0.8607\n",
      "[Fold 1 | Epoch 32] Train Loss: 0.2774 | Train Acc: 0.8962 | Val Loss: 0.4094 | Val Acc: 0.8665\n",
      "[Fold 1 | Epoch 33] Train Loss: 0.2787 | Train Acc: 0.8961 | Val Loss: 0.4197 | Val Acc: 0.8582\n",
      "[Fold 1 | Epoch 34] Train Loss: 0.2698 | Train Acc: 0.8989 | Val Loss: 0.4227 | Val Acc: 0.8546\n",
      "[Fold 1 | Epoch 35] Train Loss: 0.2629 | Train Acc: 0.9016 | Val Loss: 0.4892 | Val Acc: 0.8322\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 32\n",
      "ACC: 0.8665 | MF1: 0.8170 | G-Mean: 0.5562\n",
      "[Class 0] Prec: 0.9038 | Rec: 0.9219 | F1: 0.9128 | GM: 0.9219\n",
      "[Class 1] Prec: 0.6475 | Rec: 0.4647 | F1: 0.5411 | GM: 0.4647\n",
      "[Class 2] Prec: 0.9220 | Rec: 0.8846 | F1: 0.9029 | GM: 0.8846\n",
      "[Class 3] Prec: 0.8906 | Rec: 0.9093 | F1: 0.8998 | GM: 0.9093\n",
      "[Class 4] Prec: 0.7691 | Rec: 0.8977 | F1: 0.8285 | GM: 0.8977\n",
      "\n",
      "===== Fold 2 =====\n",
      "[INFO] Total parameters BEFORE pruning: 83,789\n",
      "[INFO] Non-zero parameters AFTER pruning: 42,377\n",
      "[INFO] Pruned parameters: 41,412 (49.42%)\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5690 | Train Acc: 0.7830 | Val Loss: 0.4670 | Val Acc: 0.8285\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4741 | Train Acc: 0.8242 | Val Loss: 0.5138 | Val Acc: 0.8120\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4536 | Train Acc: 0.8310 | Val Loss: 0.4246 | Val Acc: 0.8448\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4403 | Train Acc: 0.8374 | Val Loss: 0.4420 | Val Acc: 0.8335\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4306 | Train Acc: 0.8385 | Val Loss: 0.4054 | Val Acc: 0.8510\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4231 | Train Acc: 0.8449 | Val Loss: 0.4641 | Val Acc: 0.8246\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4109 | Train Acc: 0.8472 | Val Loss: 0.5852 | Val Acc: 0.7922\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.4076 | Train Acc: 0.8479 | Val Loss: 0.4369 | Val Acc: 0.8391\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.3983 | Train Acc: 0.8533 | Val Loss: 0.4200 | Val Acc: 0.8507\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.3930 | Train Acc: 0.8540 | Val Loss: 0.4103 | Val Acc: 0.8506\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3889 | Train Acc: 0.8560 | Val Loss: 0.5076 | Val Acc: 0.8194\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3861 | Train Acc: 0.8587 | Val Loss: 0.4775 | Val Acc: 0.8223\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3731 | Train Acc: 0.8616 | Val Loss: 0.4018 | Val Acc: 0.8549\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3733 | Train Acc: 0.8628 | Val Loss: 0.4156 | Val Acc: 0.8473\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3654 | Train Acc: 0.8649 | Val Loss: 0.4103 | Val Acc: 0.8484\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3598 | Train Acc: 0.8682 | Val Loss: 0.4771 | Val Acc: 0.8286\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3534 | Train Acc: 0.8677 | Val Loss: 0.5233 | Val Acc: 0.8197\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3530 | Train Acc: 0.8689 | Val Loss: 0.4000 | Val Acc: 0.8521\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3426 | Train Acc: 0.8714 | Val Loss: 0.4036 | Val Acc: 0.8520\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3394 | Train Acc: 0.8754 | Val Loss: 0.4004 | Val Acc: 0.8592\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3318 | Train Acc: 0.8773 | Val Loss: 0.4132 | Val Acc: 0.8468\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.3262 | Train Acc: 0.8771 | Val Loss: 0.4227 | Val Acc: 0.8520\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.3185 | Train Acc: 0.8818 | Val Loss: 0.3848 | Val Acc: 0.8649\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.3125 | Train Acc: 0.8838 | Val Loss: 0.4294 | Val Acc: 0.8497\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.3106 | Train Acc: 0.8836 | Val Loss: 0.4003 | Val Acc: 0.8615\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.2991 | Train Acc: 0.8888 | Val Loss: 0.4048 | Val Acc: 0.8559\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.2979 | Train Acc: 0.8891 | Val Loss: 0.4460 | Val Acc: 0.8488\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.2885 | Train Acc: 0.8932 | Val Loss: 0.4391 | Val Acc: 0.8566\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.2871 | Train Acc: 0.8912 | Val Loss: 0.4432 | Val Acc: 0.8478\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.2773 | Train Acc: 0.8962 | Val Loss: 0.4695 | Val Acc: 0.8470\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.2708 | Train Acc: 0.8983 | Val Loss: 0.4822 | Val Acc: 0.8374\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.2668 | Train Acc: 0.8994 | Val Loss: 0.4773 | Val Acc: 0.8552\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.2619 | Train Acc: 0.9032 | Val Loss: 0.4278 | Val Acc: 0.8645\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.2552 | Train Acc: 0.9034 | Val Loss: 0.4786 | Val Acc: 0.8405\n",
      "[Fold 2 | Epoch 35] Train Loss: 0.2504 | Train Acc: 0.9068 | Val Loss: 0.5142 | Val Acc: 0.8402\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 23\n",
      "ACC: 0.8649 | MF1: 0.8172 | G-Mean: 0.5668\n",
      "[Class 0] Prec: 0.9160 | Rec: 0.9019 | F1: 0.9089 | GM: 0.9019\n",
      "[Class 1] Prec: 0.6091 | Rec: 0.4980 | F1: 0.5480 | GM: 0.4980\n",
      "[Class 2] Prec: 0.9128 | Rec: 0.8924 | F1: 0.9025 | GM: 0.8924\n",
      "[Class 3] Prec: 0.8767 | Rec: 0.9204 | F1: 0.8980 | GM: 0.9204\n",
      "[Class 4] Prec: 0.7902 | Rec: 0.8710 | F1: 0.8286 | GM: 0.8710\n",
      "\n",
      "===== Fold 3 =====\n",
      "[INFO] Total parameters BEFORE pruning: 83,789\n",
      "[INFO] Non-zero parameters AFTER pruning: 42,377\n",
      "[INFO] Pruned parameters: 41,412 (49.42%)\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5804 | Train Acc: 0.7810 | Val Loss: 0.5279 | Val Acc: 0.8074\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4823 | Train Acc: 0.8204 | Val Loss: 0.4889 | Val Acc: 0.8209\n",
      "[Fold 3 | Epoch 3] Train Loss: 0.4559 | Train Acc: 0.8310 | Val Loss: 0.5950 | Val Acc: 0.7687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3 | Epoch 4] Train Loss: 0.4396 | Train Acc: 0.8370 | Val Loss: 0.4441 | Val Acc: 0.8463\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4337 | Train Acc: 0.8412 | Val Loss: 0.4566 | Val Acc: 0.8273\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4203 | Train Acc: 0.8438 | Val Loss: 0.4317 | Val Acc: 0.8418\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4196 | Train Acc: 0.8436 | Val Loss: 0.4289 | Val Acc: 0.8434\n",
      "[Fold 3 | Epoch 8] Train Loss: 0.4124 | Train Acc: 0.8473 | Val Loss: 0.4577 | Val Acc: 0.8385\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.4028 | Train Acc: 0.8514 | Val Loss: 0.4849 | Val Acc: 0.8248\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.3974 | Train Acc: 0.8542 | Val Loss: 0.4261 | Val Acc: 0.8425\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3920 | Train Acc: 0.8556 | Val Loss: 0.4492 | Val Acc: 0.8422\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3910 | Train Acc: 0.8554 | Val Loss: 0.4207 | Val Acc: 0.8397\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3836 | Train Acc: 0.8575 | Val Loss: 0.4037 | Val Acc: 0.8544\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3785 | Train Acc: 0.8608 | Val Loss: 0.4050 | Val Acc: 0.8504\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3758 | Train Acc: 0.8602 | Val Loss: 0.4028 | Val Acc: 0.8556\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3699 | Train Acc: 0.8649 | Val Loss: 0.4825 | Val Acc: 0.8322\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3648 | Train Acc: 0.8640 | Val Loss: 0.4228 | Val Acc: 0.8543\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3567 | Train Acc: 0.8682 | Val Loss: 0.4169 | Val Acc: 0.8503\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3554 | Train Acc: 0.8692 | Val Loss: 0.4734 | Val Acc: 0.8263\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.3475 | Train Acc: 0.8694 | Val Loss: 0.3932 | Val Acc: 0.8599\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.3420 | Train Acc: 0.8706 | Val Loss: 0.5095 | Val Acc: 0.8225\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.3399 | Train Acc: 0.8734 | Val Loss: 0.4777 | Val Acc: 0.8226\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.3337 | Train Acc: 0.8763 | Val Loss: 0.5143 | Val Acc: 0.8068\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.3291 | Train Acc: 0.8783 | Val Loss: 0.4245 | Val Acc: 0.8563\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.3256 | Train Acc: 0.8784 | Val Loss: 0.4768 | Val Acc: 0.8364\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.3152 | Train Acc: 0.8824 | Val Loss: 0.6092 | Val Acc: 0.7974\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.3128 | Train Acc: 0.8846 | Val Loss: 0.4040 | Val Acc: 0.8572\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.3072 | Train Acc: 0.8837 | Val Loss: 0.3941 | Val Acc: 0.8613\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.3046 | Train Acc: 0.8857 | Val Loss: 0.3996 | Val Acc: 0.8618\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.2970 | Train Acc: 0.8879 | Val Loss: 0.4391 | Val Acc: 0.8440\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.2885 | Train Acc: 0.8942 | Val Loss: 0.4448 | Val Acc: 0.8580\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.2856 | Train Acc: 0.8950 | Val Loss: 0.4261 | Val Acc: 0.8554\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.2787 | Train Acc: 0.8946 | Val Loss: 0.4073 | Val Acc: 0.8593\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.2742 | Train Acc: 0.8967 | Val Loss: 0.4008 | Val Acc: 0.8623\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.2687 | Train Acc: 0.8996 | Val Loss: 0.4302 | Val Acc: 0.8567\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 34\n",
      "ACC: 0.8623 | MF1: 0.8227 | G-Mean: 0.6072\n",
      "[Class 0] Prec: 0.9083 | Rec: 0.9034 | F1: 0.9059 | GM: 0.9034\n",
      "[Class 1] Prec: 0.5511 | Rec: 0.6137 | F1: 0.5807 | GM: 0.6137\n",
      "[Class 2] Prec: 0.9120 | Rec: 0.8910 | F1: 0.9014 | GM: 0.8910\n",
      "[Class 3] Prec: 0.9110 | Rec: 0.9060 | F1: 0.9085 | GM: 0.9060\n",
      "[Class 4] Prec: 0.8101 | Rec: 0.8237 | F1: 0.8168 | GM: 0.8237\n",
      "\n",
      "===== Fold 4 =====\n",
      "[INFO] Total parameters BEFORE pruning: 83,789\n",
      "[INFO] Non-zero parameters AFTER pruning: 42,377\n",
      "[INFO] Pruned parameters: 41,412 (49.42%)\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5846 | Train Acc: 0.7786 | Val Loss: 0.7295 | Val Acc: 0.7475\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4686 | Train Acc: 0.8278 | Val Loss: 0.5225 | Val Acc: 0.8131\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4531 | Train Acc: 0.8316 | Val Loss: 0.4370 | Val Acc: 0.8405\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4400 | Train Acc: 0.8374 | Val Loss: 0.5371 | Val Acc: 0.8180\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4305 | Train Acc: 0.8426 | Val Loss: 0.5029 | Val Acc: 0.8147\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4197 | Train Acc: 0.8449 | Val Loss: 0.4271 | Val Acc: 0.8468\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.4120 | Train Acc: 0.8496 | Val Loss: 0.4866 | Val Acc: 0.8269\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.4089 | Train Acc: 0.8483 | Val Loss: 0.4146 | Val Acc: 0.8461\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.3997 | Train Acc: 0.8526 | Val Loss: 0.4396 | Val Acc: 0.8438\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.3973 | Train Acc: 0.8539 | Val Loss: 0.3853 | Val Acc: 0.8613\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.3934 | Train Acc: 0.8540 | Val Loss: 0.4003 | Val Acc: 0.8583\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3844 | Train Acc: 0.8593 | Val Loss: 0.3946 | Val Acc: 0.8559\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3847 | Train Acc: 0.8561 | Val Loss: 0.3869 | Val Acc: 0.8612\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3737 | Train Acc: 0.8620 | Val Loss: 0.3835 | Val Acc: 0.8618\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3704 | Train Acc: 0.8637 | Val Loss: 0.4144 | Val Acc: 0.8497\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3676 | Train Acc: 0.8645 | Val Loss: 0.3905 | Val Acc: 0.8562\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3620 | Train Acc: 0.8674 | Val Loss: 0.3959 | Val Acc: 0.8599\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3594 | Train Acc: 0.8683 | Val Loss: 0.4198 | Val Acc: 0.8517\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3452 | Train Acc: 0.8714 | Val Loss: 0.4984 | Val Acc: 0.8329\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3488 | Train Acc: 0.8700 | Val Loss: 0.4453 | Val Acc: 0.8415\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3469 | Train Acc: 0.8698 | Val Loss: 0.4067 | Val Acc: 0.8592\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.3390 | Train Acc: 0.8706 | Val Loss: 0.4011 | Val Acc: 0.8567\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.3304 | Train Acc: 0.8785 | Val Loss: 0.4152 | Val Acc: 0.8493\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.3273 | Train Acc: 0.8801 | Val Loss: 0.4124 | Val Acc: 0.8524\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.3238 | Train Acc: 0.8781 | Val Loss: 0.3918 | Val Acc: 0.8600\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.3124 | Train Acc: 0.8851 | Val Loss: 0.4477 | Val Acc: 0.8519\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.3137 | Train Acc: 0.8831 | Val Loss: 0.4112 | Val Acc: 0.8536\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.3056 | Train Acc: 0.8866 | Val Loss: 0.4169 | Val Acc: 0.8573\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.3013 | Train Acc: 0.8872 | Val Loss: 0.4499 | Val Acc: 0.8562\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.2986 | Train Acc: 0.8880 | Val Loss: 0.4476 | Val Acc: 0.8384\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.2948 | Train Acc: 0.8903 | Val Loss: 0.5895 | Val Acc: 0.8359\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.2856 | Train Acc: 0.8931 | Val Loss: 0.4117 | Val Acc: 0.8556\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.2791 | Train Acc: 0.8955 | Val Loss: 0.4238 | Val Acc: 0.8572\n",
      "[Fold 4 | Epoch 34] Train Loss: 0.2757 | Train Acc: 0.8966 | Val Loss: 0.4796 | Val Acc: 0.8425\n",
      "[Fold 4 | Epoch 35] Train Loss: 0.2632 | Train Acc: 0.9013 | Val Loss: 0.4765 | Val Acc: 0.8349\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 14\n",
      "ACC: 0.8618 | MF1: 0.8118 | G-Mean: 0.5623\n",
      "[Class 0] Prec: 0.8963 | Rec: 0.9088 | F1: 0.9025 | GM: 0.9088\n",
      "[Class 1] Prec: 0.5598 | Rec: 0.4863 | F1: 0.5205 | GM: 0.4863\n",
      "[Class 2] Prec: 0.9327 | Rec: 0.8775 | F1: 0.9043 | GM: 0.8775\n",
      "[Class 3] Prec: 0.8996 | Rec: 0.9215 | F1: 0.9104 | GM: 0.9215\n",
      "[Class 4] Prec: 0.7665 | Rec: 0.8847 | F1: 0.8214 | GM: 0.8847\n",
      "\n",
      "===== Fold 5 =====\n",
      "[INFO] Total parameters BEFORE pruning: 83,789\n",
      "[INFO] Non-zero parameters AFTER pruning: 42,377\n",
      "[INFO] Pruned parameters: 41,412 (49.42%)\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.5636 | Train Acc: 0.7866 | Val Loss: 0.5932 | Val Acc: 0.7839\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4795 | Train Acc: 0.8206 | Val Loss: 0.5046 | Val Acc: 0.8166\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4517 | Train Acc: 0.8332 | Val Loss: 0.4636 | Val Acc: 0.8265\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4444 | Train Acc: 0.8335 | Val Loss: 0.4097 | Val Acc: 0.8484\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4288 | Train Acc: 0.8414 | Val Loss: 0.4505 | Val Acc: 0.8334\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4278 | Train Acc: 0.8409 | Val Loss: 0.4109 | Val Acc: 0.8530\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.4128 | Train Acc: 0.8462 | Val Loss: 0.4010 | Val Acc: 0.8523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 8] Train Loss: 0.4135 | Train Acc: 0.8485 | Val Loss: 0.4008 | Val Acc: 0.8523\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.4109 | Train Acc: 0.8456 | Val Loss: 0.4212 | Val Acc: 0.8443\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.3965 | Train Acc: 0.8553 | Val Loss: 0.3885 | Val Acc: 0.8580\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.3940 | Train Acc: 0.8542 | Val Loss: 0.4032 | Val Acc: 0.8523\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3915 | Train Acc: 0.8553 | Val Loss: 0.4000 | Val Acc: 0.8517\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3883 | Train Acc: 0.8558 | Val Loss: 0.3858 | Val Acc: 0.8612\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3847 | Train Acc: 0.8587 | Val Loss: 0.4254 | Val Acc: 0.8481\n",
      "[Fold 5 | Epoch 15] Train Loss: 0.3793 | Train Acc: 0.8589 | Val Loss: 0.4785 | Val Acc: 0.8220\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3703 | Train Acc: 0.8630 | Val Loss: 0.3696 | Val Acc: 0.8656\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3722 | Train Acc: 0.8623 | Val Loss: 0.4269 | Val Acc: 0.8407\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3627 | Train Acc: 0.8657 | Val Loss: 0.3888 | Val Acc: 0.8587\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3585 | Train Acc: 0.8661 | Val Loss: 0.3825 | Val Acc: 0.8547\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3568 | Train Acc: 0.8667 | Val Loss: 0.3971 | Val Acc: 0.8504\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.3548 | Train Acc: 0.8662 | Val Loss: 0.4323 | Val Acc: 0.8364\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.3422 | Train Acc: 0.8719 | Val Loss: 0.5046 | Val Acc: 0.8160\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.3448 | Train Acc: 0.8713 | Val Loss: 0.3734 | Val Acc: 0.8602\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.3363 | Train Acc: 0.8752 | Val Loss: 0.3868 | Val Acc: 0.8549\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.3296 | Train Acc: 0.8772 | Val Loss: 0.4030 | Val Acc: 0.8560\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.3277 | Train Acc: 0.8792 | Val Loss: 0.3929 | Val Acc: 0.8557\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.3162 | Train Acc: 0.8843 | Val Loss: 0.3949 | Val Acc: 0.8572\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.3128 | Train Acc: 0.8825 | Val Loss: 0.4217 | Val Acc: 0.8640\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.3110 | Train Acc: 0.8846 | Val Loss: 0.4278 | Val Acc: 0.8523\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.3007 | Train Acc: 0.8881 | Val Loss: 0.4228 | Val Acc: 0.8579\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.2921 | Train Acc: 0.8921 | Val Loss: 0.3988 | Val Acc: 0.8605\n",
      "[Fold 5 | Epoch 32] Train Loss: 0.2864 | Train Acc: 0.8932 | Val Loss: 0.4001 | Val Acc: 0.8630\n",
      "[Fold 5 | Epoch 33] Train Loss: 0.2899 | Train Acc: 0.8911 | Val Loss: 0.4178 | Val Acc: 0.8542\n",
      "[Fold 5 | Epoch 34] Train Loss: 0.2837 | Train Acc: 0.8927 | Val Loss: 0.4011 | Val Acc: 0.8682\n",
      "[Fold 5 | Epoch 35] Train Loss: 0.2785 | Train Acc: 0.8974 | Val Loss: 0.4312 | Val Acc: 0.8603\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 34\n",
      "ACC: 0.8682 | MF1: 0.8223 | G-Mean: 0.5726\n",
      "[Class 0] Prec: 0.9454 | Rec: 0.8825 | F1: 0.9129 | GM: 0.8825\n",
      "[Class 1] Prec: 0.6265 | Rec: 0.5000 | F1: 0.5562 | GM: 0.5000\n",
      "[Class 2] Prec: 0.9088 | Rec: 0.8971 | F1: 0.9029 | GM: 0.8971\n",
      "[Class 3] Prec: 0.8866 | Rec: 0.9336 | F1: 0.9095 | GM: 0.9336\n",
      "[Class 4] Prec: 0.7804 | Rec: 0.8870 | F1: 0.8303 | GM: 0.8870\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8647 | MF1: 0.8184 | G-Mean: 0.5743\n",
      "[Class 0] Prec: 0.9135 | Rec: 0.9037 | F1: 0.9086 | GM: 0.9037\n",
      "[Class 1] Prec: 0.5938 | Rec: 0.5125 | F1: 0.5502 | GM: 0.5125\n",
      "[Class 2] Prec: 0.9175 | Rec: 0.8885 | F1: 0.9028 | GM: 0.8885\n",
      "[Class 3] Prec: 0.8927 | Rec: 0.9181 | F1: 0.9052 | GM: 0.9181\n",
      "[Class 4] Prec: 0.7825 | Rec: 0.8728 | F1: 0.8252 | GM: 0.8728\n",
      "Confusion Matrix:\n",
      "[[ 5847   288   136    28   171]\n",
      " [  318  1307   289     2   634]\n",
      " [  120   279 13128   469   779]\n",
      " [   14     0   351  4150     5]\n",
      " [  102   327   404     0  5717]]\n"
     ]
    }
   ],
   "source": [
    "#p7\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ==== Load and Normalize Data ====\n",
    "\n",
    "df = pd.read_csv(\"pruned_dataset3.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "     # === Build and Prune Model ===\n",
    "    model_unpruned = FinalNetwork(C=8, num_classes=num_classes, layers=7, genotype=searched_genotype).to(device)\n",
    "    total_params_before = sum(p.numel() for p in model_unpruned.parameters())\n",
    "    print(f\"[INFO] Total parameters BEFORE pruning: {total_params_before:,}\")\n",
    "\n",
    "    model = prune_model_entropy(model_unpruned, prune_ratio=0.5)\n",
    "    nonzero_params_after = sum((p != 0).sum().item() for p in model.parameters())\n",
    "    zero_params = total_params_before - nonzero_params_after\n",
    "    pruned_ratio = 100 * zero_params / total_params_before\n",
    "    print(f\"[INFO] Non-zero parameters AFTER pruning: {nonzero_params_after:,}\")\n",
    "    print(f\"[INFO] Pruned parameters: {zero_params:,} ({pruned_ratio:.2f}%)\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    " \n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "\n",
    "    for epoch in range(35):  # You can change this to 50 or more\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7532feca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5632 | Train Acc: 0.7897 | Val Loss: 0.4684 | Val Acc: 0.8255\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4762 | Train Acc: 0.8234 | Val Loss: 0.5530 | Val Acc: 0.8014\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4532 | Train Acc: 0.8336 | Val Loss: 0.4284 | Val Acc: 0.8410\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4386 | Train Acc: 0.8345 | Val Loss: 0.4250 | Val Acc: 0.8404\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4228 | Train Acc: 0.8432 | Val Loss: 0.3942 | Val Acc: 0.8494\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4145 | Train Acc: 0.8469 | Val Loss: 0.3764 | Val Acc: 0.8580\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.4051 | Train Acc: 0.8494 | Val Loss: 0.4170 | Val Acc: 0.8388\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.4025 | Train Acc: 0.8510 | Val Loss: 0.3854 | Val Acc: 0.8582\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.3931 | Train Acc: 0.8532 | Val Loss: 0.3991 | Val Acc: 0.8493\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.3860 | Train Acc: 0.8586 | Val Loss: 0.3934 | Val Acc: 0.8503\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3791 | Train Acc: 0.8618 | Val Loss: 0.3937 | Val Acc: 0.8533\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3747 | Train Acc: 0.8625 | Val Loss: 0.3576 | Val Acc: 0.8625\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3754 | Train Acc: 0.8609 | Val Loss: 0.3986 | Val Acc: 0.8531\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3661 | Train Acc: 0.8636 | Val Loss: 0.3879 | Val Acc: 0.8540\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3570 | Train Acc: 0.8677 | Val Loss: 0.4039 | Val Acc: 0.8457\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3453 | Train Acc: 0.8696 | Val Loss: 0.3661 | Val Acc: 0.8643\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3427 | Train Acc: 0.8713 | Val Loss: 0.3917 | Val Acc: 0.8556\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3326 | Train Acc: 0.8754 | Val Loss: 0.3690 | Val Acc: 0.8626\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3226 | Train Acc: 0.8802 | Val Loss: 0.3861 | Val Acc: 0.8577\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3190 | Train Acc: 0.8813 | Val Loss: 0.4056 | Val Acc: 0.8441\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3013 | Train Acc: 0.8866 | Val Loss: 0.3960 | Val Acc: 0.8531\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.2988 | Train Acc: 0.8880 | Val Loss: 0.3937 | Val Acc: 0.8603\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.2953 | Train Acc: 0.8897 | Val Loss: 0.4322 | Val Acc: 0.8448\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.2829 | Train Acc: 0.8959 | Val Loss: 0.3640 | Val Acc: 0.8682\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.2692 | Train Acc: 0.9000 | Val Loss: 0.4733 | Val Acc: 0.8315\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.2592 | Train Acc: 0.9032 | Val Loss: 0.4259 | Val Acc: 0.8401\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.2466 | Train Acc: 0.9076 | Val Loss: 0.4099 | Val Acc: 0.8587\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.2427 | Train Acc: 0.9092 | Val Loss: 0.4399 | Val Acc: 0.8481\n",
      "[Fold 1 | Epoch 29] Train Loss: 0.2295 | Train Acc: 0.9138 | Val Loss: 0.4251 | Val Acc: 0.8597\n",
      "[Fold 1 | Epoch 30] Train Loss: 0.2161 | Train Acc: 0.9190 | Val Loss: 0.4925 | Val Acc: 0.8500\n",
      "[Fold 1 | Epoch 31] Train Loss: 0.2106 | Train Acc: 0.9211 | Val Loss: 0.4587 | Val Acc: 0.8556\n",
      "[Fold 1 | Epoch 32] Train Loss: 0.2011 | Train Acc: 0.9255 | Val Loss: 0.4319 | Val Acc: 0.8636\n",
      "[Fold 1 | Epoch 33] Train Loss: 0.1895 | Train Acc: 0.9265 | Val Loss: 0.4941 | Val Acc: 0.8440\n",
      "[Fold 1 | Epoch 34] Train Loss: 0.1877 | Train Acc: 0.9306 | Val Loss: 0.5071 | Val Acc: 0.8391\n",
      "[Fold 1 | Epoch 35] Train Loss: 0.1818 | Train Acc: 0.9297 | Val Loss: 0.4689 | Val Acc: 0.8562\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 24\n",
      "ACC: 0.8682 | MF1: 0.8252 | G-Mean: 0.8875\n",
      "[Class 0] Prec: 0.9409 | Rec: 0.8870 | F1: 0.9131 | GM: 0.9359\n",
      "[Class 1] Prec: 0.5983 | Rec: 0.5585 | F1: 0.5777 | GM: 0.7365\n",
      "[Class 2] Prec: 0.9045 | Rec: 0.9039 | F1: 0.9042 | GM: 0.9163\n",
      "[Class 3] Prec: 0.8898 | Rec: 0.9071 | F1: 0.8984 | GM: 0.9447\n",
      "[Class 4] Prec: 0.8062 | Rec: 0.8604 | F1: 0.8324 | GM: 0.9042\n",
      "\n",
      "===== Fold 2 =====\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5721 | Train Acc: 0.7855 | Val Loss: 0.4932 | Val Acc: 0.8219\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4747 | Train Acc: 0.8244 | Val Loss: 0.4355 | Val Acc: 0.8434\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4422 | Train Acc: 0.8344 | Val Loss: 0.6197 | Val Acc: 0.7954\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4346 | Train Acc: 0.8392 | Val Loss: 0.4403 | Val Acc: 0.8375\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4241 | Train Acc: 0.8417 | Val Loss: 0.6861 | Val Acc: 0.7771\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4153 | Train Acc: 0.8437 | Val Loss: 0.3985 | Val Acc: 0.8513\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4055 | Train Acc: 0.8491 | Val Loss: 0.4187 | Val Acc: 0.8506\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.4034 | Train Acc: 0.8510 | Val Loss: 0.4252 | Val Acc: 0.8407\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.3918 | Train Acc: 0.8547 | Val Loss: 0.5245 | Val Acc: 0.7989\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.3889 | Train Acc: 0.8542 | Val Loss: 0.4011 | Val Acc: 0.8587\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3856 | Train Acc: 0.8575 | Val Loss: 0.4014 | Val Acc: 0.8520\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3734 | Train Acc: 0.8601 | Val Loss: 0.4567 | Val Acc: 0.8335\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3715 | Train Acc: 0.8622 | Val Loss: 0.3867 | Val Acc: 0.8597\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3624 | Train Acc: 0.8634 | Val Loss: 0.4456 | Val Acc: 0.8311\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3582 | Train Acc: 0.8667 | Val Loss: 0.4183 | Val Acc: 0.8466\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3484 | Train Acc: 0.8716 | Val Loss: 0.4770 | Val Acc: 0.8354\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3409 | Train Acc: 0.8739 | Val Loss: 0.4243 | Val Acc: 0.8454\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3322 | Train Acc: 0.8747 | Val Loss: 0.4517 | Val Acc: 0.8348\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3245 | Train Acc: 0.8789 | Val Loss: 0.3943 | Val Acc: 0.8605\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3186 | Train Acc: 0.8812 | Val Loss: 0.3853 | Val Acc: 0.8661\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3140 | Train Acc: 0.8835 | Val Loss: 0.5002 | Val Acc: 0.8288\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.2991 | Train Acc: 0.8884 | Val Loss: 0.4927 | Val Acc: 0.8212\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.2924 | Train Acc: 0.8901 | Val Loss: 0.4468 | Val Acc: 0.8566\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.2830 | Train Acc: 0.8941 | Val Loss: 0.4115 | Val Acc: 0.8507\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.2747 | Train Acc: 0.8969 | Val Loss: 0.4140 | Val Acc: 0.8612\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.2651 | Train Acc: 0.9021 | Val Loss: 0.4506 | Val Acc: 0.8549\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.2634 | Train Acc: 0.9004 | Val Loss: 0.4038 | Val Acc: 0.8575\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.2539 | Train Acc: 0.9061 | Val Loss: 0.4053 | Val Acc: 0.8546\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.2373 | Train Acc: 0.9108 | Val Loss: 0.5656 | Val Acc: 0.8073\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.2373 | Train Acc: 0.9089 | Val Loss: 0.4359 | Val Acc: 0.8536\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.2139 | Train Acc: 0.9203 | Val Loss: 0.4488 | Val Acc: 0.8589\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.2118 | Train Acc: 0.9200 | Val Loss: 0.4280 | Val Acc: 0.8585\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.2029 | Train Acc: 0.9242 | Val Loss: 0.4159 | Val Acc: 0.8691\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.1946 | Train Acc: 0.9267 | Val Loss: 0.4962 | Val Acc: 0.8490\n",
      "[Fold 2 | Epoch 35] Train Loss: 0.1887 | Train Acc: 0.9293 | Val Loss: 0.5000 | Val Acc: 0.8610\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 33\n",
      "ACC: 0.8691 | MF1: 0.8274 | G-Mean: 0.8876\n",
      "[Class 0] Prec: 0.8941 | Rec: 0.9392 | F1: 0.9160 | GM: 0.9573\n",
      "[Class 1] Prec: 0.6175 | Rec: 0.5701 | F1: 0.5928 | GM: 0.7442\n",
      "[Class 2] Prec: 0.9074 | Rec: 0.8985 | F1: 0.9029 | GM: 0.9138\n",
      "[Class 3] Prec: 0.9426 | Rec: 0.8280 | F1: 0.8816 | GM: 0.9066\n",
      "[Class 4] Prec: 0.8101 | Rec: 0.8806 | F1: 0.8439 | GM: 0.9160\n",
      "\n",
      "===== Fold 3 =====\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5705 | Train Acc: 0.7867 | Val Loss: 0.5074 | Val Acc: 0.8067\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4745 | Train Acc: 0.8252 | Val Loss: 0.4569 | Val Acc: 0.8301\n",
      "[Fold 3 | Epoch 3] Train Loss: 0.4526 | Train Acc: 0.8321 | Val Loss: 0.4345 | Val Acc: 0.8364\n",
      "[Fold 3 | Epoch 4] Train Loss: 0.4340 | Train Acc: 0.8376 | Val Loss: 0.4247 | Val Acc: 0.8487\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4213 | Train Acc: 0.8415 | Val Loss: 0.5821 | Val Acc: 0.7860\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4139 | Train Acc: 0.8470 | Val Loss: 0.4222 | Val Acc: 0.8414\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4071 | Train Acc: 0.8482 | Val Loss: 0.4771 | Val Acc: 0.8239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3 | Epoch 8] Train Loss: 0.3977 | Train Acc: 0.8535 | Val Loss: 0.4243 | Val Acc: 0.8418\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.3896 | Train Acc: 0.8541 | Val Loss: 0.4653 | Val Acc: 0.8361\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.3863 | Train Acc: 0.8569 | Val Loss: 0.5001 | Val Acc: 0.8042\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3806 | Train Acc: 0.8592 | Val Loss: 0.3981 | Val Acc: 0.8554\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3732 | Train Acc: 0.8607 | Val Loss: 0.3963 | Val Acc: 0.8573\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3618 | Train Acc: 0.8656 | Val Loss: 0.4221 | Val Acc: 0.8533\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3555 | Train Acc: 0.8659 | Val Loss: 0.3859 | Val Acc: 0.8622\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3438 | Train Acc: 0.8695 | Val Loss: 0.3876 | Val Acc: 0.8583\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3338 | Train Acc: 0.8735 | Val Loss: 0.4559 | Val Acc: 0.8408\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3322 | Train Acc: 0.8742 | Val Loss: 0.3790 | Val Acc: 0.8663\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3180 | Train Acc: 0.8819 | Val Loss: 0.4274 | Val Acc: 0.8481\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3101 | Train Acc: 0.8831 | Val Loss: 0.4124 | Val Acc: 0.8562\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.2943 | Train Acc: 0.8884 | Val Loss: 0.3856 | Val Acc: 0.8609\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.2829 | Train Acc: 0.8953 | Val Loss: 0.4098 | Val Acc: 0.8643\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.2727 | Train Acc: 0.8962 | Val Loss: 0.3974 | Val Acc: 0.8665\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.2640 | Train Acc: 0.9005 | Val Loss: 0.4464 | Val Acc: 0.8345\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.2462 | Train Acc: 0.9070 | Val Loss: 0.4571 | Val Acc: 0.8397\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.2374 | Train Acc: 0.9111 | Val Loss: 0.4311 | Val Acc: 0.8669\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.2235 | Train Acc: 0.9150 | Val Loss: 0.4512 | Val Acc: 0.8616\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.2140 | Train Acc: 0.9194 | Val Loss: 0.4306 | Val Acc: 0.8702\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.2103 | Train Acc: 0.9204 | Val Loss: 0.4631 | Val Acc: 0.8603\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.1943 | Train Acc: 0.9270 | Val Loss: 0.4424 | Val Acc: 0.8696\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.1900 | Train Acc: 0.9278 | Val Loss: 0.4818 | Val Acc: 0.8483\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.1731 | Train Acc: 0.9341 | Val Loss: 0.4991 | Val Acc: 0.8560\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.1695 | Train Acc: 0.9365 | Val Loss: 0.5762 | Val Acc: 0.8435\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.1655 | Train Acc: 0.9365 | Val Loss: 0.5063 | Val Acc: 0.8671\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.1554 | Train Acc: 0.9415 | Val Loss: 0.5082 | Val Acc: 0.8695\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.1545 | Train Acc: 0.9436 | Val Loss: 0.5498 | Val Acc: 0.8586\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 27\n",
      "ACC: 0.8702 | MF1: 0.8278 | G-Mean: 0.8770\n",
      "[Class 0] Prec: 0.9606 | Rec: 0.9043 | F1: 0.9316 | GM: 0.9472\n",
      "[Class 1] Prec: 0.7249 | Rec: 0.4880 | F1: 0.5833 | GM: 0.6936\n",
      "[Class 2] Prec: 0.8654 | Rec: 0.9262 | F1: 0.8948 | GM: 0.9083\n",
      "[Class 3] Prec: 0.8971 | Rec: 0.8950 | F1: 0.8960 | GM: 0.9390\n",
      "[Class 4] Prec: 0.8254 | Rec: 0.8411 | F1: 0.8332 | GM: 0.8970\n",
      "\n",
      "===== Fold 4 =====\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5527 | Train Acc: 0.7907 | Val Loss: 0.4933 | Val Acc: 0.8186\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4733 | Train Acc: 0.8222 | Val Loss: 0.4555 | Val Acc: 0.8365\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4434 | Train Acc: 0.8329 | Val Loss: 0.4365 | Val Acc: 0.8420\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4298 | Train Acc: 0.8402 | Val Loss: 0.5446 | Val Acc: 0.8151\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4168 | Train Acc: 0.8436 | Val Loss: 0.4163 | Val Acc: 0.8507\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4047 | Train Acc: 0.8493 | Val Loss: 0.4356 | Val Acc: 0.8301\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.4006 | Train Acc: 0.8502 | Val Loss: 0.5096 | Val Acc: 0.8249\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.3968 | Train Acc: 0.8513 | Val Loss: 0.3838 | Val Acc: 0.8563\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.3910 | Train Acc: 0.8551 | Val Loss: 0.4619 | Val Acc: 0.8229\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.3823 | Train Acc: 0.8564 | Val Loss: 0.3870 | Val Acc: 0.8580\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.3801 | Train Acc: 0.8576 | Val Loss: 0.3713 | Val Acc: 0.8676\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3711 | Train Acc: 0.8631 | Val Loss: 0.3952 | Val Acc: 0.8552\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3634 | Train Acc: 0.8648 | Val Loss: 0.3906 | Val Acc: 0.8606\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3605 | Train Acc: 0.8657 | Val Loss: 0.4233 | Val Acc: 0.8398\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3570 | Train Acc: 0.8655 | Val Loss: 0.4060 | Val Acc: 0.8531\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3448 | Train Acc: 0.8714 | Val Loss: 0.3988 | Val Acc: 0.8540\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3371 | Train Acc: 0.8747 | Val Loss: 0.4030 | Val Acc: 0.8500\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3273 | Train Acc: 0.8767 | Val Loss: 0.3842 | Val Acc: 0.8606\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3293 | Train Acc: 0.8781 | Val Loss: 0.4398 | Val Acc: 0.8362\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3179 | Train Acc: 0.8830 | Val Loss: 0.3986 | Val Acc: 0.8570\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3051 | Train Acc: 0.8872 | Val Loss: 0.4107 | Val Acc: 0.8534\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.2995 | Train Acc: 0.8878 | Val Loss: 0.4149 | Val Acc: 0.8460\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.2826 | Train Acc: 0.8958 | Val Loss: 0.4141 | Val Acc: 0.8587\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.2752 | Train Acc: 0.8967 | Val Loss: 0.4065 | Val Acc: 0.8585\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.2701 | Train Acc: 0.9008 | Val Loss: 0.4851 | Val Acc: 0.8334\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.2540 | Train Acc: 0.9057 | Val Loss: 0.4394 | Val Acc: 0.8491\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.2426 | Train Acc: 0.9101 | Val Loss: 0.4824 | Val Acc: 0.8427\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.2372 | Train Acc: 0.9105 | Val Loss: 0.4125 | Val Acc: 0.8575\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.2286 | Train Acc: 0.9151 | Val Loss: 0.4687 | Val Acc: 0.8302\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.2188 | Train Acc: 0.9198 | Val Loss: 0.5561 | Val Acc: 0.8424\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.2062 | Train Acc: 0.9217 | Val Loss: 0.4263 | Val Acc: 0.8629\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.2035 | Train Acc: 0.9226 | Val Loss: 0.4852 | Val Acc: 0.8587\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.1884 | Train Acc: 0.9293 | Val Loss: 0.5101 | Val Acc: 0.8375\n",
      "[Fold 4 | Epoch 34] Train Loss: 0.1784 | Train Acc: 0.9336 | Val Loss: 0.4778 | Val Acc: 0.8520\n",
      "[Fold 4 | Epoch 35] Train Loss: 0.1743 | Train Acc: 0.9349 | Val Loss: 0.5064 | Val Acc: 0.8537\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 11\n",
      "ACC: 0.8676 | MF1: 0.8119 | G-Mean: 0.8737\n",
      "[Class 0] Prec: 0.9108 | Rec: 0.9282 | F1: 0.9194 | GM: 0.9533\n",
      "[Class 1] Prec: 0.5861 | Rec: 0.4451 | F1: 0.5060 | GM: 0.6595\n",
      "[Class 2] Prec: 0.8900 | Rec: 0.9104 | F1: 0.9001 | GM: 0.9135\n",
      "[Class 3] Prec: 0.8896 | Rec: 0.9161 | F1: 0.9027 | GM: 0.9490\n",
      "[Class 4] Prec: 0.8335 | Rec: 0.8297 | F1: 0.8316 | GM: 0.8931\n",
      "\n",
      "===== Fold 5 =====\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.5545 | Train Acc: 0.7889 | Val Loss: 0.4974 | Val Acc: 0.8194\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4729 | Train Acc: 0.8237 | Val Loss: 0.4546 | Val Acc: 0.8427\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4464 | Train Acc: 0.8351 | Val Loss: 0.4387 | Val Acc: 0.8400\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4302 | Train Acc: 0.8365 | Val Loss: 0.4376 | Val Acc: 0.8392\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4188 | Train Acc: 0.8447 | Val Loss: 0.4535 | Val Acc: 0.8334\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4090 | Train Acc: 0.8461 | Val Loss: 0.3876 | Val Acc: 0.8618\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.4035 | Train Acc: 0.8501 | Val Loss: 0.3974 | Val Acc: 0.8549\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.3946 | Train Acc: 0.8525 | Val Loss: 0.4919 | Val Acc: 0.8331\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.3911 | Train Acc: 0.8550 | Val Loss: 0.4461 | Val Acc: 0.8424\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.3814 | Train Acc: 0.8578 | Val Loss: 0.4401 | Val Acc: 0.8374\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.3788 | Train Acc: 0.8588 | Val Loss: 0.4457 | Val Acc: 0.8334\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3705 | Train Acc: 0.8624 | Val Loss: 0.3979 | Val Acc: 0.8494\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3669 | Train Acc: 0.8637 | Val Loss: 0.3856 | Val Acc: 0.8642\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3554 | Train Acc: 0.8682 | Val Loss: 0.4194 | Val Acc: 0.8493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 15] Train Loss: 0.3535 | Train Acc: 0.8671 | Val Loss: 0.3960 | Val Acc: 0.8567\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3487 | Train Acc: 0.8705 | Val Loss: 0.4104 | Val Acc: 0.8586\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3315 | Train Acc: 0.8762 | Val Loss: 0.4560 | Val Acc: 0.8321\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3284 | Train Acc: 0.8775 | Val Loss: 0.4187 | Val Acc: 0.8460\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3175 | Train Acc: 0.8793 | Val Loss: 0.4289 | Val Acc: 0.8529\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3100 | Train Acc: 0.8838 | Val Loss: 0.4684 | Val Acc: 0.8281\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.2977 | Train Acc: 0.8877 | Val Loss: 0.4721 | Val Acc: 0.8425\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.2950 | Train Acc: 0.8891 | Val Loss: 0.4522 | Val Acc: 0.8468\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.2831 | Train Acc: 0.8927 | Val Loss: 0.4131 | Val Acc: 0.8556\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.2805 | Train Acc: 0.8938 | Val Loss: 0.4277 | Val Acc: 0.8562\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.2634 | Train Acc: 0.9029 | Val Loss: 0.5906 | Val Acc: 0.8172\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.2529 | Train Acc: 0.9059 | Val Loss: 0.4220 | Val Acc: 0.8606\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.2466 | Train Acc: 0.9067 | Val Loss: 0.4443 | Val Acc: 0.8600\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.2390 | Train Acc: 0.9101 | Val Loss: 0.4954 | Val Acc: 0.8371\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.2194 | Train Acc: 0.9163 | Val Loss: 0.4963 | Val Acc: 0.8496\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.2152 | Train Acc: 0.9180 | Val Loss: 0.5145 | Val Acc: 0.8496\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.2063 | Train Acc: 0.9210 | Val Loss: 0.5295 | Val Acc: 0.8424\n",
      "[Fold 5 | Epoch 32] Train Loss: 0.1991 | Train Acc: 0.9243 | Val Loss: 0.5100 | Val Acc: 0.8511\n",
      "[Fold 5 | Epoch 33] Train Loss: 0.1861 | Train Acc: 0.9307 | Val Loss: 0.5812 | Val Acc: 0.8361\n",
      "[Fold 5 | Epoch 34] Train Loss: 0.1827 | Train Acc: 0.9311 | Val Loss: 0.4829 | Val Acc: 0.8544\n",
      "[Fold 5 | Epoch 35] Train Loss: 0.1731 | Train Acc: 0.9336 | Val Loss: 0.4978 | Val Acc: 0.8632\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 13\n",
      "ACC: 0.8642 | MF1: 0.8163 | G-Mean: 0.8840\n",
      "[Class 0] Prec: 0.8994 | Rec: 0.9189 | F1: 0.9090 | GM: 0.9473\n",
      "[Class 1] Prec: 0.6029 | Rec: 0.4882 | F1: 0.5395 | GM: 0.6898\n",
      "[Class 2] Prec: 0.9332 | Rec: 0.8741 | F1: 0.9027 | GM: 0.9132\n",
      "[Class 3] Prec: 0.8824 | Rec: 0.9381 | F1: 0.9094 | GM: 0.9595\n",
      "[Class 4] Prec: 0.7667 | Rec: 0.8832 | F1: 0.8209 | GM: 0.9101\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8679 | MF1: 0.8220 | G-Mean: 0.8824\n",
      "[Class 0] Prec: 0.9197 | Rec: 0.9156 | F1: 0.9176 | GM: 0.9483\n",
      "[Class 1] Prec: 0.6224 | Rec: 0.5110 | F1: 0.5612 | GM: 0.7062\n",
      "[Class 2] Prec: 0.8991 | Rec: 0.9027 | F1: 0.9009 | GM: 0.9133\n",
      "[Class 3] Prec: 0.8987 | Rec: 0.8973 | F1: 0.8980 | GM: 0.9402\n",
      "[Class 4] Prec: 0.8074 | Rec: 0.8588 | F1: 0.8323 | GM: 0.9041\n",
      "Confusion Matrix:\n",
      "[[ 5803   267    98    11   159]\n",
      " [  312  1279   410     4   498]\n",
      " [   86   232 13487   432   704]\n",
      " [   12     1   443  3984     0]\n",
      " [   97   276   563     2  5705]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# ==== Load and Normalize Data ====\n",
    "\n",
    "df = pd.read_csv(\"pruned_dataset3.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "# Z-score normalization\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== Evaluation Metric Function ====\n",
    "def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    gmeans = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        tn = np.sum((y_pred != c) & (y_true != c))\n",
    "        fp = np.sum((y_pred == c) & (y_true != c))\n",
    "        gm = np.sqrt((tp / (tp + fn + 1e-6)) * (tn / (tn + fp + 1e-6)))\n",
    "        gmeans.append(gm)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, mf1, np.mean(gmeans), prec, rec, f1s, gmeans, cm\n",
    "\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "    X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "    X_val, y_val = X_all[val_idx], y_all[val_idx]\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "\n",
    "    model = FinalNetwork(C=12, num_classes=num_classes, layers=9, genotype=searched_genotype).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "\n",
    "    for epoch in range(35):  # You can change this to 50 or more\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21bce93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[INFO] Total parameters BEFORE pruning: 201,881\n",
      "[INFO] Non-zero parameters AFTER pruning: 101,663\n",
      "[INFO] Pruned parameters: 100,218 (49.64%)\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5900 | Train Acc: 0.7783 | Val Loss: 0.4640 | Val Acc: 0.8275\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4790 | Train Acc: 0.8228 | Val Loss: 0.6538 | Val Acc: 0.7456\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4566 | Train Acc: 0.8305 | Val Loss: 0.4473 | Val Acc: 0.8342\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4381 | Train Acc: 0.8372 | Val Loss: 0.4053 | Val Acc: 0.8500\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4269 | Train Acc: 0.8413 | Val Loss: 0.4498 | Val Acc: 0.8325\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4132 | Train Acc: 0.8481 | Val Loss: 0.4627 | Val Acc: 0.8306\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.4095 | Train Acc: 0.8466 | Val Loss: 0.4898 | Val Acc: 0.8197\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.4021 | Train Acc: 0.8492 | Val Loss: 0.4150 | Val Acc: 0.8458\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.4008 | Train Acc: 0.8519 | Val Loss: 0.4204 | Val Acc: 0.8441\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.3953 | Train Acc: 0.8511 | Val Loss: 0.4218 | Val Acc: 0.8443\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3838 | Train Acc: 0.8572 | Val Loss: 0.3944 | Val Acc: 0.8526\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3803 | Train Acc: 0.8590 | Val Loss: 0.3703 | Val Acc: 0.8671\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3778 | Train Acc: 0.8593 | Val Loss: 0.3983 | Val Acc: 0.8503\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3733 | Train Acc: 0.8616 | Val Loss: 0.4159 | Val Acc: 0.8519\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3660 | Train Acc: 0.8649 | Val Loss: 0.4112 | Val Acc: 0.8550\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3613 | Train Acc: 0.8631 | Val Loss: 0.4598 | Val Acc: 0.8249\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3557 | Train Acc: 0.8700 | Val Loss: 0.4153 | Val Acc: 0.8488\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3541 | Train Acc: 0.8668 | Val Loss: 0.4425 | Val Acc: 0.8470\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3413 | Train Acc: 0.8728 | Val Loss: 0.3827 | Val Acc: 0.8580\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3429 | Train Acc: 0.8711 | Val Loss: 0.4681 | Val Acc: 0.8345\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3352 | Train Acc: 0.8734 | Val Loss: 0.3747 | Val Acc: 0.8672\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.3303 | Train Acc: 0.8751 | Val Loss: 0.4183 | Val Acc: 0.8554\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.3193 | Train Acc: 0.8800 | Val Loss: 0.3856 | Val Acc: 0.8632\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.3122 | Train Acc: 0.8827 | Val Loss: 0.3942 | Val Acc: 0.8576\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.3072 | Train Acc: 0.8840 | Val Loss: 0.4202 | Val Acc: 0.8483\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.2984 | Train Acc: 0.8889 | Val Loss: 0.4419 | Val Acc: 0.8467\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.2894 | Train Acc: 0.8927 | Val Loss: 0.3896 | Val Acc: 0.8610\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.2884 | Train Acc: 0.8916 | Val Loss: 0.4166 | Val Acc: 0.8642\n",
      "[Fold 1 | Epoch 29] Train Loss: 0.2824 | Train Acc: 0.8963 | Val Loss: 0.4533 | Val Acc: 0.8371\n",
      "[Fold 1 | Epoch 30] Train Loss: 0.2713 | Train Acc: 0.8986 | Val Loss: 0.4181 | Val Acc: 0.8494\n",
      "[Fold 1 | Epoch 31] Train Loss: 0.2611 | Train Acc: 0.9021 | Val Loss: 0.4266 | Val Acc: 0.8458\n",
      "[Fold 1 | Epoch 32] Train Loss: 0.2547 | Train Acc: 0.9043 | Val Loss: 0.4433 | Val Acc: 0.8531\n",
      "[Fold 1 | Epoch 33] Train Loss: 0.2415 | Train Acc: 0.9092 | Val Loss: 0.5155 | Val Acc: 0.8443\n",
      "[Fold 1 | Epoch 34] Train Loss: 0.2432 | Train Acc: 0.9091 | Val Loss: 0.4375 | Val Acc: 0.8577\n",
      "[Fold 1 | Epoch 35] Train Loss: 0.2299 | Train Acc: 0.9131 | Val Loss: 0.5288 | Val Acc: 0.8388\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 21\n",
      "ACC: 0.8672 | MF1: 0.8218 | G-Mean: 0.8857\n",
      "[Class 0] Prec: 0.9232 | Rec: 0.9011 | F1: 0.9120 | GM: 0.9411\n",
      "[Class 1] Prec: 0.6268 | Rec: 0.5039 | F1: 0.5587 | GM: 0.7014\n",
      "[Class 2] Prec: 0.9236 | Rec: 0.8839 | F1: 0.9033 | GM: 0.9146\n",
      "[Class 3] Prec: 0.8889 | Rec: 0.9292 | F1: 0.9086 | GM: 0.9556\n",
      "[Class 4] Prec: 0.7675 | Rec: 0.8947 | F1: 0.8262 | GM: 0.9157\n",
      "\n",
      "===== Fold 2 =====\n",
      "[INFO] Total parameters BEFORE pruning: 201,881\n",
      "[INFO] Non-zero parameters AFTER pruning: 101,663\n",
      "[INFO] Pruned parameters: 100,218 (49.64%)\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5798 | Train Acc: 0.7865 | Val Loss: 1.0982 | Val Acc: 0.6829\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4799 | Train Acc: 0.8209 | Val Loss: 0.5932 | Val Acc: 0.7809\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4588 | Train Acc: 0.8299 | Val Loss: 0.4461 | Val Acc: 0.8385\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4438 | Train Acc: 0.8354 | Val Loss: 0.4347 | Val Acc: 0.8411\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4356 | Train Acc: 0.8393 | Val Loss: 0.4166 | Val Acc: 0.8523\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4276 | Train Acc: 0.8409 | Val Loss: 0.4104 | Val Acc: 0.8529\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4178 | Train Acc: 0.8458 | Val Loss: 0.4059 | Val Acc: 0.8519\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.4112 | Train Acc: 0.8474 | Val Loss: 0.4367 | Val Acc: 0.8445\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.4053 | Train Acc: 0.8520 | Val Loss: 0.3914 | Val Acc: 0.8569\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.3998 | Train Acc: 0.8525 | Val Loss: 0.4234 | Val Acc: 0.8460\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3932 | Train Acc: 0.8536 | Val Loss: 0.3885 | Val Acc: 0.8586\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3900 | Train Acc: 0.8549 | Val Loss: 0.3933 | Val Acc: 0.8596\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3860 | Train Acc: 0.8573 | Val Loss: 0.4070 | Val Acc: 0.8507\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3772 | Train Acc: 0.8614 | Val Loss: 0.3983 | Val Acc: 0.8575\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3739 | Train Acc: 0.8621 | Val Loss: 0.3923 | Val Acc: 0.8612\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3761 | Train Acc: 0.8601 | Val Loss: 0.4253 | Val Acc: 0.8438\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3638 | Train Acc: 0.8660 | Val Loss: 0.4131 | Val Acc: 0.8503\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3595 | Train Acc: 0.8657 | Val Loss: 0.4695 | Val Acc: 0.8357\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3590 | Train Acc: 0.8657 | Val Loss: 0.4917 | Val Acc: 0.8275\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3452 | Train Acc: 0.8702 | Val Loss: 0.3981 | Val Acc: 0.8536\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3455 | Train Acc: 0.8702 | Val Loss: 0.4063 | Val Acc: 0.8519\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.3383 | Train Acc: 0.8725 | Val Loss: 0.4575 | Val Acc: 0.8369\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.3294 | Train Acc: 0.8762 | Val Loss: 0.4451 | Val Acc: 0.8395\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.3243 | Train Acc: 0.8791 | Val Loss: 0.4071 | Val Acc: 0.8595\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.3162 | Train Acc: 0.8821 | Val Loss: 0.4493 | Val Acc: 0.8407\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.3078 | Train Acc: 0.8830 | Val Loss: 0.4299 | Val Acc: 0.8477\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.3012 | Train Acc: 0.8867 | Val Loss: 0.4926 | Val Acc: 0.8260\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.2958 | Train Acc: 0.8880 | Val Loss: 0.4272 | Val Acc: 0.8509\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.2918 | Train Acc: 0.8913 | Val Loss: 0.4346 | Val Acc: 0.8431\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.2812 | Train Acc: 0.8947 | Val Loss: 0.4716 | Val Acc: 0.8466\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.2701 | Train Acc: 0.8990 | Val Loss: 0.5858 | Val Acc: 0.8248\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.2705 | Train Acc: 0.8970 | Val Loss: 0.4224 | Val Acc: 0.8553\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.2654 | Train Acc: 0.8983 | Val Loss: 0.4946 | Val Acc: 0.8587\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.2583 | Train Acc: 0.9029 | Val Loss: 0.4920 | Val Acc: 0.8362\n",
      "[Fold 2 | Epoch 35] Train Loss: 0.2489 | Train Acc: 0.9057 | Val Loss: 0.4219 | Val Acc: 0.8636\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 35\n",
      "ACC: 0.8636 | MF1: 0.8255 | G-Mean: 0.8882\n",
      "[Class 0] Prec: 0.9256 | Rec: 0.9042 | F1: 0.9148 | GM: 0.9430\n",
      "[Class 1] Prec: 0.5912 | Rec: 0.6039 | F1: 0.5975 | GM: 0.7642\n",
      "[Class 2] Prec: 0.8859 | Rec: 0.9042 | F1: 0.8950 | GM: 0.9093\n",
      "[Class 3] Prec: 0.8894 | Rec: 0.9071 | F1: 0.8981 | GM: 0.9444\n",
      "[Class 4] Prec: 0.8416 | Rec: 0.8031 | F1: 0.8219 | GM: 0.8803\n",
      "\n",
      "===== Fold 3 =====\n",
      "[INFO] Total parameters BEFORE pruning: 201,881\n",
      "[INFO] Non-zero parameters AFTER pruning: 101,663\n",
      "[INFO] Pruned parameters: 100,218 (49.64%)\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5975 | Train Acc: 0.7762 | Val Loss: 0.5583 | Val Acc: 0.7919\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4925 | Train Acc: 0.8191 | Val Loss: 0.5797 | Val Acc: 0.7883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3 | Epoch 3] Train Loss: 0.4686 | Train Acc: 0.8275 | Val Loss: 0.4423 | Val Acc: 0.8382\n",
      "[Fold 3 | Epoch 4] Train Loss: 0.4491 | Train Acc: 0.8332 | Val Loss: 0.4772 | Val Acc: 0.8210\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4412 | Train Acc: 0.8363 | Val Loss: 0.4587 | Val Acc: 0.8269\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4275 | Train Acc: 0.8432 | Val Loss: 0.4508 | Val Acc: 0.8418\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4222 | Train Acc: 0.8436 | Val Loss: 0.4659 | Val Acc: 0.8394\n",
      "[Fold 3 | Epoch 8] Train Loss: 0.4132 | Train Acc: 0.8454 | Val Loss: 0.4236 | Val Acc: 0.8466\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.4049 | Train Acc: 0.8473 | Val Loss: 0.4098 | Val Acc: 0.8490\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.4024 | Train Acc: 0.8494 | Val Loss: 0.4695 | Val Acc: 0.8262\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3983 | Train Acc: 0.8524 | Val Loss: 0.4210 | Val Acc: 0.8494\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3902 | Train Acc: 0.8539 | Val Loss: 0.4040 | Val Acc: 0.8506\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3844 | Train Acc: 0.8571 | Val Loss: 0.4145 | Val Acc: 0.8497\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3802 | Train Acc: 0.8592 | Val Loss: 0.4011 | Val Acc: 0.8530\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3794 | Train Acc: 0.8595 | Val Loss: 0.4182 | Val Acc: 0.8539\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3731 | Train Acc: 0.8615 | Val Loss: 0.4272 | Val Acc: 0.8438\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3623 | Train Acc: 0.8664 | Val Loss: 0.6363 | Val Acc: 0.8106\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3596 | Train Acc: 0.8654 | Val Loss: 0.5742 | Val Acc: 0.7943\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3559 | Train Acc: 0.8662 | Val Loss: 0.4805 | Val Acc: 0.8233\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.3504 | Train Acc: 0.8708 | Val Loss: 0.4178 | Val Acc: 0.8572\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.3424 | Train Acc: 0.8713 | Val Loss: 0.5315 | Val Acc: 0.8282\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.3379 | Train Acc: 0.8742 | Val Loss: 0.4920 | Val Acc: 0.8283\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.3339 | Train Acc: 0.8729 | Val Loss: 0.4106 | Val Acc: 0.8526\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.3291 | Train Acc: 0.8765 | Val Loss: 0.4713 | Val Acc: 0.8206\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.3225 | Train Acc: 0.8790 | Val Loss: 0.4028 | Val Acc: 0.8585\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.3161 | Train Acc: 0.8828 | Val Loss: 0.4552 | Val Acc: 0.8364\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.3101 | Train Acc: 0.8857 | Val Loss: 0.4883 | Val Acc: 0.8170\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.2981 | Train Acc: 0.8878 | Val Loss: 0.4435 | Val Acc: 0.8431\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.2956 | Train Acc: 0.8887 | Val Loss: 0.4976 | Val Acc: 0.8430\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.2853 | Train Acc: 0.8929 | Val Loss: 0.4130 | Val Acc: 0.8564\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.2847 | Train Acc: 0.8934 | Val Loss: 0.5944 | Val Acc: 0.8209\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.2754 | Train Acc: 0.8980 | Val Loss: 0.4580 | Val Acc: 0.8447\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.2666 | Train Acc: 0.8996 | Val Loss: 0.4766 | Val Acc: 0.8355\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.2602 | Train Acc: 0.9027 | Val Loss: 0.4252 | Val Acc: 0.8534\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.2508 | Train Acc: 0.9054 | Val Loss: 0.4490 | Val Acc: 0.8646\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 35\n",
      "ACC: 0.8646 | MF1: 0.8239 | G-Mean: 0.8851\n",
      "[Class 0] Prec: 0.9550 | Rec: 0.8686 | F1: 0.9098 | GM: 0.9276\n",
      "[Class 1] Prec: 0.6364 | Rec: 0.5490 | F1: 0.5895 | GM: 0.7317\n",
      "[Class 2] Prec: 0.8955 | Rec: 0.9015 | F1: 0.8985 | GM: 0.9120\n",
      "[Class 3] Prec: 0.8754 | Rec: 0.9248 | F1: 0.8994 | GM: 0.9522\n",
      "[Class 4] Prec: 0.7889 | Rec: 0.8588 | F1: 0.8224 | GM: 0.9017\n",
      "\n",
      "===== Fold 4 =====\n",
      "[INFO] Total parameters BEFORE pruning: 201,881\n",
      "[INFO] Non-zero parameters AFTER pruning: 101,663\n",
      "[INFO] Pruned parameters: 100,218 (49.64%)\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5948 | Train Acc: 0.7764 | Val Loss: 1.0789 | Val Acc: 0.6253\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4715 | Train Acc: 0.8249 | Val Loss: 0.5515 | Val Acc: 0.7921\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4555 | Train Acc: 0.8316 | Val Loss: 0.4438 | Val Acc: 0.8338\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4317 | Train Acc: 0.8393 | Val Loss: 0.7072 | Val Acc: 0.7555\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4334 | Train Acc: 0.8381 | Val Loss: 0.4255 | Val Acc: 0.8362\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4172 | Train Acc: 0.8471 | Val Loss: 0.4283 | Val Acc: 0.8428\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.4146 | Train Acc: 0.8475 | Val Loss: 0.4055 | Val Acc: 0.8517\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.4042 | Train Acc: 0.8523 | Val Loss: 0.4185 | Val Acc: 0.8476\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.4018 | Train Acc: 0.8526 | Val Loss: 0.4174 | Val Acc: 0.8480\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.3986 | Train Acc: 0.8544 | Val Loss: 0.4253 | Val Acc: 0.8415\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.3916 | Train Acc: 0.8552 | Val Loss: 0.5178 | Val Acc: 0.8018\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3914 | Train Acc: 0.8529 | Val Loss: 0.3816 | Val Acc: 0.8628\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3798 | Train Acc: 0.8587 | Val Loss: 0.4228 | Val Acc: 0.8467\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3756 | Train Acc: 0.8596 | Val Loss: 0.4239 | Val Acc: 0.8359\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3744 | Train Acc: 0.8627 | Val Loss: 0.4349 | Val Acc: 0.8458\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3650 | Train Acc: 0.8659 | Val Loss: 0.4379 | Val Acc: 0.8392\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3625 | Train Acc: 0.8653 | Val Loss: 0.3897 | Val Acc: 0.8554\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3570 | Train Acc: 0.8670 | Val Loss: 0.4057 | Val Acc: 0.8477\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3480 | Train Acc: 0.8686 | Val Loss: 0.4134 | Val Acc: 0.8564\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3435 | Train Acc: 0.8700 | Val Loss: 0.3760 | Val Acc: 0.8628\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3346 | Train Acc: 0.8762 | Val Loss: 0.4037 | Val Acc: 0.8542\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.3327 | Train Acc: 0.8777 | Val Loss: 0.4161 | Val Acc: 0.8572\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.3318 | Train Acc: 0.8773 | Val Loss: 0.4918 | Val Acc: 0.8378\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.3153 | Train Acc: 0.8827 | Val Loss: 0.5685 | Val Acc: 0.8080\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.3140 | Train Acc: 0.8842 | Val Loss: 0.5402 | Val Acc: 0.8147\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.3071 | Train Acc: 0.8860 | Val Loss: 0.4117 | Val Acc: 0.8607\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.2942 | Train Acc: 0.8906 | Val Loss: 0.4440 | Val Acc: 0.8483\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.2905 | Train Acc: 0.8896 | Val Loss: 0.4563 | Val Acc: 0.8564\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.2911 | Train Acc: 0.8915 | Val Loss: 0.4050 | Val Acc: 0.8582\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.2740 | Train Acc: 0.8980 | Val Loss: 0.3814 | Val Acc: 0.8651\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.2706 | Train Acc: 0.8998 | Val Loss: 0.4377 | Val Acc: 0.8590\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.2642 | Train Acc: 0.9021 | Val Loss: 0.5856 | Val Acc: 0.8292\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.2619 | Train Acc: 0.9028 | Val Loss: 0.4169 | Val Acc: 0.8557\n",
      "[Fold 4 | Epoch 34] Train Loss: 0.2475 | Train Acc: 0.9074 | Val Loss: 0.5195 | Val Acc: 0.8299\n",
      "[Fold 4 | Epoch 35] Train Loss: 0.2421 | Train Acc: 0.9088 | Val Loss: 0.4550 | Val Acc: 0.8549\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 30\n",
      "ACC: 0.8651 | MF1: 0.8219 | G-Mean: 0.8847\n",
      "[Class 0] Prec: 0.9085 | Rec: 0.9057 | F1: 0.9071 | GM: 0.9418\n",
      "[Class 1] Prec: 0.6096 | Rec: 0.5451 | F1: 0.5756 | GM: 0.7281\n",
      "[Class 2] Prec: 0.9035 | Rec: 0.8968 | F1: 0.9001 | GM: 0.9130\n",
      "[Class 3] Prec: 0.9019 | Rec: 0.8850 | F1: 0.8934 | GM: 0.9340\n",
      "[Class 4] Prec: 0.8045 | Rec: 0.8641 | F1: 0.8333 | GM: 0.9067\n",
      "\n",
      "===== Fold 5 =====\n",
      "[INFO] Total parameters BEFORE pruning: 201,881\n",
      "[INFO] Non-zero parameters AFTER pruning: 101,663\n",
      "[INFO] Pruned parameters: 100,218 (49.64%)\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.5801 | Train Acc: 0.7826 | Val Loss: 0.4927 | Val Acc: 0.8200\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4840 | Train Acc: 0.8211 | Val Loss: 0.4952 | Val Acc: 0.8146\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4584 | Train Acc: 0.8303 | Val Loss: 0.4826 | Val Acc: 0.8216\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4432 | Train Acc: 0.8339 | Val Loss: 0.4349 | Val Acc: 0.8431\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4320 | Train Acc: 0.8386 | Val Loss: 0.4809 | Val Acc: 0.8199\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4246 | Train Acc: 0.8422 | Val Loss: 0.4331 | Val Acc: 0.8405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 7] Train Loss: 0.4208 | Train Acc: 0.8436 | Val Loss: 0.4047 | Val Acc: 0.8474\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.4116 | Train Acc: 0.8474 | Val Loss: 0.4191 | Val Acc: 0.8490\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.4031 | Train Acc: 0.8515 | Val Loss: 0.4414 | Val Acc: 0.8441\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.3946 | Train Acc: 0.8526 | Val Loss: 0.4013 | Val Acc: 0.8506\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.3939 | Train Acc: 0.8536 | Val Loss: 0.4140 | Val Acc: 0.8488\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3865 | Train Acc: 0.8574 | Val Loss: 0.4361 | Val Acc: 0.8375\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3793 | Train Acc: 0.8598 | Val Loss: 0.3745 | Val Acc: 0.8645\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3769 | Train Acc: 0.8592 | Val Loss: 0.4037 | Val Acc: 0.8523\n",
      "[Fold 5 | Epoch 15] Train Loss: 0.3715 | Train Acc: 0.8619 | Val Loss: 0.3816 | Val Acc: 0.8613\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3691 | Train Acc: 0.8609 | Val Loss: 0.4294 | Val Acc: 0.8447\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3662 | Train Acc: 0.8640 | Val Loss: 0.4071 | Val Acc: 0.8553\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3579 | Train Acc: 0.8664 | Val Loss: 0.4054 | Val Acc: 0.8517\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3504 | Train Acc: 0.8691 | Val Loss: 0.3844 | Val Acc: 0.8619\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3476 | Train Acc: 0.8702 | Val Loss: 0.4001 | Val Acc: 0.8557\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.3413 | Train Acc: 0.8702 | Val Loss: 0.4182 | Val Acc: 0.8481\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.3279 | Train Acc: 0.8762 | Val Loss: 0.4171 | Val Acc: 0.8550\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.3253 | Train Acc: 0.8767 | Val Loss: 0.3966 | Val Acc: 0.8527\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.3196 | Train Acc: 0.8824 | Val Loss: 0.4274 | Val Acc: 0.8529\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.3115 | Train Acc: 0.8831 | Val Loss: 0.4102 | Val Acc: 0.8547\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.3067 | Train Acc: 0.8853 | Val Loss: 0.4311 | Val Acc: 0.8540\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.2997 | Train Acc: 0.8890 | Val Loss: 0.4263 | Val Acc: 0.8556\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.2869 | Train Acc: 0.8941 | Val Loss: 0.4408 | Val Acc: 0.8437\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.2854 | Train Acc: 0.8917 | Val Loss: 0.4477 | Val Acc: 0.8524\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.2780 | Train Acc: 0.8955 | Val Loss: 0.5634 | Val Acc: 0.8265\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.2674 | Train Acc: 0.8985 | Val Loss: 0.4123 | Val Acc: 0.8651\n",
      "[Fold 5 | Epoch 32] Train Loss: 0.2612 | Train Acc: 0.9017 | Val Loss: 0.4620 | Val Acc: 0.8387\n",
      "[Fold 5 | Epoch 33] Train Loss: 0.2623 | Train Acc: 0.9007 | Val Loss: 0.4612 | Val Acc: 0.8625\n",
      "[Fold 5 | Epoch 34] Train Loss: 0.2483 | Train Acc: 0.9053 | Val Loss: 0.4593 | Val Acc: 0.8530\n",
      "[Fold 5 | Epoch 35] Train Loss: 0.2419 | Train Acc: 0.9094 | Val Loss: 0.5096 | Val Acc: 0.8394\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 31\n",
      "ACC: 0.8651 | MF1: 0.8263 | G-Mean: 0.8865\n",
      "[Class 0] Prec: 0.9034 | Rec: 0.9181 | F1: 0.9107 | GM: 0.9474\n",
      "[Class 1] Prec: 0.5988 | Rec: 0.6059 | F1: 0.6023 | GM: 0.7658\n",
      "[Class 2] Prec: 0.8862 | Rec: 0.9117 | F1: 0.8987 | GM: 0.9128\n",
      "[Class 3] Prec: 0.9402 | Rec: 0.8518 | F1: 0.8938 | GM: 0.9192\n",
      "[Class 4] Prec: 0.8348 | Rec: 0.8176 | F1: 0.8261 | GM: 0.8871\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8651 | MF1: 0.8240 | G-Mean: 0.8862\n",
      "[Class 0] Prec: 0.9225 | Rec: 0.8995 | F1: 0.9109 | GM: 0.9402\n",
      "[Class 1] Prec: 0.6112 | Rec: 0.5616 | F1: 0.5853 | GM: 0.7387\n",
      "[Class 2] Prec: 0.8986 | Rec: 0.8996 | F1: 0.8991 | GM: 0.9124\n",
      "[Class 3] Prec: 0.8980 | Rec: 0.8996 | F1: 0.8988 | GM: 0.9412\n",
      "[Class 4] Prec: 0.8055 | Rec: 0.8476 | F1: 0.8260 | GM: 0.8986\n",
      "Confusion Matrix:\n",
      "[[ 5820   297   164    18   171]\n",
      " [  283  1432   335     3   497]\n",
      " [  110   263 13292   441   669]\n",
      " [    7     0   443  4066     4]\n",
      " [   89   351   558     0  5552]]\n"
     ]
    }
   ],
   "source": [
    "#p9\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ==== Load and Normalize Data ====\n",
    "\n",
    "df = pd.read_csv(\"pruned_dataset3.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "     # === Build and Prune Model ===\n",
    "    model_unpruned = FinalNetwork(C=12, num_classes=num_classes, layers=9, genotype=searched_genotype).to(device)\n",
    "    total_params_before = sum(p.numel() for p in model_unpruned.parameters())\n",
    "    print(f\"[INFO] Total parameters BEFORE pruning: {total_params_before:,}\")\n",
    "\n",
    "    model = prune_model_entropy(model_unpruned, prune_ratio=0.5)\n",
    "    nonzero_params_after = sum((p != 0).sum().item() for p in model.parameters())\n",
    "    zero_params = total_params_before - nonzero_params_after\n",
    "    pruned_ratio = 100 * zero_params / total_params_before\n",
    "    print(f\"[INFO] Non-zero parameters AFTER pruning: {nonzero_params_after:,}\")\n",
    "    print(f\"[INFO] Pruned parameters: {zero_params:,} ({pruned_ratio:.2f}%)\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    " \n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "\n",
    "    for epoch in range(35):  # You can change this to 50 or more\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd53db05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5666 | Train Acc: 0.7878 | Val Loss: 0.5703 | Val Acc: 0.7885\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4736 | Train Acc: 0.8262 | Val Loss: 0.4977 | Val Acc: 0.8153\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4536 | Train Acc: 0.8315 | Val Loss: 0.6087 | Val Acc: 0.7741\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4310 | Train Acc: 0.8407 | Val Loss: 0.4806 | Val Acc: 0.8179\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4274 | Train Acc: 0.8393 | Val Loss: 0.6876 | Val Acc: 0.7791\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4147 | Train Acc: 0.8459 | Val Loss: 0.4184 | Val Acc: 0.8381\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.4056 | Train Acc: 0.8507 | Val Loss: 0.4262 | Val Acc: 0.8387\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.4013 | Train Acc: 0.8519 | Val Loss: 0.4267 | Val Acc: 0.8504\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.3910 | Train Acc: 0.8542 | Val Loss: 0.4674 | Val Acc: 0.8250\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.3876 | Train Acc: 0.8554 | Val Loss: 0.3761 | Val Acc: 0.8597\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3830 | Train Acc: 0.8580 | Val Loss: 0.3601 | Val Acc: 0.8619\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3729 | Train Acc: 0.8640 | Val Loss: 0.4134 | Val Acc: 0.8410\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3717 | Train Acc: 0.8648 | Val Loss: 0.3907 | Val Acc: 0.8509\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3588 | Train Acc: 0.8682 | Val Loss: 0.3640 | Val Acc: 0.8609\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3527 | Train Acc: 0.8692 | Val Loss: 0.3818 | Val Acc: 0.8580\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3473 | Train Acc: 0.8691 | Val Loss: 0.3584 | Val Acc: 0.8639\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3402 | Train Acc: 0.8738 | Val Loss: 0.3919 | Val Acc: 0.8536\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3308 | Train Acc: 0.8769 | Val Loss: 0.3584 | Val Acc: 0.8668\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3209 | Train Acc: 0.8809 | Val Loss: 0.3898 | Val Acc: 0.8513\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3125 | Train Acc: 0.8831 | Val Loss: 0.3780 | Val Acc: 0.8593\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3041 | Train Acc: 0.8878 | Val Loss: 0.3849 | Val Acc: 0.8646\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.2978 | Train Acc: 0.8926 | Val Loss: 0.4114 | Val Acc: 0.8501\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.2913 | Train Acc: 0.8920 | Val Loss: 0.4383 | Val Acc: 0.8448\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.2779 | Train Acc: 0.8939 | Val Loss: 0.3955 | Val Acc: 0.8629\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.2661 | Train Acc: 0.9004 | Val Loss: 0.3651 | Val Acc: 0.8683\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.2604 | Train Acc: 0.9028 | Val Loss: 0.4523 | Val Acc: 0.8441\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.2493 | Train Acc: 0.9073 | Val Loss: 0.4986 | Val Acc: 0.8253\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.2362 | Train Acc: 0.9112 | Val Loss: 0.5548 | Val Acc: 0.8149\n",
      "[Fold 1 | Epoch 29] Train Loss: 0.2316 | Train Acc: 0.9126 | Val Loss: 0.4344 | Val Acc: 0.8530\n",
      "[Fold 1 | Epoch 30] Train Loss: 0.2239 | Train Acc: 0.9154 | Val Loss: 0.4481 | Val Acc: 0.8504\n",
      "[Fold 1 | Epoch 31] Train Loss: 0.2146 | Train Acc: 0.9193 | Val Loss: 0.4839 | Val Acc: 0.8556\n",
      "[Fold 1 | Epoch 32] Train Loss: 0.2033 | Train Acc: 0.9240 | Val Loss: 0.4022 | Val Acc: 0.8663\n",
      "[Fold 1 | Epoch 33] Train Loss: 0.1901 | Train Acc: 0.9279 | Val Loss: 0.6037 | Val Acc: 0.8382\n",
      "[Fold 1 | Epoch 34] Train Loss: 0.1895 | Train Acc: 0.9282 | Val Loss: 0.4825 | Val Acc: 0.8433\n",
      "[Fold 1 | Epoch 35] Train Loss: 0.1747 | Train Acc: 0.9333 | Val Loss: 0.4517 | Val Acc: 0.8629\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 25\n",
      "ACC: 0.8683 | MF1: 0.8268 | G-Mean: 0.8892\n",
      "[Class 0] Prec: 0.9380 | Rec: 0.9019 | F1: 0.9196 | GM: 0.9433\n",
      "[Class 1] Prec: 0.5445 | Rec: 0.6411 | F1: 0.5889 | GM: 0.7841\n",
      "[Class 2] Prec: 0.8904 | Rec: 0.9221 | F1: 0.9059 | GM: 0.9187\n",
      "[Class 3] Prec: 0.9362 | Rec: 0.8245 | F1: 0.8768 | GM: 0.9044\n",
      "[Class 4] Prec: 0.8561 | Rec: 0.8301 | F1: 0.8429 | GM: 0.8957\n",
      "\n",
      "===== Fold 2 =====\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5673 | Train Acc: 0.7860 | Val Loss: 0.4701 | Val Acc: 0.8252\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4847 | Train Acc: 0.8192 | Val Loss: 0.4505 | Val Acc: 0.8336\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4516 | Train Acc: 0.8303 | Val Loss: 0.5207 | Val Acc: 0.7949\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4340 | Train Acc: 0.8374 | Val Loss: 0.4583 | Val Acc: 0.8321\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4253 | Train Acc: 0.8428 | Val Loss: 0.4212 | Val Acc: 0.8488\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4128 | Train Acc: 0.8471 | Val Loss: 0.4393 | Val Acc: 0.8382\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4055 | Train Acc: 0.8496 | Val Loss: 0.4091 | Val Acc: 0.8605\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.3999 | Train Acc: 0.8498 | Val Loss: 0.4555 | Val Acc: 0.8381\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.3955 | Train Acc: 0.8525 | Val Loss: 0.4978 | Val Acc: 0.8345\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.3882 | Train Acc: 0.8546 | Val Loss: 0.4517 | Val Acc: 0.8400\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3804 | Train Acc: 0.8589 | Val Loss: 0.3935 | Val Acc: 0.8507\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3755 | Train Acc: 0.8612 | Val Loss: 0.4111 | Val Acc: 0.8514\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3688 | Train Acc: 0.8643 | Val Loss: 0.3925 | Val Acc: 0.8596\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3673 | Train Acc: 0.8631 | Val Loss: 0.4119 | Val Acc: 0.8544\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3542 | Train Acc: 0.8671 | Val Loss: 0.4185 | Val Acc: 0.8421\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3559 | Train Acc: 0.8679 | Val Loss: 0.3950 | Val Acc: 0.8566\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3448 | Train Acc: 0.8718 | Val Loss: 0.4283 | Val Acc: 0.8455\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3366 | Train Acc: 0.8763 | Val Loss: 0.3777 | Val Acc: 0.8622\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3261 | Train Acc: 0.8784 | Val Loss: 0.4286 | Val Acc: 0.8523\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3187 | Train Acc: 0.8825 | Val Loss: 0.3839 | Val Acc: 0.8599\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3072 | Train Acc: 0.8856 | Val Loss: 0.4248 | Val Acc: 0.8463\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.2997 | Train Acc: 0.8889 | Val Loss: 0.4093 | Val Acc: 0.8567\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.2958 | Train Acc: 0.8892 | Val Loss: 0.4441 | Val Acc: 0.8404\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.2894 | Train Acc: 0.8919 | Val Loss: 0.4472 | Val Acc: 0.8531\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.2764 | Train Acc: 0.8979 | Val Loss: 0.4355 | Val Acc: 0.8507\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.2619 | Train Acc: 0.9023 | Val Loss: 0.4133 | Val Acc: 0.8521\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.2562 | Train Acc: 0.9051 | Val Loss: 0.4284 | Val Acc: 0.8513\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.2413 | Train Acc: 0.9108 | Val Loss: 0.4523 | Val Acc: 0.8554\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.2363 | Train Acc: 0.9111 | Val Loss: 0.4481 | Val Acc: 0.8595\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.2282 | Train Acc: 0.9148 | Val Loss: 0.4590 | Val Acc: 0.8616\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.2173 | Train Acc: 0.9193 | Val Loss: 0.4657 | Val Acc: 0.8520\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.2075 | Train Acc: 0.9225 | Val Loss: 0.4575 | Val Acc: 0.8557\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.2003 | Train Acc: 0.9252 | Val Loss: 0.4888 | Val Acc: 0.8513\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.1925 | Train Acc: 0.9264 | Val Loss: 0.5243 | Val Acc: 0.8497\n",
      "[Fold 2 | Epoch 35] Train Loss: 0.1840 | Train Acc: 0.9294 | Val Loss: 0.5851 | Val Acc: 0.8523\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 18\n",
      "ACC: 0.8622 | MF1: 0.7873 | G-Mean: 0.8519\n",
      "[Class 0] Prec: 0.8561 | Rec: 0.9432 | F1: 0.8975 | GM: 0.9542\n",
      "[Class 1] Prec: 0.6681 | Rec: 0.2898 | F1: 0.4043 | GM: 0.5352\n",
      "[Class 2] Prec: 0.9119 | Rec: 0.9074 | F1: 0.9096 | GM: 0.9198\n",
      "[Class 3] Prec: 0.9155 | Rec: 0.8819 | F1: 0.8984 | GM: 0.9336\n",
      "[Class 4] Prec: 0.7680 | Rec: 0.8952 | F1: 0.8268 | GM: 0.9164\n",
      "\n",
      "===== Fold 3 =====\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5630 | Train Acc: 0.7890 | Val Loss: 0.5029 | Val Acc: 0.8085\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4637 | Train Acc: 0.8288 | Val Loss: 0.7770 | Val Acc: 0.7411\n",
      "[Fold 3 | Epoch 3] Train Loss: 0.4474 | Train Acc: 0.8324 | Val Loss: 0.5003 | Val Acc: 0.8197\n",
      "[Fold 3 | Epoch 4] Train Loss: 0.4375 | Train Acc: 0.8362 | Val Loss: 0.4901 | Val Acc: 0.8203\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4230 | Train Acc: 0.8423 | Val Loss: 0.4456 | Val Acc: 0.8276\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4120 | Train Acc: 0.8464 | Val Loss: 0.5221 | Val Acc: 0.8028\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4084 | Train Acc: 0.8471 | Val Loss: 0.4183 | Val Acc: 0.8457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3 | Epoch 8] Train Loss: 0.3975 | Train Acc: 0.8527 | Val Loss: 0.5332 | Val Acc: 0.8015\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.3877 | Train Acc: 0.8553 | Val Loss: 0.4176 | Val Acc: 0.8480\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.3885 | Train Acc: 0.8561 | Val Loss: 0.4011 | Val Acc: 0.8521\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3801 | Train Acc: 0.8602 | Val Loss: 0.4172 | Val Acc: 0.8553\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3760 | Train Acc: 0.8585 | Val Loss: 0.4219 | Val Acc: 0.8496\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3628 | Train Acc: 0.8653 | Val Loss: 0.3877 | Val Acc: 0.8615\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3627 | Train Acc: 0.8635 | Val Loss: 0.4289 | Val Acc: 0.8365\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3533 | Train Acc: 0.8653 | Val Loss: 0.3787 | Val Acc: 0.8628\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3458 | Train Acc: 0.8721 | Val Loss: 0.5301 | Val Acc: 0.8052\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3388 | Train Acc: 0.8729 | Val Loss: 0.4548 | Val Acc: 0.8369\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3300 | Train Acc: 0.8783 | Val Loss: 0.4121 | Val Acc: 0.8543\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3206 | Train Acc: 0.8801 | Val Loss: 0.4408 | Val Acc: 0.8392\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.3105 | Train Acc: 0.8849 | Val Loss: 0.4043 | Val Acc: 0.8632\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.3060 | Train Acc: 0.8871 | Val Loss: 0.4225 | Val Acc: 0.8517\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.2962 | Train Acc: 0.8871 | Val Loss: 0.4556 | Val Acc: 0.8418\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.2778 | Train Acc: 0.8957 | Val Loss: 0.4090 | Val Acc: 0.8651\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.2728 | Train Acc: 0.8964 | Val Loss: 0.4926 | Val Acc: 0.8379\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.2604 | Train Acc: 0.9036 | Val Loss: 0.5121 | Val Acc: 0.8450\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.2552 | Train Acc: 0.9045 | Val Loss: 0.4614 | Val Acc: 0.8572\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.2403 | Train Acc: 0.9081 | Val Loss: 0.4913 | Val Acc: 0.8437\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.2347 | Train Acc: 0.9109 | Val Loss: 0.4387 | Val Acc: 0.8622\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.2207 | Train Acc: 0.9183 | Val Loss: 0.4480 | Val Acc: 0.8619\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.2125 | Train Acc: 0.9199 | Val Loss: 0.4630 | Val Acc: 0.8653\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.2043 | Train Acc: 0.9236 | Val Loss: 0.4951 | Val Acc: 0.8569\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.1991 | Train Acc: 0.9251 | Val Loss: 0.4926 | Val Acc: 0.8523\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.1877 | Train Acc: 0.9288 | Val Loss: 0.5131 | Val Acc: 0.8623\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.1782 | Train Acc: 0.9334 | Val Loss: 0.5148 | Val Acc: 0.8595\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.1672 | Train Acc: 0.9376 | Val Loss: 0.5273 | Val Acc: 0.8635\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 30\n",
      "ACC: 0.8653 | MF1: 0.8147 | G-Mean: 0.8717\n",
      "[Class 0] Prec: 0.9260 | Rec: 0.9191 | F1: 0.9226 | GM: 0.9513\n",
      "[Class 1] Prec: 0.6897 | Rec: 0.4382 | F1: 0.5359 | GM: 0.6569\n",
      "[Class 2] Prec: 0.9014 | Rec: 0.8969 | F1: 0.8991 | GM: 0.9111\n",
      "[Class 3] Prec: 0.9260 | Rec: 0.8476 | F1: 0.8851 | GM: 0.9161\n",
      "[Class 4] Prec: 0.7597 | Rec: 0.9165 | F1: 0.8308 | GM: 0.9229\n",
      "\n",
      "===== Fold 4 =====\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5706 | Train Acc: 0.7839 | Val Loss: 0.4566 | Val Acc: 0.8313\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4801 | Train Acc: 0.8215 | Val Loss: 0.4761 | Val Acc: 0.8258\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4622 | Train Acc: 0.8290 | Val Loss: 0.4993 | Val Acc: 0.8173\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4478 | Train Acc: 0.8332 | Val Loss: 0.4364 | Val Acc: 0.8367\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4357 | Train Acc: 0.8381 | Val Loss: 0.4197 | Val Acc: 0.8471\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4164 | Train Acc: 0.8456 | Val Loss: 0.6347 | Val Acc: 0.7655\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.4104 | Train Acc: 0.8483 | Val Loss: 0.4375 | Val Acc: 0.8355\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.4076 | Train Acc: 0.8475 | Val Loss: 0.4689 | Val Acc: 0.8134\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.4016 | Train Acc: 0.8516 | Val Loss: 0.4289 | Val Acc: 0.8415\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.3940 | Train Acc: 0.8529 | Val Loss: 0.4522 | Val Acc: 0.8372\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.3865 | Train Acc: 0.8563 | Val Loss: 0.3862 | Val Acc: 0.8546\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3814 | Train Acc: 0.8578 | Val Loss: 0.4472 | Val Acc: 0.8357\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3781 | Train Acc: 0.8594 | Val Loss: 0.4271 | Val Acc: 0.8402\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3698 | Train Acc: 0.8603 | Val Loss: 0.4086 | Val Acc: 0.8498\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3666 | Train Acc: 0.8628 | Val Loss: 0.3864 | Val Acc: 0.8605\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3601 | Train Acc: 0.8651 | Val Loss: 0.4259 | Val Acc: 0.8443\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3529 | Train Acc: 0.8692 | Val Loss: 0.3986 | Val Acc: 0.8504\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3465 | Train Acc: 0.8719 | Val Loss: 0.3939 | Val Acc: 0.8549\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3388 | Train Acc: 0.8744 | Val Loss: 0.4387 | Val Acc: 0.8440\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3279 | Train Acc: 0.8781 | Val Loss: 0.3851 | Val Acc: 0.8615\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3239 | Train Acc: 0.8795 | Val Loss: 0.5067 | Val Acc: 0.8189\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.3183 | Train Acc: 0.8827 | Val Loss: 0.4406 | Val Acc: 0.8473\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.3087 | Train Acc: 0.8842 | Val Loss: 0.4390 | Val Acc: 0.8454\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.2962 | Train Acc: 0.8894 | Val Loss: 0.3980 | Val Acc: 0.8539\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.2893 | Train Acc: 0.8925 | Val Loss: 0.4032 | Val Acc: 0.8622\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.2818 | Train Acc: 0.8970 | Val Loss: 0.5386 | Val Acc: 0.8189\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.2748 | Train Acc: 0.8981 | Val Loss: 0.4013 | Val Acc: 0.8593\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.2649 | Train Acc: 0.9021 | Val Loss: 0.4856 | Val Acc: 0.8405\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.2592 | Train Acc: 0.9017 | Val Loss: 0.4353 | Val Acc: 0.8523\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.2504 | Train Acc: 0.9055 | Val Loss: 0.4032 | Val Acc: 0.8632\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.2429 | Train Acc: 0.9094 | Val Loss: 0.4630 | Val Acc: 0.8542\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.2281 | Train Acc: 0.9138 | Val Loss: 0.4620 | Val Acc: 0.8444\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.2223 | Train Acc: 0.9164 | Val Loss: 0.4542 | Val Acc: 0.8491\n",
      "[Fold 4 | Epoch 34] Train Loss: 0.2118 | Train Acc: 0.9200 | Val Loss: 0.4927 | Val Acc: 0.8613\n",
      "[Fold 4 | Epoch 35] Train Loss: 0.2042 | Train Acc: 0.9247 | Val Loss: 0.4860 | Val Acc: 0.8428\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 30\n",
      "ACC: 0.8632 | MF1: 0.8217 | G-Mean: 0.8928\n",
      "[Class 0] Prec: 0.9290 | Rec: 0.8992 | F1: 0.9138 | GM: 0.9407\n",
      "[Class 1] Prec: 0.5519 | Rec: 0.5949 | F1: 0.5726 | GM: 0.7576\n",
      "[Class 2] Prec: 0.9164 | Rec: 0.8713 | F1: 0.8933 | GM: 0.9055\n",
      "[Class 3] Prec: 0.8536 | Rec: 0.9393 | F1: 0.8944 | GM: 0.9574\n",
      "[Class 4] Prec: 0.8160 | Rec: 0.8532 | F1: 0.8342 | GM: 0.9028\n",
      "\n",
      "===== Fold 5 =====\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.5869 | Train Acc: 0.7778 | Val Loss: 0.5262 | Val Acc: 0.8017\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4762 | Train Acc: 0.8217 | Val Loss: 0.7126 | Val Acc: 0.7684\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4530 | Train Acc: 0.8309 | Val Loss: 0.4566 | Val Acc: 0.8236\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4377 | Train Acc: 0.8363 | Val Loss: 0.5630 | Val Acc: 0.7885\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4229 | Train Acc: 0.8436 | Val Loss: 0.5226 | Val Acc: 0.8248\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4193 | Train Acc: 0.8447 | Val Loss: 0.5763 | Val Acc: 0.7885\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.4100 | Train Acc: 0.8497 | Val Loss: 0.3965 | Val Acc: 0.8603\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.4049 | Train Acc: 0.8508 | Val Loss: 0.4335 | Val Acc: 0.8488\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.3968 | Train Acc: 0.8543 | Val Loss: 0.4305 | Val Acc: 0.8517\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.3917 | Train Acc: 0.8553 | Val Loss: 0.4709 | Val Acc: 0.8334\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.3827 | Train Acc: 0.8597 | Val Loss: 0.5324 | Val Acc: 0.8012\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3830 | Train Acc: 0.8566 | Val Loss: 0.4063 | Val Acc: 0.8470\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3663 | Train Acc: 0.8633 | Val Loss: 0.4294 | Val Acc: 0.8407\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3643 | Train Acc: 0.8644 | Val Loss: 0.4545 | Val Acc: 0.8443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 15] Train Loss: 0.3655 | Train Acc: 0.8649 | Val Loss: 0.3973 | Val Acc: 0.8543\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3546 | Train Acc: 0.8685 | Val Loss: 0.4340 | Val Acc: 0.8497\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3461 | Train Acc: 0.8722 | Val Loss: 0.4626 | Val Acc: 0.8365\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3413 | Train Acc: 0.8751 | Val Loss: 0.3897 | Val Acc: 0.8619\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3292 | Train Acc: 0.8804 | Val Loss: 0.3964 | Val Acc: 0.8585\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3265 | Train Acc: 0.8791 | Val Loss: 0.4023 | Val Acc: 0.8542\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.3164 | Train Acc: 0.8825 | Val Loss: 0.5188 | Val Acc: 0.8296\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.3065 | Train Acc: 0.8841 | Val Loss: 0.4348 | Val Acc: 0.8540\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.2968 | Train Acc: 0.8875 | Val Loss: 0.4255 | Val Acc: 0.8597\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.2904 | Train Acc: 0.8936 | Val Loss: 0.3960 | Val Acc: 0.8646\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.2855 | Train Acc: 0.8940 | Val Loss: 0.4254 | Val Acc: 0.8552\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.2776 | Train Acc: 0.8962 | Val Loss: 0.4140 | Val Acc: 0.8572\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.2626 | Train Acc: 0.9019 | Val Loss: 0.4732 | Val Acc: 0.8506\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.2617 | Train Acc: 0.9020 | Val Loss: 0.4641 | Val Acc: 0.8488\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.2528 | Train Acc: 0.9049 | Val Loss: 0.4310 | Val Acc: 0.8497\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.2397 | Train Acc: 0.9104 | Val Loss: 0.4326 | Val Acc: 0.8595\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.2323 | Train Acc: 0.9118 | Val Loss: 0.4621 | Val Acc: 0.8564\n",
      "[Fold 5 | Epoch 32] Train Loss: 0.2238 | Train Acc: 0.9167 | Val Loss: 0.4597 | Val Acc: 0.8600\n",
      "[Fold 5 | Epoch 33] Train Loss: 0.2148 | Train Acc: 0.9181 | Val Loss: 0.5366 | Val Acc: 0.8296\n",
      "[Fold 5 | Epoch 34] Train Loss: 0.2055 | Train Acc: 0.9232 | Val Loss: 0.5986 | Val Acc: 0.8265\n",
      "[Fold 5 | Epoch 35] Train Loss: 0.1952 | Train Acc: 0.9280 | Val Loss: 0.4639 | Val Acc: 0.8534\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 24\n",
      "ACC: 0.8646 | MF1: 0.8179 | G-Mean: 0.8825\n",
      "[Class 0] Prec: 0.8790 | Rec: 0.9374 | F1: 0.9073 | GM: 0.9539\n",
      "[Class 1] Prec: 0.6341 | Rec: 0.4961 | F1: 0.5567 | GM: 0.6963\n",
      "[Class 2] Prec: 0.9086 | Rec: 0.8880 | F1: 0.8982 | GM: 0.9108\n",
      "[Class 3] Prec: 0.8627 | Rec: 0.9381 | F1: 0.8988 | GM: 0.9577\n",
      "[Class 4] Prec: 0.8246 | Rec: 0.8328 | F1: 0.8287 | GM: 0.8937\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8647 | MF1: 0.8152 | G-Mean: 0.8788\n",
      "[Class 0] Prec: 0.9039 | Rec: 0.9200 | F1: 0.9119 | GM: 0.9487\n",
      "[Class 1] Prec: 0.6003 | Rec: 0.4890 | F1: 0.5390 | GM: 0.6904\n",
      "[Class 2] Prec: 0.9055 | Rec: 0.8972 | F1: 0.9013 | GM: 0.9133\n",
      "[Class 3] Prec: 0.8952 | Rec: 0.8869 | F1: 0.8911 | GM: 0.9346\n",
      "[Class 4] Prec: 0.8019 | Rec: 0.8657 | F1: 0.8326 | GM: 0.9067\n",
      "Confusion Matrix:\n",
      "[[ 5831   253    96    21   137]\n",
      " [  342  1224   370     4   563]\n",
      " [  126   254 13405   436   720]\n",
      " [    7     0   494  3938     1]\n",
      " [  145   308   439     0  5751]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# ==== Load and Normalize Data ====\n",
    "\n",
    "df = pd.read_csv(\"pruned_dataset3.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "# Z-score normalization\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== Evaluation Metric Function ====\n",
    "def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    gmeans = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        tn = np.sum((y_pred != c) & (y_true != c))\n",
    "        fp = np.sum((y_pred == c) & (y_true != c))\n",
    "        gm = np.sqrt((tp / (tp + fn + 1e-6)) * (tn / (tn + fp + 1e-6)))\n",
    "        gmeans.append(gm)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, mf1, np.mean(gmeans), prec, rec, f1s, gmeans, cm\n",
    "\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "    X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "    X_val, y_val = X_all[val_idx], y_all[val_idx]\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "\n",
    "    model = FinalNetwork(C=12, num_classes=num_classes, layers=11, genotype=searched_genotype).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "\n",
    "    for epoch in range(35):  # You can change this to 50 or more\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91c671f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[INFO] Total parameters BEFORE pruning: 284,105\n",
      "[INFO] Non-zero parameters AFTER pruning: 142,775\n",
      "[INFO] Pruned parameters: 141,330 (49.75%)\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5718 | Train Acc: 0.7854 | Val Loss: 0.7692 | Val Acc: 0.7421\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4934 | Train Acc: 0.8150 | Val Loss: 0.4560 | Val Acc: 0.8339\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4602 | Train Acc: 0.8273 | Val Loss: 0.4531 | Val Acc: 0.8361\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4482 | Train Acc: 0.8348 | Val Loss: 0.5172 | Val Acc: 0.8137\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4341 | Train Acc: 0.8377 | Val Loss: 0.4753 | Val Acc: 0.8301\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4263 | Train Acc: 0.8432 | Val Loss: 0.4667 | Val Acc: 0.8316\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.4241 | Train Acc: 0.8430 | Val Loss: 0.4780 | Val Acc: 0.8232\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.4114 | Train Acc: 0.8468 | Val Loss: 0.4410 | Val Acc: 0.8293\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.4087 | Train Acc: 0.8492 | Val Loss: 0.4038 | Val Acc: 0.8483\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.3986 | Train Acc: 0.8517 | Val Loss: 0.3934 | Val Acc: 0.8550\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3959 | Train Acc: 0.8553 | Val Loss: 0.3985 | Val Acc: 0.8576\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3911 | Train Acc: 0.8541 | Val Loss: 0.3828 | Val Acc: 0.8579\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3895 | Train Acc: 0.8546 | Val Loss: 0.4109 | Val Acc: 0.8526\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3833 | Train Acc: 0.8580 | Val Loss: 0.4148 | Val Acc: 0.8448\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3741 | Train Acc: 0.8624 | Val Loss: 0.4147 | Val Acc: 0.8441\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3745 | Train Acc: 0.8612 | Val Loss: 0.3884 | Val Acc: 0.8566\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3681 | Train Acc: 0.8640 | Val Loss: 0.4476 | Val Acc: 0.8463\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3644 | Train Acc: 0.8634 | Val Loss: 0.3949 | Val Acc: 0.8520\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3588 | Train Acc: 0.8665 | Val Loss: 0.4171 | Val Acc: 0.8500\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3531 | Train Acc: 0.8680 | Val Loss: 0.4055 | Val Acc: 0.8513\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3518 | Train Acc: 0.8711 | Val Loss: 0.3847 | Val Acc: 0.8600\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.3440 | Train Acc: 0.8699 | Val Loss: 0.4101 | Val Acc: 0.8450\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.3381 | Train Acc: 0.8755 | Val Loss: 0.4108 | Val Acc: 0.8534\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.3342 | Train Acc: 0.8743 | Val Loss: 0.4079 | Val Acc: 0.8572\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.3281 | Train Acc: 0.8779 | Val Loss: 0.4849 | Val Acc: 0.8306\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.3255 | Train Acc: 0.8783 | Val Loss: 0.4013 | Val Acc: 0.8562\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.3162 | Train Acc: 0.8836 | Val Loss: 0.4270 | Val Acc: 0.8424\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.3026 | Train Acc: 0.8880 | Val Loss: 0.4714 | Val Acc: 0.8421\n",
      "[Fold 1 | Epoch 29] Train Loss: 0.3011 | Train Acc: 0.8848 | Val Loss: 0.3931 | Val Acc: 0.8635\n",
      "[Fold 1 | Epoch 30] Train Loss: 0.2982 | Train Acc: 0.8891 | Val Loss: 0.3956 | Val Acc: 0.8632\n",
      "[Fold 1 | Epoch 31] Train Loss: 0.2899 | Train Acc: 0.8934 | Val Loss: 0.4145 | Val Acc: 0.8562\n",
      "[Fold 1 | Epoch 32] Train Loss: 0.2805 | Train Acc: 0.8959 | Val Loss: 0.3798 | Val Acc: 0.8642\n",
      "[Fold 1 | Epoch 33] Train Loss: 0.2770 | Train Acc: 0.8971 | Val Loss: 0.4817 | Val Acc: 0.8237\n",
      "[Fold 1 | Epoch 34] Train Loss: 0.2657 | Train Acc: 0.9000 | Val Loss: 0.4099 | Val Acc: 0.8638\n",
      "[Fold 1 | Epoch 35] Train Loss: 0.2621 | Train Acc: 0.9022 | Val Loss: 0.4137 | Val Acc: 0.8597\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 32\n",
      "ACC: 0.8642 | MF1: 0.8136 | G-Mean: 0.8767\n",
      "[Class 0] Prec: 0.8899 | Rec: 0.9181 | F1: 0.9038 | GM: 0.9457\n",
      "[Class 1] Prec: 0.6366 | Rec: 0.4569 | F1: 0.5320 | GM: 0.6689\n",
      "[Class 2] Prec: 0.9066 | Rec: 0.8931 | F1: 0.8998 | GM: 0.9125\n",
      "[Class 3] Prec: 0.8883 | Rec: 0.9148 | F1: 0.9014 | GM: 0.9482\n",
      "[Class 4] Prec: 0.7965 | Rec: 0.8695 | F1: 0.8314 | GM: 0.9082\n",
      "\n",
      "===== Fold 2 =====\n",
      "[INFO] Total parameters BEFORE pruning: 284,105\n",
      "[INFO] Non-zero parameters AFTER pruning: 142,775\n",
      "[INFO] Pruned parameters: 141,330 (49.75%)\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5755 | Train Acc: 0.7841 | Val Loss: 0.8858 | Val Acc: 0.7008\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4791 | Train Acc: 0.8214 | Val Loss: 0.4847 | Val Acc: 0.8167\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4637 | Train Acc: 0.8269 | Val Loss: 0.4949 | Val Acc: 0.8177\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4438 | Train Acc: 0.8348 | Val Loss: 0.5496 | Val Acc: 0.8110\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4360 | Train Acc: 0.8365 | Val Loss: 0.4266 | Val Acc: 0.8463\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4293 | Train Acc: 0.8394 | Val Loss: 0.4304 | Val Acc: 0.8365\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4170 | Train Acc: 0.8453 | Val Loss: 0.4435 | Val Acc: 0.8405\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.4157 | Train Acc: 0.8466 | Val Loss: 0.4615 | Val Acc: 0.8387\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.4041 | Train Acc: 0.8497 | Val Loss: 0.4265 | Val Acc: 0.8418\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.4093 | Train Acc: 0.8490 | Val Loss: 0.3944 | Val Acc: 0.8590\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3996 | Train Acc: 0.8520 | Val Loss: 0.4489 | Val Acc: 0.8342\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3951 | Train Acc: 0.8540 | Val Loss: 0.3946 | Val Acc: 0.8539\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3915 | Train Acc: 0.8550 | Val Loss: 0.4041 | Val Acc: 0.8503\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3840 | Train Acc: 0.8571 | Val Loss: 0.3964 | Val Acc: 0.8506\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3780 | Train Acc: 0.8571 | Val Loss: 0.5075 | Val Acc: 0.8186\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3688 | Train Acc: 0.8622 | Val Loss: 0.3846 | Val Acc: 0.8569\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3680 | Train Acc: 0.8629 | Val Loss: 0.4039 | Val Acc: 0.8547\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3679 | Train Acc: 0.8631 | Val Loss: 0.3977 | Val Acc: 0.8547\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3635 | Train Acc: 0.8662 | Val Loss: 0.4029 | Val Acc: 0.8501\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3591 | Train Acc: 0.8659 | Val Loss: 0.3995 | Val Acc: 0.8550\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3571 | Train Acc: 0.8689 | Val Loss: 0.3851 | Val Acc: 0.8579\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.3464 | Train Acc: 0.8715 | Val Loss: 0.4576 | Val Acc: 0.8364\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.3385 | Train Acc: 0.8732 | Val Loss: 0.4658 | Val Acc: 0.8268\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.3339 | Train Acc: 0.8746 | Val Loss: 0.4207 | Val Acc: 0.8531\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.3243 | Train Acc: 0.8788 | Val Loss: 0.4291 | Val Acc: 0.8514\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.3213 | Train Acc: 0.8779 | Val Loss: 0.4286 | Val Acc: 0.8507\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.3154 | Train Acc: 0.8823 | Val Loss: 0.4019 | Val Acc: 0.8587\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.3124 | Train Acc: 0.8817 | Val Loss: 0.4074 | Val Acc: 0.8530\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.3052 | Train Acc: 0.8838 | Val Loss: 0.4018 | Val Acc: 0.8566\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.2985 | Train Acc: 0.8865 | Val Loss: 0.4609 | Val Acc: 0.8390\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.2953 | Train Acc: 0.8882 | Val Loss: 0.4222 | Val Acc: 0.8559\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.2851 | Train Acc: 0.8927 | Val Loss: 0.4077 | Val Acc: 0.8593\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.2864 | Train Acc: 0.8915 | Val Loss: 0.4246 | Val Acc: 0.8534\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.2682 | Train Acc: 0.8994 | Val Loss: 0.4401 | Val Acc: 0.8520\n",
      "[Fold 2 | Epoch 35] Train Loss: 0.2630 | Train Acc: 0.9016 | Val Loss: 0.4640 | Val Acc: 0.8457\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 32\n",
      "ACC: 0.8593 | MF1: 0.8145 | G-Mean: 0.8788\n",
      "[Class 0] Prec: 0.9482 | Rec: 0.8918 | F1: 0.9192 | GM: 0.9391\n",
      "[Class 1] Prec: 0.6464 | Rec: 0.4804 | F1: 0.5512 | GM: 0.6859\n",
      "[Class 2] Prec: 0.9135 | Rec: 0.8724 | F1: 0.8925 | GM: 0.9052\n",
      "[Class 3] Prec: 0.8792 | Rec: 0.9181 | F1: 0.8983 | GM: 0.9492\n",
      "[Class 4] Prec: 0.7356 | Rec: 0.9046 | F1: 0.8114 | GM: 0.9146\n",
      "\n",
      "===== Fold 3 =====\n",
      "[INFO] Total parameters BEFORE pruning: 284,105\n",
      "[INFO] Non-zero parameters AFTER pruning: 142,775\n",
      "[INFO] Pruned parameters: 141,330 (49.75%)\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5784 | Train Acc: 0.7832 | Val Loss: 0.5912 | Val Acc: 0.7750\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4894 | Train Acc: 0.8173 | Val Loss: 0.4996 | Val Acc: 0.8164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3 | Epoch 3] Train Loss: 0.4608 | Train Acc: 0.8292 | Val Loss: 0.4489 | Val Acc: 0.8348\n",
      "[Fold 3 | Epoch 4] Train Loss: 0.4485 | Train Acc: 0.8344 | Val Loss: 0.7031 | Val Acc: 0.7730\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4392 | Train Acc: 0.8362 | Val Loss: 0.4561 | Val Acc: 0.8329\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4277 | Train Acc: 0.8409 | Val Loss: 0.4062 | Val Acc: 0.8547\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4196 | Train Acc: 0.8445 | Val Loss: 0.4764 | Val Acc: 0.8324\n",
      "[Fold 3 | Epoch 8] Train Loss: 0.4182 | Train Acc: 0.8436 | Val Loss: 0.4341 | Val Acc: 0.8430\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.4117 | Train Acc: 0.8448 | Val Loss: 0.5266 | Val Acc: 0.8246\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.4042 | Train Acc: 0.8500 | Val Loss: 0.4507 | Val Acc: 0.8391\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3960 | Train Acc: 0.8531 | Val Loss: 0.6396 | Val Acc: 0.7769\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3932 | Train Acc: 0.8530 | Val Loss: 0.4595 | Val Acc: 0.8306\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3869 | Train Acc: 0.8563 | Val Loss: 0.4092 | Val Acc: 0.8500\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3880 | Train Acc: 0.8549 | Val Loss: 0.4383 | Val Acc: 0.8497\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3803 | Train Acc: 0.8580 | Val Loss: 0.5306 | Val Acc: 0.8021\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3768 | Train Acc: 0.8600 | Val Loss: 0.4280 | Val Acc: 0.8471\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3731 | Train Acc: 0.8588 | Val Loss: 0.4380 | Val Acc: 0.8414\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3645 | Train Acc: 0.8649 | Val Loss: 0.4583 | Val Acc: 0.8421\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3658 | Train Acc: 0.8624 | Val Loss: 0.4156 | Val Acc: 0.8455\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.3555 | Train Acc: 0.8674 | Val Loss: 0.3967 | Val Acc: 0.8583\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.3531 | Train Acc: 0.8673 | Val Loss: 0.4039 | Val Acc: 0.8557\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.3447 | Train Acc: 0.8704 | Val Loss: 0.4546 | Val Acc: 0.8473\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.3400 | Train Acc: 0.8740 | Val Loss: 0.4200 | Val Acc: 0.8577\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.3367 | Train Acc: 0.8747 | Val Loss: 0.4035 | Val Acc: 0.8543\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.3316 | Train Acc: 0.8770 | Val Loss: 0.4868 | Val Acc: 0.8329\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.3284 | Train Acc: 0.8760 | Val Loss: 0.3851 | Val Acc: 0.8633\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.3111 | Train Acc: 0.8815 | Val Loss: 0.4193 | Val Acc: 0.8534\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.3106 | Train Acc: 0.8842 | Val Loss: 0.5245 | Val Acc: 0.8134\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.3032 | Train Acc: 0.8865 | Val Loss: 0.4286 | Val Acc: 0.8501\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.2941 | Train Acc: 0.8897 | Val Loss: 0.4526 | Val Acc: 0.8468\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.2839 | Train Acc: 0.8934 | Val Loss: 0.4450 | Val Acc: 0.8564\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.2848 | Train Acc: 0.8948 | Val Loss: 0.4059 | Val Acc: 0.8606\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.2783 | Train Acc: 0.8964 | Val Loss: 0.4221 | Val Acc: 0.8560\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.2682 | Train Acc: 0.9000 | Val Loss: 0.5074 | Val Acc: 0.8412\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.2627 | Train Acc: 0.8999 | Val Loss: 0.5026 | Val Acc: 0.8316\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 26\n",
      "ACC: 0.8633 | MF1: 0.8165 | G-Mean: 0.8820\n",
      "[Class 0] Prec: 0.8790 | Rec: 0.9150 | F1: 0.8966 | GM: 0.9427\n",
      "[Class 1] Prec: 0.6108 | Rec: 0.5078 | F1: 0.5546 | GM: 0.7035\n",
      "[Class 2] Prec: 0.9121 | Rec: 0.8917 | F1: 0.9018 | GM: 0.9140\n",
      "[Class 3] Prec: 0.8824 | Rec: 0.9215 | F1: 0.9015 | GM: 0.9511\n",
      "[Class 4] Prec: 0.8101 | Rec: 0.8466 | F1: 0.8279 | GM: 0.8987\n",
      "\n",
      "===== Fold 4 =====\n",
      "[INFO] Total parameters BEFORE pruning: 284,105\n",
      "[INFO] Non-zero parameters AFTER pruning: 142,775\n",
      "[INFO] Pruned parameters: 141,330 (49.75%)\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5985 | Train Acc: 0.7709 | Val Loss: 0.6063 | Val Acc: 0.7814\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4827 | Train Acc: 0.8194 | Val Loss: 0.4723 | Val Acc: 0.8194\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4625 | Train Acc: 0.8271 | Val Loss: 0.8383 | Val Acc: 0.7311\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4402 | Train Acc: 0.8371 | Val Loss: 0.4216 | Val Acc: 0.8434\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4342 | Train Acc: 0.8384 | Val Loss: 0.5059 | Val Acc: 0.8121\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4296 | Train Acc: 0.8412 | Val Loss: 0.4731 | Val Acc: 0.8381\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.4203 | Train Acc: 0.8428 | Val Loss: 0.3904 | Val Acc: 0.8542\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.4133 | Train Acc: 0.8453 | Val Loss: 0.4204 | Val Acc: 0.8454\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.4074 | Train Acc: 0.8485 | Val Loss: 0.4562 | Val Acc: 0.8303\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.4055 | Train Acc: 0.8493 | Val Loss: 0.4123 | Val Acc: 0.8408\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.4020 | Train Acc: 0.8498 | Val Loss: 0.4590 | Val Acc: 0.8345\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3940 | Train Acc: 0.8549 | Val Loss: 0.4518 | Val Acc: 0.8365\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3903 | Train Acc: 0.8534 | Val Loss: 0.4155 | Val Acc: 0.8441\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3860 | Train Acc: 0.8550 | Val Loss: 0.4451 | Val Acc: 0.8404\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3812 | Train Acc: 0.8575 | Val Loss: 0.4626 | Val Acc: 0.8375\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3776 | Train Acc: 0.8592 | Val Loss: 0.4520 | Val Acc: 0.8321\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3770 | Train Acc: 0.8591 | Val Loss: 0.4065 | Val Acc: 0.8519\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3682 | Train Acc: 0.8610 | Val Loss: 0.4552 | Val Acc: 0.8435\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3673 | Train Acc: 0.8651 | Val Loss: 0.3922 | Val Acc: 0.8648\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3605 | Train Acc: 0.8647 | Val Loss: 0.4035 | Val Acc: 0.8534\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3552 | Train Acc: 0.8649 | Val Loss: 0.4217 | Val Acc: 0.8474\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.3499 | Train Acc: 0.8698 | Val Loss: 0.4468 | Val Acc: 0.8491\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.3463 | Train Acc: 0.8701 | Val Loss: 0.3757 | Val Acc: 0.8603\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.3424 | Train Acc: 0.8694 | Val Loss: 0.4168 | Val Acc: 0.8521\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.3368 | Train Acc: 0.8743 | Val Loss: 0.4554 | Val Acc: 0.8368\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.3290 | Train Acc: 0.8754 | Val Loss: 0.4035 | Val Acc: 0.8511\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.3230 | Train Acc: 0.8784 | Val Loss: 0.3982 | Val Acc: 0.8543\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.3174 | Train Acc: 0.8800 | Val Loss: 0.3948 | Val Acc: 0.8560\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.3183 | Train Acc: 0.8806 | Val Loss: 0.4311 | Val Acc: 0.8497\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.3090 | Train Acc: 0.8831 | Val Loss: 0.4715 | Val Acc: 0.8445\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.3022 | Train Acc: 0.8862 | Val Loss: 0.4184 | Val Acc: 0.8443\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.2923 | Train Acc: 0.8887 | Val Loss: 0.3985 | Val Acc: 0.8599\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.2892 | Train Acc: 0.8908 | Val Loss: 0.4627 | Val Acc: 0.8497\n",
      "[Fold 4 | Epoch 34] Train Loss: 0.2839 | Train Acc: 0.8925 | Val Loss: 0.4218 | Val Acc: 0.8501\n",
      "[Fold 4 | Epoch 35] Train Loss: 0.2729 | Train Acc: 0.8970 | Val Loss: 0.4614 | Val Acc: 0.8453\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 19\n",
      "ACC: 0.8648 | MF1: 0.8203 | G-Mean: 0.8803\n",
      "[Class 0] Prec: 0.9338 | Rec: 0.8934 | F1: 0.9131 | GM: 0.9383\n",
      "[Class 1] Prec: 0.5833 | Rec: 0.5353 | F1: 0.5583 | GM: 0.7205\n",
      "[Class 2] Prec: 0.8777 | Rec: 0.9205 | F1: 0.8986 | GM: 0.9130\n",
      "[Class 3] Prec: 0.9081 | Rec: 0.9071 | F1: 0.9076 | GM: 0.9459\n",
      "[Class 4] Prec: 0.8387 | Rec: 0.8099 | F1: 0.8241 | GM: 0.8836\n",
      "\n",
      "===== Fold 5 =====\n",
      "[INFO] Total parameters BEFORE pruning: 284,105\n",
      "[INFO] Non-zero parameters AFTER pruning: 142,775\n",
      "[INFO] Pruned parameters: 141,330 (49.75%)\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.5745 | Train Acc: 0.7846 | Val Loss: 0.5477 | Val Acc: 0.7886\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4851 | Train Acc: 0.8177 | Val Loss: 0.4387 | Val Acc: 0.8405\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4638 | Train Acc: 0.8266 | Val Loss: 0.4781 | Val Acc: 0.8240\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4512 | Train Acc: 0.8329 | Val Loss: 0.5030 | Val Acc: 0.8154\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4365 | Train Acc: 0.8357 | Val Loss: 0.4852 | Val Acc: 0.8326\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4304 | Train Acc: 0.8398 | Val Loss: 0.4366 | Val Acc: 0.8440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 7] Train Loss: 0.4270 | Train Acc: 0.8404 | Val Loss: 0.4091 | Val Acc: 0.8486\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.4222 | Train Acc: 0.8422 | Val Loss: 0.4249 | Val Acc: 0.8486\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.4154 | Train Acc: 0.8457 | Val Loss: 0.4232 | Val Acc: 0.8438\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.4045 | Train Acc: 0.8492 | Val Loss: 0.4058 | Val Acc: 0.8526\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.4002 | Train Acc: 0.8514 | Val Loss: 0.4076 | Val Acc: 0.8473\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3934 | Train Acc: 0.8537 | Val Loss: 0.4273 | Val Acc: 0.8378\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3924 | Train Acc: 0.8550 | Val Loss: 0.3923 | Val Acc: 0.8567\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3878 | Train Acc: 0.8557 | Val Loss: 0.3906 | Val Acc: 0.8567\n",
      "[Fold 5 | Epoch 15] Train Loss: 0.3875 | Train Acc: 0.8576 | Val Loss: 0.3925 | Val Acc: 0.8622\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3792 | Train Acc: 0.8577 | Val Loss: 0.4574 | Val Acc: 0.8305\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3721 | Train Acc: 0.8618 | Val Loss: 0.3977 | Val Acc: 0.8537\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3665 | Train Acc: 0.8654 | Val Loss: 0.4446 | Val Acc: 0.8450\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3608 | Train Acc: 0.8649 | Val Loss: 0.4175 | Val Acc: 0.8433\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3588 | Train Acc: 0.8668 | Val Loss: 0.4054 | Val Acc: 0.8536\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.3526 | Train Acc: 0.8674 | Val Loss: 0.4406 | Val Acc: 0.8447\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.3449 | Train Acc: 0.8708 | Val Loss: 0.4206 | Val Acc: 0.8506\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.3404 | Train Acc: 0.8714 | Val Loss: 0.4000 | Val Acc: 0.8514\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.3361 | Train Acc: 0.8729 | Val Loss: 0.3984 | Val Acc: 0.8554\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.3268 | Train Acc: 0.8796 | Val Loss: 0.4426 | Val Acc: 0.8364\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.3245 | Train Acc: 0.8772 | Val Loss: 0.4039 | Val Acc: 0.8652\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.3134 | Train Acc: 0.8834 | Val Loss: 0.4373 | Val Acc: 0.8412\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.3152 | Train Acc: 0.8813 | Val Loss: 0.4272 | Val Acc: 0.8523\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.3021 | Train Acc: 0.8859 | Val Loss: 0.4445 | Val Acc: 0.8567\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.3011 | Train Acc: 0.8862 | Val Loss: 0.4483 | Val Acc: 0.8346\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.2925 | Train Acc: 0.8901 | Val Loss: 0.4220 | Val Acc: 0.8546\n",
      "[Fold 5 | Epoch 32] Train Loss: 0.2854 | Train Acc: 0.8935 | Val Loss: 0.4318 | Val Acc: 0.8467\n",
      "[Fold 5 | Epoch 33] Train Loss: 0.2761 | Train Acc: 0.8972 | Val Loss: 0.5144 | Val Acc: 0.8397\n",
      "[Fold 5 | Epoch 34] Train Loss: 0.2694 | Train Acc: 0.8992 | Val Loss: 0.4291 | Val Acc: 0.8540\n",
      "[Fold 5 | Epoch 35] Train Loss: 0.2669 | Train Acc: 0.8993 | Val Loss: 0.4525 | Val Acc: 0.8546\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 26\n",
      "ACC: 0.8652 | MF1: 0.8240 | G-Mean: 0.8897\n",
      "[Class 0] Prec: 0.9290 | Rec: 0.9003 | F1: 0.9144 | GM: 0.9414\n",
      "[Class 1] Prec: 0.5610 | Rec: 0.5863 | F1: 0.5733 | GM: 0.7517\n",
      "[Class 2] Prec: 0.9081 | Rec: 0.8961 | F1: 0.9021 | GM: 0.9145\n",
      "[Class 3] Prec: 0.9080 | Rec: 0.9060 | F1: 0.9070 | GM: 0.9453\n",
      "[Class 4] Prec: 0.8056 | Rec: 0.8412 | F1: 0.8230 | GM: 0.8954\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8634 | MF1: 0.8179 | G-Mean: 0.8817\n",
      "[Class 0] Prec: 0.9149 | Rec: 0.9037 | F1: 0.9093 | GM: 0.9415\n",
      "[Class 1] Prec: 0.6032 | Rec: 0.5133 | F1: 0.5547 | GM: 0.7069\n",
      "[Class 2] Prec: 0.9032 | Rec: 0.8948 | F1: 0.8990 | GM: 0.9119\n",
      "[Class 3] Prec: 0.8929 | Rec: 0.9135 | F1: 0.9031 | GM: 0.9479\n",
      "[Class 4] Prec: 0.7945 | Rec: 0.8544 | F1: 0.8234 | GM: 0.9004\n",
      "Confusion Matrix:\n",
      "[[ 5847   297   160    22   144]\n",
      " [  320  1309   371     4   546]\n",
      " [  103   229 13220   469   754]\n",
      " [    6     0   382  4129     3]\n",
      " [  115   335   504     0  5596]]\n"
     ]
    }
   ],
   "source": [
    "#p12\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ==== Load and Normalize Data ====\n",
    "\n",
    "df = pd.read_csv(\"pruned_dataset3.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "     # === Build and Prune Model ===\n",
    "    model_unpruned = FinalNetwork(C=12, num_classes=num_classes, layers=11, genotype=searched_genotype).to(device)\n",
    "    total_params_before = sum(p.numel() for p in model_unpruned.parameters())\n",
    "    print(f\"[INFO] Total parameters BEFORE pruning: {total_params_before:,}\")\n",
    "\n",
    "    model = prune_model_entropy(model_unpruned, prune_ratio=0.5)\n",
    "    nonzero_params_after = sum((p != 0).sum().item() for p in model.parameters())\n",
    "    zero_params = total_params_before - nonzero_params_after\n",
    "    pruned_ratio = 100 * zero_params / total_params_before\n",
    "    print(f\"[INFO] Non-zero parameters AFTER pruning: {nonzero_params_after:,}\")\n",
    "    print(f\"[INFO] Pruned parameters: {zero_params:,} ({pruned_ratio:.2f}%)\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    " \n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "\n",
    "    for epoch in range(35):  # You can change this to 50 or more\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fca70344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5637 | Train Acc: 0.7891 | Val Loss: 0.4642 | Val Acc: 0.8192\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4796 | Train Acc: 0.8227 | Val Loss: 0.7066 | Val Acc: 0.7196\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4565 | Train Acc: 0.8306 | Val Loss: 0.4299 | Val Acc: 0.8392\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4389 | Train Acc: 0.8367 | Val Loss: 0.3936 | Val Acc: 0.8473\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4228 | Train Acc: 0.8439 | Val Loss: 0.5453 | Val Acc: 0.8009\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4189 | Train Acc: 0.8466 | Val Loss: 0.3930 | Val Acc: 0.8516\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.4187 | Train Acc: 0.8452 | Val Loss: 0.4700 | Val Acc: 0.8156\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.4021 | Train Acc: 0.8517 | Val Loss: 0.3910 | Val Acc: 0.8547\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.3989 | Train Acc: 0.8530 | Val Loss: 0.4041 | Val Acc: 0.8488\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.3946 | Train Acc: 0.8536 | Val Loss: 0.3774 | Val Acc: 0.8585\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3895 | Train Acc: 0.8547 | Val Loss: 0.4222 | Val Acc: 0.8371\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3824 | Train Acc: 0.8559 | Val Loss: 0.4070 | Val Acc: 0.8493\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3790 | Train Acc: 0.8595 | Val Loss: 0.3628 | Val Acc: 0.8632\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3731 | Train Acc: 0.8617 | Val Loss: 0.3823 | Val Acc: 0.8550\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3659 | Train Acc: 0.8625 | Val Loss: 0.4533 | Val Acc: 0.8342\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3595 | Train Acc: 0.8674 | Val Loss: 0.4059 | Val Acc: 0.8473\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3587 | Train Acc: 0.8684 | Val Loss: 0.4436 | Val Acc: 0.8414\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3461 | Train Acc: 0.8706 | Val Loss: 0.4283 | Val Acc: 0.8478\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3410 | Train Acc: 0.8719 | Val Loss: 0.3542 | Val Acc: 0.8653\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3355 | Train Acc: 0.8756 | Val Loss: 0.4792 | Val Acc: 0.8240\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3277 | Train Acc: 0.8791 | Val Loss: 0.4741 | Val Acc: 0.8348\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.3283 | Train Acc: 0.8777 | Val Loss: 0.3589 | Val Acc: 0.8678\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.3065 | Train Acc: 0.8866 | Val Loss: 0.3874 | Val Acc: 0.8506\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.3050 | Train Acc: 0.8865 | Val Loss: 0.3905 | Val Acc: 0.8572\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.3007 | Train Acc: 0.8872 | Val Loss: 0.4236 | Val Acc: 0.8478\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.2949 | Train Acc: 0.8889 | Val Loss: 0.3843 | Val Acc: 0.8534\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.2849 | Train Acc: 0.8930 | Val Loss: 0.4083 | Val Acc: 0.8546\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.2774 | Train Acc: 0.8964 | Val Loss: 0.3726 | Val Acc: 0.8623\n",
      "[Fold 1 | Epoch 29] Train Loss: 0.2639 | Train Acc: 0.9008 | Val Loss: 0.4164 | Val Acc: 0.8569\n",
      "[Fold 1 | Epoch 30] Train Loss: 0.2601 | Train Acc: 0.8996 | Val Loss: 0.3770 | Val Acc: 0.8662\n",
      "[Fold 1 | Epoch 31] Train Loss: 0.2506 | Train Acc: 0.9066 | Val Loss: 0.4090 | Val Acc: 0.8653\n",
      "[Fold 1 | Epoch 32] Train Loss: 0.2512 | Train Acc: 0.9055 | Val Loss: 0.4368 | Val Acc: 0.8517\n",
      "[Fold 1 | Epoch 33] Train Loss: 0.2320 | Train Acc: 0.9136 | Val Loss: 0.4168 | Val Acc: 0.8587\n",
      "[Fold 1 | Epoch 34] Train Loss: 0.2285 | Train Acc: 0.9131 | Val Loss: 0.4081 | Val Acc: 0.8597\n",
      "[Fold 1 | Epoch 35] Train Loss: 0.2146 | Train Acc: 0.9198 | Val Loss: 0.4746 | Val Acc: 0.8523\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 22\n",
      "ACC: 0.8678 | MF1: 0.8188 | G-Mean: 0.8826\n",
      "[Class 0] Prec: 0.8967 | Rec: 0.9333 | F1: 0.9146 | GM: 0.9544\n",
      "[Class 1] Prec: 0.6276 | Rec: 0.4859 | F1: 0.5477 | GM: 0.6893\n",
      "[Class 2] Prec: 0.9198 | Rec: 0.8865 | F1: 0.9028 | GM: 0.9140\n",
      "[Class 3] Prec: 0.8803 | Rec: 0.9025 | F1: 0.8913 | GM: 0.9416\n",
      "[Class 4] Prec: 0.7967 | Rec: 0.8826 | F1: 0.8374 | GM: 0.9136\n",
      "\n",
      "===== Fold 2 =====\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5802 | Train Acc: 0.7795 | Val Loss: 0.5397 | Val Acc: 0.8070\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4745 | Train Acc: 0.8251 | Val Loss: 0.4660 | Val Acc: 0.8245\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4502 | Train Acc: 0.8303 | Val Loss: 0.4324 | Val Acc: 0.8458\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4386 | Train Acc: 0.8362 | Val Loss: 0.4386 | Val Acc: 0.8352\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4236 | Train Acc: 0.8425 | Val Loss: 0.4372 | Val Acc: 0.8415\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4130 | Train Acc: 0.8485 | Val Loss: 0.4141 | Val Acc: 0.8519\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4097 | Train Acc: 0.8482 | Val Loss: 0.4937 | Val Acc: 0.8151\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.4001 | Train Acc: 0.8518 | Val Loss: 0.4500 | Val Acc: 0.8266\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.3954 | Train Acc: 0.8537 | Val Loss: 0.4003 | Val Acc: 0.8542\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.3899 | Train Acc: 0.8543 | Val Loss: 0.3892 | Val Acc: 0.8556\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3854 | Train Acc: 0.8564 | Val Loss: 0.3989 | Val Acc: 0.8550\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3745 | Train Acc: 0.8613 | Val Loss: 0.4054 | Val Acc: 0.8509\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3726 | Train Acc: 0.8621 | Val Loss: 0.3947 | Val Acc: 0.8536\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3657 | Train Acc: 0.8636 | Val Loss: 0.3718 | Val Acc: 0.8616\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3662 | Train Acc: 0.8605 | Val Loss: 0.4140 | Val Acc: 0.8501\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3614 | Train Acc: 0.8657 | Val Loss: 0.3681 | Val Acc: 0.8751\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3515 | Train Acc: 0.8700 | Val Loss: 0.4000 | Val Acc: 0.8504\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3421 | Train Acc: 0.8725 | Val Loss: 0.4575 | Val Acc: 0.8517\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3426 | Train Acc: 0.8726 | Val Loss: 0.3853 | Val Acc: 0.8622\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3336 | Train Acc: 0.8743 | Val Loss: 0.3684 | Val Acc: 0.8669\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3234 | Train Acc: 0.8778 | Val Loss: 0.3911 | Val Acc: 0.8572\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.3212 | Train Acc: 0.8804 | Val Loss: 0.3934 | Val Acc: 0.8620\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.3119 | Train Acc: 0.8826 | Val Loss: 0.3893 | Val Acc: 0.8629\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.3070 | Train Acc: 0.8842 | Val Loss: 0.4686 | Val Acc: 0.8451\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.2997 | Train Acc: 0.8870 | Val Loss: 0.4210 | Val Acc: 0.8569\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.2901 | Train Acc: 0.8906 | Val Loss: 0.4524 | Val Acc: 0.8362\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.2854 | Train Acc: 0.8925 | Val Loss: 0.4536 | Val Acc: 0.8613\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.2759 | Train Acc: 0.8981 | Val Loss: 0.4288 | Val Acc: 0.8448\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.2660 | Train Acc: 0.9003 | Val Loss: 0.4508 | Val Acc: 0.8595\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.2561 | Train Acc: 0.9039 | Val Loss: 0.4343 | Val Acc: 0.8526\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.2548 | Train Acc: 0.9028 | Val Loss: 0.4318 | Val Acc: 0.8575\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.2443 | Train Acc: 0.9071 | Val Loss: 0.4455 | Val Acc: 0.8474\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.2307 | Train Acc: 0.9141 | Val Loss: 0.4125 | Val Acc: 0.8652\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.2286 | Train Acc: 0.9137 | Val Loss: 0.4342 | Val Acc: 0.8573\n",
      "[Fold 2 | Epoch 35] Train Loss: 0.2225 | Train Acc: 0.9178 | Val Loss: 0.4888 | Val Acc: 0.8521\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 16\n",
      "ACC: 0.8751 | MF1: 0.8280 | G-Mean: 0.8833\n",
      "[Class 0] Prec: 0.9547 | Rec: 0.9111 | F1: 0.9324 | GM: 0.9500\n",
      "[Class 1] Prec: 0.6256 | Rec: 0.4971 | F1: 0.5540 | GM: 0.6965\n",
      "[Class 2] Prec: 0.8922 | Rec: 0.9248 | F1: 0.9082 | GM: 0.9194\n",
      "[Class 3] Prec: 0.9123 | Rec: 0.9071 | F1: 0.9097 | GM: 0.9465\n",
      "[Class 4] Prec: 0.8178 | Rec: 0.8544 | F1: 0.8357 | GM: 0.9040\n",
      "\n",
      "===== Fold 3 =====\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5910 | Train Acc: 0.7787 | Val Loss: 0.5812 | Val Acc: 0.7929\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4956 | Train Acc: 0.8166 | Val Loss: 0.5492 | Val Acc: 0.8031\n",
      "[Fold 3 | Epoch 3] Train Loss: 0.4597 | Train Acc: 0.8304 | Val Loss: 0.4628 | Val Acc: 0.8302\n",
      "[Fold 3 | Epoch 4] Train Loss: 0.4483 | Train Acc: 0.8346 | Val Loss: 0.5214 | Val Acc: 0.8106\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4332 | Train Acc: 0.8393 | Val Loss: 0.4545 | Val Acc: 0.8318\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4209 | Train Acc: 0.8439 | Val Loss: 0.4259 | Val Acc: 0.8433\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4093 | Train Acc: 0.8472 | Val Loss: 0.4335 | Val Acc: 0.8407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3 | Epoch 8] Train Loss: 0.4114 | Train Acc: 0.8470 | Val Loss: 0.5470 | Val Acc: 0.8080\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.3953 | Train Acc: 0.8536 | Val Loss: 0.4669 | Val Acc: 0.8276\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.3958 | Train Acc: 0.8534 | Val Loss: 0.4137 | Val Acc: 0.8564\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3883 | Train Acc: 0.8591 | Val Loss: 0.4230 | Val Acc: 0.8445\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3755 | Train Acc: 0.8608 | Val Loss: 0.4375 | Val Acc: 0.8425\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3763 | Train Acc: 0.8599 | Val Loss: 0.3824 | Val Acc: 0.8638\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3735 | Train Acc: 0.8610 | Val Loss: 0.4272 | Val Acc: 0.8407\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3626 | Train Acc: 0.8654 | Val Loss: 0.3995 | Val Acc: 0.8560\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3616 | Train Acc: 0.8658 | Val Loss: 0.4314 | Val Acc: 0.8490\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3566 | Train Acc: 0.8673 | Val Loss: 0.4115 | Val Acc: 0.8510\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3479 | Train Acc: 0.8704 | Val Loss: 0.4249 | Val Acc: 0.8493\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3425 | Train Acc: 0.8718 | Val Loss: 0.3925 | Val Acc: 0.8595\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.3289 | Train Acc: 0.8770 | Val Loss: 0.4080 | Val Acc: 0.8613\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.3326 | Train Acc: 0.8740 | Val Loss: 0.4213 | Val Acc: 0.8539\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.3225 | Train Acc: 0.8793 | Val Loss: 0.3995 | Val Acc: 0.8552\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.3148 | Train Acc: 0.8830 | Val Loss: 0.4057 | Val Acc: 0.8566\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.3095 | Train Acc: 0.8846 | Val Loss: 0.4717 | Val Acc: 0.8438\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.2965 | Train Acc: 0.8861 | Val Loss: 0.4221 | Val Acc: 0.8520\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.2898 | Train Acc: 0.8924 | Val Loss: 0.4009 | Val Acc: 0.8676\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.2840 | Train Acc: 0.8918 | Val Loss: 0.4091 | Val Acc: 0.8649\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.2737 | Train Acc: 0.8988 | Val Loss: 0.4214 | Val Acc: 0.8536\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.2680 | Train Acc: 0.9000 | Val Loss: 0.4922 | Val Acc: 0.8316\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.2605 | Train Acc: 0.9024 | Val Loss: 0.4741 | Val Acc: 0.8509\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.2571 | Train Acc: 0.9024 | Val Loss: 0.4466 | Val Acc: 0.8579\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.2416 | Train Acc: 0.9087 | Val Loss: 0.4266 | Val Acc: 0.8656\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.2325 | Train Acc: 0.9112 | Val Loss: 0.4880 | Val Acc: 0.8402\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.2225 | Train Acc: 0.9161 | Val Loss: 0.4440 | Val Acc: 0.8639\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.2220 | Train Acc: 0.9143 | Val Loss: 0.4725 | Val Acc: 0.8586\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 26\n",
      "ACC: 0.8676 | MF1: 0.8237 | G-Mean: 0.8856\n",
      "[Class 0] Prec: 0.9271 | Rec: 0.9134 | F1: 0.9202 | GM: 0.9485\n",
      "[Class 1] Prec: 0.5995 | Rec: 0.5279 | F1: 0.5614 | GM: 0.7166\n",
      "[Class 2] Prec: 0.9091 | Rec: 0.8913 | F1: 0.9001 | GM: 0.9116\n",
      "[Class 3] Prec: 0.9068 | Rec: 0.8894 | F1: 0.8980 | GM: 0.9368\n",
      "[Class 4] Prec: 0.7961 | Rec: 0.8858 | F1: 0.8385 | GM: 0.9148\n",
      "\n",
      "===== Fold 4 =====\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5612 | Train Acc: 0.7888 | Val Loss: 0.4981 | Val Acc: 0.8219\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4741 | Train Acc: 0.8226 | Val Loss: 0.4340 | Val Acc: 0.8378\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4497 | Train Acc: 0.8328 | Val Loss: 0.4565 | Val Acc: 0.8346\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4321 | Train Acc: 0.8391 | Val Loss: 0.4230 | Val Acc: 0.8445\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4262 | Train Acc: 0.8411 | Val Loss: 0.4615 | Val Acc: 0.8364\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4141 | Train Acc: 0.8467 | Val Loss: 0.4101 | Val Acc: 0.8497\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.4125 | Train Acc: 0.8469 | Val Loss: 0.4245 | Val Acc: 0.8410\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.3989 | Train Acc: 0.8504 | Val Loss: 0.4483 | Val Acc: 0.8302\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.3992 | Train Acc: 0.8505 | Val Loss: 0.4515 | Val Acc: 0.8387\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.3912 | Train Acc: 0.8540 | Val Loss: 0.4120 | Val Acc: 0.8490\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.3824 | Train Acc: 0.8562 | Val Loss: 0.4010 | Val Acc: 0.8540\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3807 | Train Acc: 0.8564 | Val Loss: 0.3924 | Val Acc: 0.8586\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3712 | Train Acc: 0.8628 | Val Loss: 0.4684 | Val Acc: 0.8325\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3718 | Train Acc: 0.8617 | Val Loss: 0.4317 | Val Acc: 0.8400\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3606 | Train Acc: 0.8659 | Val Loss: 0.4315 | Val Acc: 0.8379\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3591 | Train Acc: 0.8651 | Val Loss: 0.3755 | Val Acc: 0.8629\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3495 | Train Acc: 0.8719 | Val Loss: 0.4444 | Val Acc: 0.8490\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3451 | Train Acc: 0.8722 | Val Loss: 0.4253 | Val Acc: 0.8516\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3364 | Train Acc: 0.8746 | Val Loss: 0.4373 | Val Acc: 0.8448\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3310 | Train Acc: 0.8771 | Val Loss: 0.4979 | Val Acc: 0.8216\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3243 | Train Acc: 0.8790 | Val Loss: 0.3920 | Val Acc: 0.8562\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.3196 | Train Acc: 0.8794 | Val Loss: 0.3885 | Val Acc: 0.8572\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.3076 | Train Acc: 0.8857 | Val Loss: 0.3957 | Val Acc: 0.8544\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.3013 | Train Acc: 0.8866 | Val Loss: 0.3921 | Val Acc: 0.8606\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.2931 | Train Acc: 0.8909 | Val Loss: 0.4269 | Val Acc: 0.8477\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.2915 | Train Acc: 0.8924 | Val Loss: 0.3921 | Val Acc: 0.8623\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.2816 | Train Acc: 0.8957 | Val Loss: 0.4620 | Val Acc: 0.8283\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.2710 | Train Acc: 0.9014 | Val Loss: 0.4378 | Val Acc: 0.8460\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.2643 | Train Acc: 0.9004 | Val Loss: 0.4323 | Val Acc: 0.8587\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.2537 | Train Acc: 0.9034 | Val Loss: 0.4227 | Val Acc: 0.8521\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.2499 | Train Acc: 0.9074 | Val Loss: 0.6092 | Val Acc: 0.8085\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.2423 | Train Acc: 0.9100 | Val Loss: 0.4235 | Val Acc: 0.8607\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.2289 | Train Acc: 0.9162 | Val Loss: 0.4547 | Val Acc: 0.8600\n",
      "[Fold 4 | Epoch 34] Train Loss: 0.2220 | Train Acc: 0.9174 | Val Loss: 0.4393 | Val Acc: 0.8572\n",
      "[Fold 4 | Epoch 35] Train Loss: 0.2158 | Train Acc: 0.9186 | Val Loss: 0.4622 | Val Acc: 0.8540\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 16\n",
      "ACC: 0.8629 | MF1: 0.8092 | G-Mean: 0.8677\n",
      "[Class 0] Prec: 0.9516 | Rec: 0.8717 | F1: 0.9099 | GM: 0.9288\n",
      "[Class 1] Prec: 0.5751 | Rec: 0.4684 | F1: 0.5163 | GM: 0.6757\n",
      "[Class 2] Prec: 0.8694 | Rec: 0.9262 | F1: 0.8969 | GM: 0.9114\n",
      "[Class 3] Prec: 0.9315 | Rec: 0.8411 | F1: 0.8840 | GM: 0.9129\n",
      "[Class 4] Prec: 0.8117 | Rec: 0.8684 | F1: 0.8391 | GM: 0.9098\n",
      "\n",
      "===== Fold 5 =====\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.5656 | Train Acc: 0.7888 | Val Loss: 0.5442 | Val Acc: 0.8091\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4717 | Train Acc: 0.8262 | Val Loss: 0.4448 | Val Acc: 0.8453\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4497 | Train Acc: 0.8321 | Val Loss: 0.5305 | Val Acc: 0.8196\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4450 | Train Acc: 0.8359 | Val Loss: 0.5003 | Val Acc: 0.8120\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4299 | Train Acc: 0.8412 | Val Loss: 0.4103 | Val Acc: 0.8466\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4206 | Train Acc: 0.8441 | Val Loss: 0.4283 | Val Acc: 0.8374\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.4160 | Train Acc: 0.8449 | Val Loss: 0.5479 | Val Acc: 0.8110\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.4076 | Train Acc: 0.8481 | Val Loss: 0.4902 | Val Acc: 0.8288\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.4039 | Train Acc: 0.8502 | Val Loss: 0.4074 | Val Acc: 0.8543\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.3980 | Train Acc: 0.8530 | Val Loss: 0.4204 | Val Acc: 0.8375\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.3892 | Train Acc: 0.8566 | Val Loss: 0.5308 | Val Acc: 0.8131\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3882 | Train Acc: 0.8539 | Val Loss: 0.3876 | Val Acc: 0.8610\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3768 | Train Acc: 0.8611 | Val Loss: 0.3861 | Val Acc: 0.8620\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3730 | Train Acc: 0.8630 | Val Loss: 0.4535 | Val Acc: 0.8410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 15] Train Loss: 0.3703 | Train Acc: 0.8642 | Val Loss: 0.4335 | Val Acc: 0.8412\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3618 | Train Acc: 0.8674 | Val Loss: 0.4126 | Val Acc: 0.8477\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3606 | Train Acc: 0.8668 | Val Loss: 0.3988 | Val Acc: 0.8503\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3500 | Train Acc: 0.8702 | Val Loss: 0.3938 | Val Acc: 0.8562\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3496 | Train Acc: 0.8704 | Val Loss: 0.3749 | Val Acc: 0.8649\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3424 | Train Acc: 0.8720 | Val Loss: 0.5389 | Val Acc: 0.8283\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.3338 | Train Acc: 0.8765 | Val Loss: 0.4695 | Val Acc: 0.8402\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.3302 | Train Acc: 0.8781 | Val Loss: 0.4457 | Val Acc: 0.8531\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.3208 | Train Acc: 0.8803 | Val Loss: 0.4233 | Val Acc: 0.8570\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.3140 | Train Acc: 0.8835 | Val Loss: 0.4546 | Val Acc: 0.8496\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.3058 | Train Acc: 0.8858 | Val Loss: 0.4440 | Val Acc: 0.8371\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.3063 | Train Acc: 0.8870 | Val Loss: 0.4056 | Val Acc: 0.8622\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.2971 | Train Acc: 0.8893 | Val Loss: 0.4579 | Val Acc: 0.8500\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.2859 | Train Acc: 0.8951 | Val Loss: 0.3982 | Val Acc: 0.8655\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.2775 | Train Acc: 0.8972 | Val Loss: 0.4204 | Val Acc: 0.8597\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.2723 | Train Acc: 0.8986 | Val Loss: 0.4037 | Val Acc: 0.8626\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.2663 | Train Acc: 0.9019 | Val Loss: 0.4637 | Val Acc: 0.8527\n",
      "[Fold 5 | Epoch 32] Train Loss: 0.2620 | Train Acc: 0.9021 | Val Loss: 0.4105 | Val Acc: 0.8636\n",
      "[Fold 5 | Epoch 33] Train Loss: 0.2483 | Train Acc: 0.9055 | Val Loss: 0.4326 | Val Acc: 0.8570\n",
      "[Fold 5 | Epoch 34] Train Loss: 0.2481 | Train Acc: 0.9073 | Val Loss: 0.4053 | Val Acc: 0.8639\n",
      "[Fold 5 | Epoch 35] Train Loss: 0.2367 | Train Acc: 0.9116 | Val Loss: 0.4961 | Val Acc: 0.8346\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 28\n",
      "ACC: 0.8655 | MF1: 0.8272 | G-Mean: 0.8866\n",
      "[Class 0] Prec: 0.9631 | Rec: 0.8679 | F1: 0.9130 | GM: 0.9281\n",
      "[Class 1] Prec: 0.5610 | Rec: 0.6314 | F1: 0.5941 | GM: 0.7789\n",
      "[Class 2] Prec: 0.8734 | Rec: 0.9289 | F1: 0.9003 | GM: 0.9148\n",
      "[Class 3] Prec: 0.9376 | Rec: 0.8650 | F1: 0.8999 | GM: 0.9261\n",
      "[Class 4] Prec: 0.8463 | Rec: 0.8115 | F1: 0.8285 | GM: 0.8853\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8678 | MF1: 0.8218 | G-Mean: 0.8816\n",
      "[Class 0] Prec: 0.9376 | Rec: 0.8990 | F1: 0.9179 | GM: 0.9418\n",
      "[Class 1] Prec: 0.5950 | Rec: 0.5230 | F1: 0.5567 | GM: 0.7131\n",
      "[Class 2] Prec: 0.8921 | Rec: 0.9115 | F1: 0.9017 | GM: 0.9144\n",
      "[Class 3] Prec: 0.9131 | Rec: 0.8806 | F1: 0.8966 | GM: 0.9327\n",
      "[Class 4] Prec: 0.8125 | Rec: 0.8609 | F1: 0.8360 | GM: 0.9059\n",
      "Confusion Matrix:\n",
      "[[ 5698   382   121    21   116]\n",
      " [  207  1309   472     4   511]\n",
      " [   91   192 13619   347   692]\n",
      " [    7     0   522  3910     1]\n",
      " [   74   317   533     0  5719]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# ==== Load and Normalize Data ====\n",
    "\n",
    "df = pd.read_csv(\"pruned_dataset3.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "# Z-score normalization\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== Evaluation Metric Function ====\n",
    "def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    gmeans = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        tn = np.sum((y_pred != c) & (y_true != c))\n",
    "        fp = np.sum((y_pred == c) & (y_true != c))\n",
    "        gm = np.sqrt((tp / (tp + fn + 1e-6)) * (tn / (tn + fp + 1e-6)))\n",
    "        gmeans.append(gm)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, mf1, np.mean(gmeans), prec, rec, f1s, gmeans, cm\n",
    "\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "    X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "    X_val, y_val = X_all[val_idx], y_all[val_idx]\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "\n",
    "    model = FinalNetwork(C=9, num_classes=num_classes, layers=11, genotype=searched_genotype).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "\n",
    "    for epoch in range(35):  # You can change this to 50 or more\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b000718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[INFO] Total parameters BEFORE pruning: 165,479\n",
      "[INFO] Non-zero parameters AFTER pruning: 82,892\n",
      "[INFO] Pruned parameters: 82,587 (49.91%)\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.6316 | Train Acc: 0.7598 | Val Loss: 1.2181 | Val Acc: 0.5825\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4956 | Train Acc: 0.8141 | Val Loss: 0.4850 | Val Acc: 0.8260\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4676 | Train Acc: 0.8267 | Val Loss: 0.6291 | Val Acc: 0.7697\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4580 | Train Acc: 0.8300 | Val Loss: 0.4531 | Val Acc: 0.8346\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4461 | Train Acc: 0.8345 | Val Loss: 0.4359 | Val Acc: 0.8438\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4334 | Train Acc: 0.8384 | Val Loss: 0.4590 | Val Acc: 0.8299\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.4255 | Train Acc: 0.8424 | Val Loss: 0.4032 | Val Acc: 0.8537\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.4210 | Train Acc: 0.8439 | Val Loss: 0.4401 | Val Acc: 0.8326\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.4128 | Train Acc: 0.8467 | Val Loss: 0.4214 | Val Acc: 0.8473\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.4101 | Train Acc: 0.8501 | Val Loss: 0.4224 | Val Acc: 0.8445\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.4058 | Train Acc: 0.8489 | Val Loss: 0.4420 | Val Acc: 0.8400\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.4006 | Train Acc: 0.8519 | Val Loss: 0.3875 | Val Acc: 0.8646\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3950 | Train Acc: 0.8525 | Val Loss: 0.4664 | Val Acc: 0.8305\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3898 | Train Acc: 0.8551 | Val Loss: 0.4591 | Val Acc: 0.8375\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3869 | Train Acc: 0.8563 | Val Loss: 0.4092 | Val Acc: 0.8529\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3839 | Train Acc: 0.8576 | Val Loss: 0.4657 | Val Acc: 0.8308\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3835 | Train Acc: 0.8576 | Val Loss: 0.4050 | Val Acc: 0.8547\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3824 | Train Acc: 0.8584 | Val Loss: 0.3878 | Val Acc: 0.8618\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3737 | Train Acc: 0.8594 | Val Loss: 0.4049 | Val Acc: 0.8480\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3719 | Train Acc: 0.8609 | Val Loss: 0.4093 | Val Acc: 0.8460\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3659 | Train Acc: 0.8618 | Val Loss: 0.3902 | Val Acc: 0.8542\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.3658 | Train Acc: 0.8635 | Val Loss: 0.4270 | Val Acc: 0.8447\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.3580 | Train Acc: 0.8658 | Val Loss: 0.4234 | Val Acc: 0.8493\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.3541 | Train Acc: 0.8691 | Val Loss: 0.4049 | Val Acc: 0.8547\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.3449 | Train Acc: 0.8724 | Val Loss: 0.4174 | Val Acc: 0.8546\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.3472 | Train Acc: 0.8711 | Val Loss: 0.4022 | Val Acc: 0.8603\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.3388 | Train Acc: 0.8738 | Val Loss: 0.4150 | Val Acc: 0.8526\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.3411 | Train Acc: 0.8724 | Val Loss: 0.4300 | Val Acc: 0.8421\n",
      "[Fold 1 | Epoch 29] Train Loss: 0.3336 | Train Acc: 0.8757 | Val Loss: 0.4659 | Val Acc: 0.8325\n",
      "[Fold 1 | Epoch 30] Train Loss: 0.3292 | Train Acc: 0.8761 | Val Loss: 0.4075 | Val Acc: 0.8488\n",
      "[Fold 1 | Epoch 31] Train Loss: 0.3252 | Train Acc: 0.8790 | Val Loss: 0.4306 | Val Acc: 0.8533\n",
      "[Fold 1 | Epoch 32] Train Loss: 0.3134 | Train Acc: 0.8849 | Val Loss: 0.4217 | Val Acc: 0.8466\n",
      "[Fold 1 | Epoch 33] Train Loss: 0.3134 | Train Acc: 0.8819 | Val Loss: 0.3976 | Val Acc: 0.8585\n",
      "[Fold 1 | Epoch 34] Train Loss: 0.3077 | Train Acc: 0.8847 | Val Loss: 0.4128 | Val Acc: 0.8587\n",
      "[Fold 1 | Epoch 35] Train Loss: 0.3066 | Train Acc: 0.8856 | Val Loss: 0.4016 | Val Acc: 0.8600\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 12\n",
      "ACC: 0.8646 | MF1: 0.8211 | G-Mean: 0.8861\n",
      "[Class 0] Prec: 0.9525 | Rec: 0.8825 | F1: 0.9162 | GM: 0.9347\n",
      "[Class 1] Prec: 0.5632 | Rec: 0.5588 | F1: 0.5610 | GM: 0.7347\n",
      "[Class 2] Prec: 0.9121 | Rec: 0.8992 | F1: 0.9056 | GM: 0.9175\n",
      "[Class 3] Prec: 0.9194 | Rec: 0.8960 | F1: 0.9076 | GM: 0.9410\n",
      "[Class 4] Prec: 0.7700 | Rec: 0.8664 | F1: 0.8154 | GM: 0.9025\n",
      "\n",
      "===== Fold 2 =====\n",
      "[INFO] Total parameters BEFORE pruning: 165,479\n",
      "[INFO] Non-zero parameters AFTER pruning: 82,892\n",
      "[INFO] Pruned parameters: 82,587 (49.91%)\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5894 | Train Acc: 0.7760 | Val Loss: 0.4971 | Val Acc: 0.8200\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4848 | Train Acc: 0.8192 | Val Loss: 0.5051 | Val Acc: 0.8143\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4698 | Train Acc: 0.8233 | Val Loss: 0.5200 | Val Acc: 0.8177\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4498 | Train Acc: 0.8336 | Val Loss: 0.5295 | Val Acc: 0.8088\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4345 | Train Acc: 0.8400 | Val Loss: 0.4632 | Val Acc: 0.8246\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4249 | Train Acc: 0.8436 | Val Loss: 0.4070 | Val Acc: 0.8507\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4234 | Train Acc: 0.8423 | Val Loss: 0.4077 | Val Acc: 0.8557\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.4195 | Train Acc: 0.8451 | Val Loss: 0.4175 | Val Acc: 0.8468\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.4083 | Train Acc: 0.8491 | Val Loss: 0.5659 | Val Acc: 0.8005\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.4051 | Train Acc: 0.8489 | Val Loss: 0.4112 | Val Acc: 0.8539\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.4027 | Train Acc: 0.8482 | Val Loss: 0.4290 | Val Acc: 0.8457\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3959 | Train Acc: 0.8526 | Val Loss: 0.4176 | Val Acc: 0.8509\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3938 | Train Acc: 0.8540 | Val Loss: 0.4126 | Val Acc: 0.8504\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3839 | Train Acc: 0.8560 | Val Loss: 0.3850 | Val Acc: 0.8645\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3864 | Train Acc: 0.8585 | Val Loss: 0.3871 | Val Acc: 0.8597\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3794 | Train Acc: 0.8599 | Val Loss: 0.4209 | Val Acc: 0.8496\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3754 | Train Acc: 0.8604 | Val Loss: 0.4092 | Val Acc: 0.8526\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3743 | Train Acc: 0.8617 | Val Loss: 0.3951 | Val Acc: 0.8592\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3696 | Train Acc: 0.8638 | Val Loss: 0.3889 | Val Acc: 0.8666\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3605 | Train Acc: 0.8661 | Val Loss: 0.4055 | Val Acc: 0.8582\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3598 | Train Acc: 0.8675 | Val Loss: 0.3963 | Val Acc: 0.8625\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.3548 | Train Acc: 0.8658 | Val Loss: 0.4076 | Val Acc: 0.8539\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.3494 | Train Acc: 0.8689 | Val Loss: 0.4220 | Val Acc: 0.8503\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.3471 | Train Acc: 0.8708 | Val Loss: 0.4265 | Val Acc: 0.8401\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.3418 | Train Acc: 0.8709 | Val Loss: 0.4969 | Val Acc: 0.8193\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.3297 | Train Acc: 0.8790 | Val Loss: 0.4057 | Val Acc: 0.8504\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.3272 | Train Acc: 0.8770 | Val Loss: 0.4126 | Val Acc: 0.8531\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.3222 | Train Acc: 0.8777 | Val Loss: 0.3948 | Val Acc: 0.8564\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.3193 | Train Acc: 0.8799 | Val Loss: 0.4178 | Val Acc: 0.8523\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.3142 | Train Acc: 0.8810 | Val Loss: 0.4462 | Val Acc: 0.8346\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.3079 | Train Acc: 0.8855 | Val Loss: 0.4055 | Val Acc: 0.8570\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.2999 | Train Acc: 0.8874 | Val Loss: 0.4036 | Val Acc: 0.8556\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.3032 | Train Acc: 0.8865 | Val Loss: 0.4163 | Val Acc: 0.8477\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.2907 | Train Acc: 0.8915 | Val Loss: 0.4617 | Val Acc: 0.8513\n",
      "[Fold 2 | Epoch 35] Train Loss: 0.2900 | Train Acc: 0.8898 | Val Loss: 0.4127 | Val Acc: 0.8587\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 19\n",
      "ACC: 0.8666 | MF1: 0.8189 | G-Mean: 0.8815\n",
      "[Class 0] Prec: 0.9222 | Rec: 0.9158 | F1: 0.9190 | GM: 0.9485\n",
      "[Class 1] Prec: 0.6072 | Rec: 0.4941 | F1: 0.5449 | GM: 0.6940\n",
      "[Class 2] Prec: 0.9179 | Rec: 0.8934 | F1: 0.9055 | GM: 0.9170\n",
      "[Class 3] Prec: 0.9269 | Rec: 0.8838 | F1: 0.9049 | GM: 0.9352\n",
      "[Class 4] Prec: 0.7603 | Rec: 0.8908 | F1: 0.8204 | GM: 0.9127\n",
      "\n",
      "===== Fold 3 =====\n",
      "[INFO] Total parameters BEFORE pruning: 165,479\n",
      "[INFO] Non-zero parameters AFTER pruning: 82,892\n",
      "[INFO] Pruned parameters: 82,587 (49.91%)\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5864 | Train Acc: 0.7788 | Val Loss: 0.5967 | Val Acc: 0.8001\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4839 | Train Acc: 0.8172 | Val Loss: 0.4598 | Val Acc: 0.8311\n",
      "[Fold 3 | Epoch 3] Train Loss: 0.4644 | Train Acc: 0.8272 | Val Loss: 0.5209 | Val Acc: 0.8182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3 | Epoch 4] Train Loss: 0.4430 | Train Acc: 0.8344 | Val Loss: 0.4847 | Val Acc: 0.8243\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4383 | Train Acc: 0.8382 | Val Loss: 0.4656 | Val Acc: 0.8341\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4254 | Train Acc: 0.8410 | Val Loss: 0.5389 | Val Acc: 0.8048\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4207 | Train Acc: 0.8438 | Val Loss: 0.4495 | Val Acc: 0.8309\n",
      "[Fold 3 | Epoch 8] Train Loss: 0.4090 | Train Acc: 0.8507 | Val Loss: 0.4077 | Val Acc: 0.8542\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.4051 | Train Acc: 0.8496 | Val Loss: 0.4385 | Val Acc: 0.8435\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.3974 | Train Acc: 0.8534 | Val Loss: 0.4049 | Val Acc: 0.8516\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3969 | Train Acc: 0.8553 | Val Loss: 0.4106 | Val Acc: 0.8466\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3879 | Train Acc: 0.8564 | Val Loss: 0.3847 | Val Acc: 0.8592\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3856 | Train Acc: 0.8562 | Val Loss: 0.4353 | Val Acc: 0.8486\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3795 | Train Acc: 0.8588 | Val Loss: 0.4526 | Val Acc: 0.8268\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3832 | Train Acc: 0.8568 | Val Loss: 0.4520 | Val Acc: 0.8309\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3708 | Train Acc: 0.8630 | Val Loss: 0.3878 | Val Acc: 0.8564\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3691 | Train Acc: 0.8624 | Val Loss: 0.3971 | Val Acc: 0.8586\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3651 | Train Acc: 0.8644 | Val Loss: 0.4380 | Val Acc: 0.8367\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3630 | Train Acc: 0.8652 | Val Loss: 0.4316 | Val Acc: 0.8454\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.3576 | Train Acc: 0.8673 | Val Loss: 0.4010 | Val Acc: 0.8506\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.3503 | Train Acc: 0.8685 | Val Loss: 0.4089 | Val Acc: 0.8544\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.3505 | Train Acc: 0.8691 | Val Loss: 0.4313 | Val Acc: 0.8484\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.3432 | Train Acc: 0.8730 | Val Loss: 0.3935 | Val Acc: 0.8613\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.3360 | Train Acc: 0.8744 | Val Loss: 0.5171 | Val Acc: 0.8311\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.3365 | Train Acc: 0.8742 | Val Loss: 0.4179 | Val Acc: 0.8461\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.3258 | Train Acc: 0.8769 | Val Loss: 0.3984 | Val Acc: 0.8536\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.3246 | Train Acc: 0.8789 | Val Loss: 0.4046 | Val Acc: 0.8577\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.3164 | Train Acc: 0.8814 | Val Loss: 0.4134 | Val Acc: 0.8497\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.3144 | Train Acc: 0.8820 | Val Loss: 0.4180 | Val Acc: 0.8480\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.3090 | Train Acc: 0.8858 | Val Loss: 0.4168 | Val Acc: 0.8523\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.3051 | Train Acc: 0.8866 | Val Loss: 0.4023 | Val Acc: 0.8592\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.2970 | Train Acc: 0.8859 | Val Loss: 0.3788 | Val Acc: 0.8636\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.2927 | Train Acc: 0.8909 | Val Loss: 0.4392 | Val Acc: 0.8550\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.2882 | Train Acc: 0.8922 | Val Loss: 0.5297 | Val Acc: 0.8172\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.2818 | Train Acc: 0.8936 | Val Loss: 0.4525 | Val Acc: 0.8493\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 32\n",
      "ACC: 0.8636 | MF1: 0.8156 | G-Mean: 0.8748\n",
      "[Class 0] Prec: 0.9349 | Rec: 0.8995 | F1: 0.9169 | GM: 0.9417\n",
      "[Class 1] Prec: 0.6713 | Rec: 0.4686 | F1: 0.5520 | GM: 0.6783\n",
      "[Class 2] Prec: 0.8993 | Rec: 0.9005 | F1: 0.8999 | GM: 0.9131\n",
      "[Class 3] Prec: 0.9089 | Rec: 0.8717 | F1: 0.8899 | GM: 0.9275\n",
      "[Class 4] Prec: 0.7568 | Rec: 0.8931 | F1: 0.8193 | GM: 0.9131\n",
      "\n",
      "===== Fold 4 =====\n",
      "[INFO] Total parameters BEFORE pruning: 165,479\n",
      "[INFO] Non-zero parameters AFTER pruning: 82,892\n",
      "[INFO] Pruned parameters: 82,587 (49.91%)\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.6162 | Train Acc: 0.7650 | Val Loss: 0.7006 | Val Acc: 0.7447\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.5030 | Train Acc: 0.8117 | Val Loss: 0.6274 | Val Acc: 0.7843\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4810 | Train Acc: 0.8208 | Val Loss: 0.4387 | Val Acc: 0.8362\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4569 | Train Acc: 0.8306 | Val Loss: 0.5500 | Val Acc: 0.7968\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4424 | Train Acc: 0.8359 | Val Loss: 0.4371 | Val Acc: 0.8319\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4324 | Train Acc: 0.8390 | Val Loss: 0.5359 | Val Acc: 0.8063\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.4233 | Train Acc: 0.8441 | Val Loss: 0.4396 | Val Acc: 0.8372\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.4169 | Train Acc: 0.8459 | Val Loss: 0.4827 | Val Acc: 0.8176\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.4173 | Train Acc: 0.8450 | Val Loss: 0.4823 | Val Acc: 0.8209\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.4072 | Train Acc: 0.8489 | Val Loss: 0.4269 | Val Acc: 0.8392\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.4053 | Train Acc: 0.8506 | Val Loss: 0.4307 | Val Acc: 0.8417\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3966 | Train Acc: 0.8528 | Val Loss: 0.4018 | Val Acc: 0.8582\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3914 | Train Acc: 0.8537 | Val Loss: 0.4321 | Val Acc: 0.8346\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3860 | Train Acc: 0.8580 | Val Loss: 0.4267 | Val Acc: 0.8497\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3854 | Train Acc: 0.8576 | Val Loss: 0.4190 | Val Acc: 0.8427\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3810 | Train Acc: 0.8594 | Val Loss: 0.3952 | Val Acc: 0.8546\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3737 | Train Acc: 0.8609 | Val Loss: 0.4300 | Val Acc: 0.8421\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3732 | Train Acc: 0.8605 | Val Loss: 0.4004 | Val Acc: 0.8497\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3657 | Train Acc: 0.8647 | Val Loss: 0.4238 | Val Acc: 0.8431\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3595 | Train Acc: 0.8657 | Val Loss: 0.3909 | Val Acc: 0.8550\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3562 | Train Acc: 0.8675 | Val Loss: 0.4091 | Val Acc: 0.8520\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.3502 | Train Acc: 0.8696 | Val Loss: 0.4139 | Val Acc: 0.8567\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.3526 | Train Acc: 0.8690 | Val Loss: 0.4122 | Val Acc: 0.8521\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.3451 | Train Acc: 0.8716 | Val Loss: 0.3831 | Val Acc: 0.8612\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.3375 | Train Acc: 0.8751 | Val Loss: 0.4446 | Val Acc: 0.8397\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.3326 | Train Acc: 0.8765 | Val Loss: 0.4039 | Val Acc: 0.8531\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.3281 | Train Acc: 0.8771 | Val Loss: 0.3833 | Val Acc: 0.8603\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.3208 | Train Acc: 0.8798 | Val Loss: 0.3948 | Val Acc: 0.8600\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.3143 | Train Acc: 0.8835 | Val Loss: 0.4013 | Val Acc: 0.8533\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.3151 | Train Acc: 0.8836 | Val Loss: 0.4230 | Val Acc: 0.8550\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.3024 | Train Acc: 0.8856 | Val Loss: 0.4141 | Val Acc: 0.8524\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.3014 | Train Acc: 0.8877 | Val Loss: 0.4728 | Val Acc: 0.8296\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.2924 | Train Acc: 0.8886 | Val Loss: 0.5183 | Val Acc: 0.8130\n",
      "[Fold 4 | Epoch 34] Train Loss: 0.2914 | Train Acc: 0.8906 | Val Loss: 0.4145 | Val Acc: 0.8553\n",
      "[Fold 4 | Epoch 35] Train Loss: 0.2812 | Train Acc: 0.8956 | Val Loss: 0.4255 | Val Acc: 0.8592\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 24\n",
      "ACC: 0.8612 | MF1: 0.8264 | G-Mean: 0.9011\n",
      "[Class 0] Prec: 0.9465 | Rec: 0.8887 | F1: 0.9167 | GM: 0.9373\n",
      "[Class 1] Prec: 0.5350 | Rec: 0.6902 | F1: 0.6027 | GM: 0.8109\n",
      "[Class 2] Prec: 0.9254 | Rec: 0.8684 | F1: 0.8959 | GM: 0.9075\n",
      "[Class 3] Prec: 0.8442 | Rec: 0.9469 | F1: 0.8926 | GM: 0.9603\n",
      "[Class 4] Prec: 0.8233 | Rec: 0.8252 | F1: 0.8242 | GM: 0.8896\n",
      "\n",
      "===== Fold 5 =====\n",
      "[INFO] Total parameters BEFORE pruning: 165,479\n",
      "[INFO] Non-zero parameters AFTER pruning: 82,892\n",
      "[INFO] Pruned parameters: 82,587 (49.91%)\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.6022 | Train Acc: 0.7724 | Val Loss: 0.5069 | Val Acc: 0.8121\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4980 | Train Acc: 0.8133 | Val Loss: 0.5166 | Val Acc: 0.8206\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4644 | Train Acc: 0.8283 | Val Loss: 0.4986 | Val Acc: 0.8321\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4451 | Train Acc: 0.8341 | Val Loss: 0.4110 | Val Acc: 0.8519\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4353 | Train Acc: 0.8369 | Val Loss: 0.6372 | Val Acc: 0.7860\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4321 | Train Acc: 0.8416 | Val Loss: 0.4039 | Val Acc: 0.8511\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.4212 | Train Acc: 0.8438 | Val Loss: 0.4559 | Val Acc: 0.8348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 8] Train Loss: 0.4112 | Train Acc: 0.8481 | Val Loss: 0.4333 | Val Acc: 0.8408\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.4124 | Train Acc: 0.8459 | Val Loss: 0.4337 | Val Acc: 0.8375\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.4036 | Train Acc: 0.8525 | Val Loss: 0.3901 | Val Acc: 0.8554\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.4045 | Train Acc: 0.8519 | Val Loss: 0.4536 | Val Acc: 0.8420\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3938 | Train Acc: 0.8555 | Val Loss: 0.4050 | Val Acc: 0.8529\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3907 | Train Acc: 0.8550 | Val Loss: 0.5024 | Val Acc: 0.8163\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3866 | Train Acc: 0.8559 | Val Loss: 0.4117 | Val Acc: 0.8547\n",
      "[Fold 5 | Epoch 15] Train Loss: 0.3840 | Train Acc: 0.8577 | Val Loss: 0.3890 | Val Acc: 0.8569\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3811 | Train Acc: 0.8581 | Val Loss: 0.4139 | Val Acc: 0.8458\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3765 | Train Acc: 0.8614 | Val Loss: 0.3966 | Val Acc: 0.8539\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3712 | Train Acc: 0.8634 | Val Loss: 0.3993 | Val Acc: 0.8490\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3673 | Train Acc: 0.8636 | Val Loss: 0.4123 | Val Acc: 0.8460\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3618 | Train Acc: 0.8665 | Val Loss: 0.5013 | Val Acc: 0.8246\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.3620 | Train Acc: 0.8675 | Val Loss: 0.3889 | Val Acc: 0.8567\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.3549 | Train Acc: 0.8679 | Val Loss: 0.4949 | Val Acc: 0.8296\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.3535 | Train Acc: 0.8683 | Val Loss: 0.3924 | Val Acc: 0.8580\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.3515 | Train Acc: 0.8684 | Val Loss: 0.3872 | Val Acc: 0.8572\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.3421 | Train Acc: 0.8726 | Val Loss: 0.3733 | Val Acc: 0.8638\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.3340 | Train Acc: 0.8757 | Val Loss: 0.4350 | Val Acc: 0.8381\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.3384 | Train Acc: 0.8743 | Val Loss: 0.3729 | Val Acc: 0.8672\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.3260 | Train Acc: 0.8801 | Val Loss: 0.4378 | Val Acc: 0.8481\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.3231 | Train Acc: 0.8804 | Val Loss: 0.4132 | Val Acc: 0.8589\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.3140 | Train Acc: 0.8828 | Val Loss: 0.4021 | Val Acc: 0.8620\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.3113 | Train Acc: 0.8820 | Val Loss: 0.4202 | Val Acc: 0.8540\n",
      "[Fold 5 | Epoch 32] Train Loss: 0.3074 | Train Acc: 0.8836 | Val Loss: 0.4038 | Val Acc: 0.8575\n",
      "[Fold 5 | Epoch 33] Train Loss: 0.3058 | Train Acc: 0.8861 | Val Loss: 0.3770 | Val Acc: 0.8682\n",
      "[Fold 5 | Epoch 34] Train Loss: 0.2978 | Train Acc: 0.8896 | Val Loss: 0.4177 | Val Acc: 0.8546\n",
      "[Fold 5 | Epoch 35] Train Loss: 0.2888 | Train Acc: 0.8919 | Val Loss: 0.4861 | Val Acc: 0.8382\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 33\n",
      "ACC: 0.8682 | MF1: 0.8205 | G-Mean: 0.8811\n",
      "[Class 0] Prec: 0.8898 | Rec: 0.9235 | F1: 0.9063 | GM: 0.9484\n",
      "[Class 1] Prec: 0.6325 | Rec: 0.4961 | F1: 0.5560 | GM: 0.6963\n",
      "[Class 2] Prec: 0.9043 | Rec: 0.9080 | F1: 0.9061 | GM: 0.9186\n",
      "[Class 3] Prec: 0.9081 | Rec: 0.9071 | F1: 0.9076 | GM: 0.9459\n",
      "[Class 4] Prec: 0.8110 | Rec: 0.8420 | F1: 0.8262 | GM: 0.8965\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8649 | MF1: 0.8209 | G-Mean: 0.8854\n",
      "[Class 0] Prec: 0.9283 | Rec: 0.9020 | F1: 0.9149 | GM: 0.9422\n",
      "[Class 1] Prec: 0.5914 | Rec: 0.5416 | F1: 0.5654 | GM: 0.7250\n",
      "[Class 2] Prec: 0.9116 | Rec: 0.8939 | F1: 0.9026 | GM: 0.9148\n",
      "[Class 3] Prec: 0.8997 | Rec: 0.9011 | F1: 0.9004 | GM: 0.9421\n",
      "[Class 4] Prec: 0.7825 | Rec: 0.8635 | F1: 0.8210 | GM: 0.9031\n",
      "Confusion Matrix:\n",
      "[[ 5836   322   133    20   159]\n",
      " [  263  1381   290     0   616]\n",
      " [   85   254 13207   434   795]\n",
      " [   12     0   433  4073     2]\n",
      " [   91   378   425     0  5656]]\n"
     ]
    }
   ],
   "source": [
    "#p12\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ==== Load and Normalize Data ====\n",
    "\n",
    "df = pd.read_csv(\"pruned_dataset3.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "     # === Build and Prune Model ===\n",
    "    model_unpruned = FinalNetwork(C=9, num_classes=num_classes, layers=11, genotype=searched_genotype).to(device)\n",
    "    total_params_before = sum(p.numel() for p in model_unpruned.parameters())\n",
    "    print(f\"[INFO] Total parameters BEFORE pruning: {total_params_before:,}\")\n",
    "\n",
    "    model = prune_model_entropy(model_unpruned, prune_ratio=0.5)\n",
    "    nonzero_params_after = sum((p != 0).sum().item() for p in model.parameters())\n",
    "    zero_params = total_params_before - nonzero_params_after\n",
    "    pruned_ratio = 100 * zero_params / total_params_before\n",
    "    print(f\"[INFO] Non-zero parameters AFTER pruning: {nonzero_params_after:,}\")\n",
    "    print(f\"[INFO] Pruned parameters: {zero_params:,} ({pruned_ratio:.2f}%)\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    " \n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "\n",
    "    for epoch in range(35):  # You can change this to 50 or more\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01e705d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5670 | Train Acc: 0.7876 | Val Loss: 0.5381 | Val Acc: 0.8027\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4643 | Train Acc: 0.8283 | Val Loss: 0.4859 | Val Acc: 0.8184\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4448 | Train Acc: 0.8358 | Val Loss: 0.4585 | Val Acc: 0.8299\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4217 | Train Acc: 0.8452 | Val Loss: 0.4332 | Val Acc: 0.8332\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4139 | Train Acc: 0.8466 | Val Loss: 0.4105 | Val Acc: 0.8435\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4049 | Train Acc: 0.8511 | Val Loss: 0.4535 | Val Acc: 0.8260\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.3936 | Train Acc: 0.8555 | Val Loss: 0.4218 | Val Acc: 0.8398\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.3912 | Train Acc: 0.8580 | Val Loss: 0.3893 | Val Acc: 0.8543\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.3800 | Train Acc: 0.8592 | Val Loss: 0.3989 | Val Acc: 0.8500\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.3730 | Train Acc: 0.8621 | Val Loss: 0.4301 | Val Acc: 0.8427\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3594 | Train Acc: 0.8668 | Val Loss: 0.3641 | Val Acc: 0.8666\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3551 | Train Acc: 0.8683 | Val Loss: 0.3641 | Val Acc: 0.8636\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3499 | Train Acc: 0.8718 | Val Loss: 0.4012 | Val Acc: 0.8470\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3399 | Train Acc: 0.8739 | Val Loss: 0.4262 | Val Acc: 0.8453\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3352 | Train Acc: 0.8766 | Val Loss: 0.4044 | Val Acc: 0.8445\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3237 | Train Acc: 0.8802 | Val Loss: 0.3896 | Val Acc: 0.8603\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3106 | Train Acc: 0.8862 | Val Loss: 0.4007 | Val Acc: 0.8559\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.2975 | Train Acc: 0.8894 | Val Loss: 0.3854 | Val Acc: 0.8610\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.2872 | Train Acc: 0.8928 | Val Loss: 0.4580 | Val Acc: 0.8351\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.2735 | Train Acc: 0.8985 | Val Loss: 0.4083 | Val Acc: 0.8582\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.2662 | Train Acc: 0.9017 | Val Loss: 0.6145 | Val Acc: 0.7715\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.2490 | Train Acc: 0.9079 | Val Loss: 0.4186 | Val Acc: 0.8523\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.2457 | Train Acc: 0.9081 | Val Loss: 0.4372 | Val Acc: 0.8486\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.2367 | Train Acc: 0.9100 | Val Loss: 0.4272 | Val Acc: 0.8516\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.2234 | Train Acc: 0.9151 | Val Loss: 0.4487 | Val Acc: 0.8523\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.2166 | Train Acc: 0.9192 | Val Loss: 0.4095 | Val Acc: 0.8706\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.2001 | Train Acc: 0.9236 | Val Loss: 0.6363 | Val Acc: 0.8027\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.1971 | Train Acc: 0.9253 | Val Loss: 0.3969 | Val Acc: 0.8661\n",
      "[Fold 1 | Epoch 29] Train Loss: 0.1771 | Train Acc: 0.9340 | Val Loss: 0.5097 | Val Acc: 0.8586\n",
      "[Fold 1 | Epoch 30] Train Loss: 0.1757 | Train Acc: 0.9347 | Val Loss: 0.5992 | Val Acc: 0.8253\n",
      "[Fold 1 | Epoch 31] Train Loss: 0.1749 | Train Acc: 0.9313 | Val Loss: 0.5780 | Val Acc: 0.8242\n",
      "[Fold 1 | Epoch 32] Train Loss: 0.1639 | Train Acc: 0.9382 | Val Loss: 0.4868 | Val Acc: 0.8444\n",
      "[Fold 1 | Epoch 33] Train Loss: 0.1504 | Train Acc: 0.9440 | Val Loss: 0.4803 | Val Acc: 0.8600\n",
      "[Fold 1 | Epoch 34] Train Loss: 0.1445 | Train Acc: 0.9459 | Val Loss: 0.5624 | Val Acc: 0.8378\n",
      "[Fold 1 | Epoch 35] Train Loss: 0.1448 | Train Acc: 0.9445 | Val Loss: 0.5366 | Val Acc: 0.8613\n",
      "[Fold 1 | Epoch 36] Train Loss: 0.1338 | Train Acc: 0.9490 | Val Loss: 0.5288 | Val Acc: 0.8559\n",
      "[Fold 1 | Epoch 37] Train Loss: 0.1360 | Train Acc: 0.9493 | Val Loss: 0.5731 | Val Acc: 0.8509\n",
      "[Fold 1 | Epoch 38] Train Loss: 0.1254 | Train Acc: 0.9518 | Val Loss: 0.5588 | Val Acc: 0.8575\n",
      "[Fold 1 | Epoch 39] Train Loss: 0.1179 | Train Acc: 0.9558 | Val Loss: 0.5983 | Val Acc: 0.8411\n",
      "[Fold 1 | Epoch 40] Train Loss: 0.1226 | Train Acc: 0.9548 | Val Loss: 0.5255 | Val Acc: 0.8612\n",
      "[Fold 1 | Epoch 41] Train Loss: 0.1136 | Train Acc: 0.9573 | Val Loss: 0.5439 | Val Acc: 0.8645\n",
      "[Fold 1 | Epoch 42] Train Loss: 0.1160 | Train Acc: 0.9555 | Val Loss: 0.5879 | Val Acc: 0.8575\n",
      "[Fold 1 | Epoch 43] Train Loss: 0.1127 | Train Acc: 0.9565 | Val Loss: 0.5908 | Val Acc: 0.8488\n",
      "[Fold 1 | Epoch 44] Train Loss: 0.1042 | Train Acc: 0.9615 | Val Loss: 0.6053 | Val Acc: 0.8575\n",
      "[Fold 1 | Epoch 45] Train Loss: 0.1023 | Train Acc: 0.9639 | Val Loss: 0.6142 | Val Acc: 0.8586\n",
      "[Fold 1 | Epoch 46] Train Loss: 0.0985 | Train Acc: 0.9638 | Val Loss: 0.6595 | Val Acc: 0.8496\n",
      "[Fold 1 | Epoch 47] Train Loss: 0.0951 | Train Acc: 0.9653 | Val Loss: 0.7435 | Val Acc: 0.8361\n",
      "[Fold 1 | Epoch 48] Train Loss: 0.0953 | Train Acc: 0.9641 | Val Loss: 0.6699 | Val Acc: 0.8493\n",
      "[Fold 1 | Epoch 49] Train Loss: 0.1010 | Train Acc: 0.9626 | Val Loss: 0.6114 | Val Acc: 0.8576\n",
      "[Fold 1 | Epoch 50] Train Loss: 0.0857 | Train Acc: 0.9684 | Val Loss: 0.6444 | Val Acc: 0.8470\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 26\n",
      "ACC: 0.8706 | MF1: 0.8297 | G-Mean: 0.8861\n",
      "[Class 0] Prec: 0.9500 | Rec: 0.8799 | F1: 0.9136 | GM: 0.9332\n",
      "[Class 1] Prec: 0.6281 | Rec: 0.5685 | F1: 0.5968 | GM: 0.7442\n",
      "[Class 2] Prec: 0.8802 | Rec: 0.9231 | F1: 0.9011 | GM: 0.9147\n",
      "[Class 3] Prec: 0.8931 | Rec: 0.8911 | F1: 0.8921 | GM: 0.9367\n",
      "[Class 4] Prec: 0.8454 | Rec: 0.8442 | F1: 0.8448 | GM: 0.9015\n",
      "\n",
      "===== Fold 2 =====\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5580 | Train Acc: 0.7913 | Val Loss: 0.5741 | Val Acc: 0.8055\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4595 | Train Acc: 0.8283 | Val Loss: 0.4139 | Val Acc: 0.8514\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4338 | Train Acc: 0.8363 | Val Loss: 0.4610 | Val Acc: 0.8299\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4162 | Train Acc: 0.8441 | Val Loss: 0.3956 | Val Acc: 0.8573\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4096 | Train Acc: 0.8453 | Val Loss: 0.4079 | Val Acc: 0.8496\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4007 | Train Acc: 0.8480 | Val Loss: 0.4847 | Val Acc: 0.8199\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.3897 | Train Acc: 0.8537 | Val Loss: 0.3793 | Val Acc: 0.8648\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.3828 | Train Acc: 0.8568 | Val Loss: 0.4000 | Val Acc: 0.8506\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.3787 | Train Acc: 0.8608 | Val Loss: 0.3880 | Val Acc: 0.8616\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.3652 | Train Acc: 0.8638 | Val Loss: 0.4695 | Val Acc: 0.8281\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3586 | Train Acc: 0.8637 | Val Loss: 0.7388 | Val Acc: 0.7271\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3542 | Train Acc: 0.8666 | Val Loss: 0.4317 | Val Acc: 0.8437\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3462 | Train Acc: 0.8694 | Val Loss: 0.4183 | Val Acc: 0.8557\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3340 | Train Acc: 0.8763 | Val Loss: 0.4011 | Val Acc: 0.8613\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3276 | Train Acc: 0.8777 | Val Loss: 0.4006 | Val Acc: 0.8639\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3137 | Train Acc: 0.8847 | Val Loss: 0.5327 | Val Acc: 0.8199\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3061 | Train Acc: 0.8843 | Val Loss: 0.3993 | Val Acc: 0.8612\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.2992 | Train Acc: 0.8881 | Val Loss: 0.3801 | Val Acc: 0.8651\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.2871 | Train Acc: 0.8928 | Val Loss: 0.4089 | Val Acc: 0.8612\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.2783 | Train Acc: 0.8956 | Val Loss: 0.3984 | Val Acc: 0.8609\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.2643 | Train Acc: 0.9005 | Val Loss: 0.3976 | Val Acc: 0.8613\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.2521 | Train Acc: 0.9057 | Val Loss: 0.4487 | Val Acc: 0.8458\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.2414 | Train Acc: 0.9075 | Val Loss: 0.4574 | Val Acc: 0.8498\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.2305 | Train Acc: 0.9143 | Val Loss: 0.4288 | Val Acc: 0.8718\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.2242 | Train Acc: 0.9161 | Val Loss: 0.5013 | Val Acc: 0.8336\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.2096 | Train Acc: 0.9203 | Val Loss: 0.4553 | Val Acc: 0.8615\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.2075 | Train Acc: 0.9215 | Val Loss: 0.5096 | Val Acc: 0.8570\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.1901 | Train Acc: 0.9277 | Val Loss: 0.4524 | Val Acc: 0.8666\n",
      "[Fold 2 | Epoch 29] Train Loss: 0.1839 | Train Acc: 0.9302 | Val Loss: 0.5375 | Val Acc: 0.8576\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.1821 | Train Acc: 0.9317 | Val Loss: 0.4997 | Val Acc: 0.8575\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.1726 | Train Acc: 0.9352 | Val Loss: 0.5016 | Val Acc: 0.8544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2 | Epoch 32] Train Loss: 0.1609 | Train Acc: 0.9384 | Val Loss: 0.4969 | Val Acc: 0.8524\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.1533 | Train Acc: 0.9433 | Val Loss: 0.5494 | Val Acc: 0.8547\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.1484 | Train Acc: 0.9449 | Val Loss: 0.5898 | Val Acc: 0.8379\n",
      "[Fold 2 | Epoch 35] Train Loss: 0.1443 | Train Acc: 0.9452 | Val Loss: 0.6278 | Val Acc: 0.8506\n",
      "[Fold 2 | Epoch 36] Train Loss: 0.1358 | Train Acc: 0.9488 | Val Loss: 0.6442 | Val Acc: 0.8496\n",
      "[Fold 2 | Epoch 37] Train Loss: 0.1336 | Train Acc: 0.9492 | Val Loss: 0.5597 | Val Acc: 0.8610\n",
      "[Fold 2 | Epoch 38] Train Loss: 0.1192 | Train Acc: 0.9546 | Val Loss: 0.6064 | Val Acc: 0.8662\n",
      "[Fold 2 | Epoch 39] Train Loss: 0.1176 | Train Acc: 0.9555 | Val Loss: 0.6761 | Val Acc: 0.8342\n",
      "[Fold 2 | Epoch 40] Train Loss: 0.1278 | Train Acc: 0.9513 | Val Loss: 0.5558 | Val Acc: 0.8610\n",
      "[Fold 2 | Epoch 41] Train Loss: 0.1014 | Train Acc: 0.9633 | Val Loss: 0.5887 | Val Acc: 0.8580\n",
      "[Fold 2 | Epoch 42] Train Loss: 0.1101 | Train Acc: 0.9594 | Val Loss: 0.5893 | Val Acc: 0.8595\n",
      "[Fold 2 | Epoch 43] Train Loss: 0.1146 | Train Acc: 0.9584 | Val Loss: 0.5868 | Val Acc: 0.8537\n",
      "[Fold 2 | Epoch 44] Train Loss: 0.0905 | Train Acc: 0.9663 | Val Loss: 0.7028 | Val Acc: 0.8543\n",
      "[Fold 2 | Epoch 45] Train Loss: 0.1134 | Train Acc: 0.9591 | Val Loss: 0.5838 | Val Acc: 0.8653\n",
      "[Fold 2 | Epoch 46] Train Loss: 0.0975 | Train Acc: 0.9644 | Val Loss: 0.7501 | Val Acc: 0.8308\n",
      "[Fold 2 | Epoch 47] Train Loss: 0.0978 | Train Acc: 0.9639 | Val Loss: 0.6314 | Val Acc: 0.8609\n",
      "[Fold 2 | Epoch 48] Train Loss: 0.0878 | Train Acc: 0.9681 | Val Loss: 0.7351 | Val Acc: 0.8443\n",
      "[Fold 2 | Epoch 49] Train Loss: 0.0896 | Train Acc: 0.9665 | Val Loss: 0.7728 | Val Acc: 0.8473\n",
      "[Fold 2 | Epoch 50] Train Loss: 0.0962 | Train Acc: 0.9639 | Val Loss: 0.6623 | Val Acc: 0.8619\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 24\n",
      "ACC: 0.8718 | MF1: 0.8301 | G-Mean: 0.8896\n",
      "[Class 0] Prec: 0.9163 | Rec: 0.9295 | F1: 0.9229 | GM: 0.9552\n",
      "[Class 1] Prec: 0.6435 | Rec: 0.5336 | F1: 0.5834 | GM: 0.7217\n",
      "[Class 2] Prec: 0.9127 | Rec: 0.8928 | F1: 0.9027 | GM: 0.9133\n",
      "[Class 3] Prec: 0.9086 | Rec: 0.9002 | F1: 0.9044 | GM: 0.9426\n",
      "[Class 4] Prec: 0.7949 | Rec: 0.8837 | F1: 0.8369 | GM: 0.9152\n",
      "\n",
      "===== Fold 3 =====\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.5431 | Train Acc: 0.7950 | Val Loss: 0.5157 | Val Acc: 0.8015\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4620 | Train Acc: 0.8289 | Val Loss: 0.4879 | Val Acc: 0.8136\n",
      "[Fold 3 | Epoch 3] Train Loss: 0.4375 | Train Acc: 0.8371 | Val Loss: 0.4426 | Val Acc: 0.8404\n",
      "[Fold 3 | Epoch 4] Train Loss: 0.4257 | Train Acc: 0.8417 | Val Loss: 0.4267 | Val Acc: 0.8445\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4095 | Train Acc: 0.8489 | Val Loss: 0.7008 | Val Acc: 0.7690\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4013 | Train Acc: 0.8502 | Val Loss: 0.4274 | Val Acc: 0.8503\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.3932 | Train Acc: 0.8552 | Val Loss: 0.4070 | Val Acc: 0.8501\n",
      "[Fold 3 | Epoch 8] Train Loss: 0.3797 | Train Acc: 0.8590 | Val Loss: 0.3870 | Val Acc: 0.8610\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.3799 | Train Acc: 0.8590 | Val Loss: 0.4383 | Val Acc: 0.8463\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.3713 | Train Acc: 0.8600 | Val Loss: 0.4117 | Val Acc: 0.8481\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3663 | Train Acc: 0.8624 | Val Loss: 0.4210 | Val Acc: 0.8387\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3533 | Train Acc: 0.8687 | Val Loss: 0.3740 | Val Acc: 0.8645\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3515 | Train Acc: 0.8682 | Val Loss: 0.4031 | Val Acc: 0.8544\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3459 | Train Acc: 0.8703 | Val Loss: 0.4195 | Val Acc: 0.8531\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3330 | Train Acc: 0.8746 | Val Loss: 0.4782 | Val Acc: 0.8272\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3278 | Train Acc: 0.8757 | Val Loss: 0.4134 | Val Acc: 0.8625\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3242 | Train Acc: 0.8776 | Val Loss: 0.4147 | Val Acc: 0.8559\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3121 | Train Acc: 0.8830 | Val Loss: 0.4632 | Val Acc: 0.8358\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.2987 | Train Acc: 0.8895 | Val Loss: 0.3982 | Val Acc: 0.8599\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.2928 | Train Acc: 0.8899 | Val Loss: 0.4272 | Val Acc: 0.8544\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.2858 | Train Acc: 0.8931 | Val Loss: 0.4082 | Val Acc: 0.8597\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.2698 | Train Acc: 0.8996 | Val Loss: 0.4416 | Val Acc: 0.8520\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.2640 | Train Acc: 0.9012 | Val Loss: 0.4525 | Val Acc: 0.8480\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.2525 | Train Acc: 0.9052 | Val Loss: 0.4259 | Val Acc: 0.8569\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.2402 | Train Acc: 0.9105 | Val Loss: 0.4610 | Val Acc: 0.8586\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.2396 | Train Acc: 0.9088 | Val Loss: 0.4590 | Val Acc: 0.8672\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.2216 | Train Acc: 0.9156 | Val Loss: 0.4458 | Val Acc: 0.8564\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.2163 | Train Acc: 0.9196 | Val Loss: 0.4896 | Val Acc: 0.8391\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.2078 | Train Acc: 0.9213 | Val Loss: 0.4573 | Val Acc: 0.8645\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.2000 | Train Acc: 0.9234 | Val Loss: 0.4750 | Val Acc: 0.8504\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.1878 | Train Acc: 0.9291 | Val Loss: 0.6337 | Val Acc: 0.8160\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.1872 | Train Acc: 0.9293 | Val Loss: 0.5892 | Val Acc: 0.8346\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.1775 | Train Acc: 0.9326 | Val Loss: 0.6127 | Val Acc: 0.8316\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.1698 | Train Acc: 0.9351 | Val Loss: 0.6001 | Val Acc: 0.8316\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.1630 | Train Acc: 0.9394 | Val Loss: 0.5896 | Val Acc: 0.8605\n",
      "[Fold 3 | Epoch 36] Train Loss: 0.1572 | Train Acc: 0.9410 | Val Loss: 0.5171 | Val Acc: 0.8671\n",
      "[Fold 3 | Epoch 37] Train Loss: 0.1555 | Train Acc: 0.9411 | Val Loss: 0.5175 | Val Acc: 0.8569\n",
      "[Fold 3 | Epoch 38] Train Loss: 0.1384 | Train Acc: 0.9481 | Val Loss: 0.5296 | Val Acc: 0.8683\n",
      "[Fold 3 | Epoch 39] Train Loss: 0.1428 | Train Acc: 0.9467 | Val Loss: 0.5757 | Val Acc: 0.8560\n",
      "[Fold 3 | Epoch 40] Train Loss: 0.1406 | Train Acc: 0.9472 | Val Loss: 0.5902 | Val Acc: 0.8531\n",
      "[Fold 3 | Epoch 41] Train Loss: 0.1290 | Train Acc: 0.9521 | Val Loss: 0.6748 | Val Acc: 0.8484\n",
      "[Fold 3 | Epoch 42] Train Loss: 0.1240 | Train Acc: 0.9527 | Val Loss: 0.6930 | Val Acc: 0.8468\n",
      "[Fold 3 | Epoch 43] Train Loss: 0.1267 | Train Acc: 0.9529 | Val Loss: 0.5730 | Val Acc: 0.8599\n",
      "[Fold 3 | Epoch 44] Train Loss: 0.1127 | Train Acc: 0.9567 | Val Loss: 0.6351 | Val Acc: 0.8668\n",
      "[Fold 3 | Epoch 45] Train Loss: 0.1146 | Train Acc: 0.9581 | Val Loss: 0.5839 | Val Acc: 0.8628\n",
      "[Fold 3 | Epoch 46] Train Loss: 0.1087 | Train Acc: 0.9581 | Val Loss: 0.6053 | Val Acc: 0.8742\n",
      "[Fold 3 | Epoch 47] Train Loss: 0.1109 | Train Acc: 0.9591 | Val Loss: 0.6265 | Val Acc: 0.8524\n",
      "[Fold 3 | Epoch 48] Train Loss: 0.1074 | Train Acc: 0.9596 | Val Loss: 0.6616 | Val Acc: 0.8540\n",
      "[Fold 3 | Epoch 49] Train Loss: 0.1086 | Train Acc: 0.9596 | Val Loss: 0.5990 | Val Acc: 0.8685\n",
      "[Fold 3 | Epoch 50] Train Loss: 0.1070 | Train Acc: 0.9589 | Val Loss: 0.9940 | Val Acc: 0.8035\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 46\n",
      "ACC: 0.8742 | MF1: 0.8388 | G-Mean: 0.8920\n",
      "[Class 0] Prec: 0.9410 | Rec: 0.9076 | F1: 0.9240 | GM: 0.9470\n",
      "[Class 1] Prec: 0.7118 | Rec: 0.5757 | F1: 0.6366 | GM: 0.7519\n",
      "[Class 2] Prec: 0.8965 | Rec: 0.9019 | F1: 0.8992 | GM: 0.9114\n",
      "[Class 3] Prec: 0.8923 | Rec: 0.8792 | F1: 0.8857 | GM: 0.9304\n",
      "[Class 4] Prec: 0.8107 | Rec: 0.8902 | F1: 0.8486 | GM: 0.9193\n",
      "\n",
      "===== Fold 4 =====\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5547 | Train Acc: 0.7883 | Val Loss: 0.4880 | Val Acc: 0.8210\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4577 | Train Acc: 0.8297 | Val Loss: 0.4297 | Val Acc: 0.8445\n",
      "[Fold 4 | Epoch 3] Train Loss: 0.4336 | Train Acc: 0.8378 | Val Loss: 0.4785 | Val Acc: 0.8190\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4261 | Train Acc: 0.8431 | Val Loss: 0.3958 | Val Acc: 0.8542\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4098 | Train Acc: 0.8474 | Val Loss: 0.3903 | Val Acc: 0.8589\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.3995 | Train Acc: 0.8505 | Val Loss: 0.4209 | Val Acc: 0.8397\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.3930 | Train Acc: 0.8550 | Val Loss: 0.4168 | Val Acc: 0.8481\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.3851 | Train Acc: 0.8588 | Val Loss: 0.4094 | Val Acc: 0.8554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4 | Epoch 9] Train Loss: 0.3794 | Train Acc: 0.8595 | Val Loss: 0.4307 | Val Acc: 0.8414\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.3712 | Train Acc: 0.8612 | Val Loss: 0.3834 | Val Acc: 0.8599\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.3620 | Train Acc: 0.8686 | Val Loss: 0.4844 | Val Acc: 0.8219\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3599 | Train Acc: 0.8668 | Val Loss: 0.4089 | Val Acc: 0.8484\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3518 | Train Acc: 0.8687 | Val Loss: 0.4399 | Val Acc: 0.8378\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3444 | Train Acc: 0.8721 | Val Loss: 0.3845 | Val Acc: 0.8579\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3340 | Train Acc: 0.8758 | Val Loss: 0.4478 | Val Acc: 0.8427\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3273 | Train Acc: 0.8776 | Val Loss: 0.4611 | Val Acc: 0.8315\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3217 | Train Acc: 0.8795 | Val Loss: 0.4112 | Val Acc: 0.8540\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3085 | Train Acc: 0.8862 | Val Loss: 0.3805 | Val Acc: 0.8610\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3015 | Train Acc: 0.8882 | Val Loss: 0.4012 | Val Acc: 0.8533\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.2934 | Train Acc: 0.8907 | Val Loss: 0.4381 | Val Acc: 0.8501\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.2850 | Train Acc: 0.8937 | Val Loss: 0.4003 | Val Acc: 0.8602\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.2753 | Train Acc: 0.8962 | Val Loss: 0.4115 | Val Acc: 0.8547\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.2654 | Train Acc: 0.9022 | Val Loss: 0.4053 | Val Acc: 0.8567\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.2561 | Train Acc: 0.9057 | Val Loss: 0.4333 | Val Acc: 0.8520\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.2455 | Train Acc: 0.9086 | Val Loss: 0.4895 | Val Acc: 0.8276\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.2355 | Train Acc: 0.9120 | Val Loss: 0.4474 | Val Acc: 0.8484\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.2321 | Train Acc: 0.9132 | Val Loss: 0.4165 | Val Acc: 0.8603\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.2206 | Train Acc: 0.9179 | Val Loss: 0.5103 | Val Acc: 0.8453\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.2153 | Train Acc: 0.9200 | Val Loss: 0.5341 | Val Acc: 0.8351\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.1981 | Train Acc: 0.9246 | Val Loss: 0.5265 | Val Acc: 0.8398\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.1970 | Train Acc: 0.9246 | Val Loss: 0.4373 | Val Acc: 0.8622\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.1910 | Train Acc: 0.9284 | Val Loss: 0.4749 | Val Acc: 0.8536\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.1759 | Train Acc: 0.9327 | Val Loss: 0.5572 | Val Acc: 0.8397\n",
      "[Fold 4 | Epoch 34] Train Loss: 0.1753 | Train Acc: 0.9356 | Val Loss: 0.4865 | Val Acc: 0.8557\n",
      "[Fold 4 | Epoch 35] Train Loss: 0.1602 | Train Acc: 0.9402 | Val Loss: 0.5592 | Val Acc: 0.8444\n",
      "[Fold 4 | Epoch 36] Train Loss: 0.1536 | Train Acc: 0.9433 | Val Loss: 0.5466 | Val Acc: 0.8407\n",
      "[Fold 4 | Epoch 37] Train Loss: 0.1550 | Train Acc: 0.9416 | Val Loss: 0.5826 | Val Acc: 0.8473\n",
      "[Fold 4 | Epoch 38] Train Loss: 0.1505 | Train Acc: 0.9430 | Val Loss: 0.5144 | Val Acc: 0.8553\n",
      "[Fold 4 | Epoch 39] Train Loss: 0.1409 | Train Acc: 0.9486 | Val Loss: 0.5242 | Val Acc: 0.8585\n",
      "[Fold 4 | Epoch 40] Train Loss: 0.1350 | Train Acc: 0.9468 | Val Loss: 0.5760 | Val Acc: 0.8451\n",
      "[Fold 4 | Epoch 41] Train Loss: 0.1318 | Train Acc: 0.9497 | Val Loss: 0.6318 | Val Acc: 0.8476\n",
      "[Fold 4 | Epoch 42] Train Loss: 0.1311 | Train Acc: 0.9511 | Val Loss: 0.5557 | Val Acc: 0.8593\n",
      "[Fold 4 | Epoch 43] Train Loss: 0.1199 | Train Acc: 0.9548 | Val Loss: 0.6537 | Val Acc: 0.8524\n",
      "[Fold 4 | Epoch 44] Train Loss: 0.1217 | Train Acc: 0.9544 | Val Loss: 0.6283 | Val Acc: 0.8530\n",
      "[Fold 4 | Epoch 45] Train Loss: 0.1158 | Train Acc: 0.9571 | Val Loss: 0.6605 | Val Acc: 0.8500\n",
      "[Fold 4 | Epoch 46] Train Loss: 0.1234 | Train Acc: 0.9541 | Val Loss: 0.7236 | Val Acc: 0.8216\n",
      "[Fold 4 | Epoch 47] Train Loss: 0.1126 | Train Acc: 0.9573 | Val Loss: 0.6933 | Val Acc: 0.8514\n",
      "[Fold 4 | Epoch 48] Train Loss: 0.1030 | Train Acc: 0.9619 | Val Loss: 0.6321 | Val Acc: 0.8575\n",
      "[Fold 4 | Epoch 49] Train Loss: 0.1082 | Train Acc: 0.9599 | Val Loss: 0.6516 | Val Acc: 0.8540\n",
      "[Fold 4 | Epoch 50] Train Loss: 0.1032 | Train Acc: 0.9605 | Val Loss: 0.7145 | Val Acc: 0.8438\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 31\n",
      "ACC: 0.8622 | MF1: 0.8227 | G-Mean: 0.8884\n",
      "[Class 0] Prec: 0.8853 | Rec: 0.9083 | F1: 0.8967 | GM: 0.9400\n",
      "[Class 1] Prec: 0.6099 | Rec: 0.5970 | F1: 0.6034 | GM: 0.7619\n",
      "[Class 2] Prec: 0.8992 | Rec: 0.8868 | F1: 0.8930 | GM: 0.9064\n",
      "[Class 3] Prec: 0.8714 | Rec: 0.9051 | F1: 0.8879 | GM: 0.9418\n",
      "[Class 4] Prec: 0.8381 | Rec: 0.8266 | F1: 0.8323 | GM: 0.8922\n",
      "\n",
      "===== Fold 5 =====\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.5617 | Train Acc: 0.7908 | Val Loss: 0.4937 | Val Acc: 0.8163\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4655 | Train Acc: 0.8260 | Val Loss: 0.4516 | Val Acc: 0.8334\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4401 | Train Acc: 0.8349 | Val Loss: 0.4235 | Val Acc: 0.8438\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4244 | Train Acc: 0.8448 | Val Loss: 0.3954 | Val Acc: 0.8533\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4113 | Train Acc: 0.8485 | Val Loss: 0.5472 | Val Acc: 0.8107\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4028 | Train Acc: 0.8524 | Val Loss: 0.3987 | Val Acc: 0.8540\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.3943 | Train Acc: 0.8542 | Val Loss: 0.4200 | Val Acc: 0.8490\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.3883 | Train Acc: 0.8567 | Val Loss: 0.4913 | Val Acc: 0.8179\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.3834 | Train Acc: 0.8567 | Val Loss: 0.4352 | Val Acc: 0.8443\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.3694 | Train Acc: 0.8628 | Val Loss: 0.5016 | Val Acc: 0.8216\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.3680 | Train Acc: 0.8636 | Val Loss: 0.5089 | Val Acc: 0.8223\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3555 | Train Acc: 0.8690 | Val Loss: 0.4381 | Val Acc: 0.8445\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3526 | Train Acc: 0.8718 | Val Loss: 0.3754 | Val Acc: 0.8668\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3486 | Train Acc: 0.8699 | Val Loss: 0.3961 | Val Acc: 0.8589\n",
      "[Fold 5 | Epoch 15] Train Loss: 0.3337 | Train Acc: 0.8779 | Val Loss: 0.3945 | Val Acc: 0.8602\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3288 | Train Acc: 0.8770 | Val Loss: 0.3816 | Val Acc: 0.8669\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3224 | Train Acc: 0.8805 | Val Loss: 0.3905 | Val Acc: 0.8600\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3150 | Train Acc: 0.8843 | Val Loss: 0.4444 | Val Acc: 0.8440\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3108 | Train Acc: 0.8842 | Val Loss: 0.4180 | Val Acc: 0.8486\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.2937 | Train Acc: 0.8915 | Val Loss: 0.4676 | Val Acc: 0.8433\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.2865 | Train Acc: 0.8947 | Val Loss: 0.4240 | Val Acc: 0.8564\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.2760 | Train Acc: 0.8967 | Val Loss: 0.4342 | Val Acc: 0.8559\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.2649 | Train Acc: 0.9023 | Val Loss: 0.5259 | Val Acc: 0.8331\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.2584 | Train Acc: 0.9038 | Val Loss: 0.4718 | Val Acc: 0.8430\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.2498 | Train Acc: 0.9062 | Val Loss: 0.4337 | Val Acc: 0.8519\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.2411 | Train Acc: 0.9115 | Val Loss: 0.4341 | Val Acc: 0.8610\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.2303 | Train Acc: 0.9127 | Val Loss: 0.4640 | Val Acc: 0.8478\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.2176 | Train Acc: 0.9188 | Val Loss: 0.4687 | Val Acc: 0.8460\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.2098 | Train Acc: 0.9223 | Val Loss: 0.5364 | Val Acc: 0.8193\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.2003 | Train Acc: 0.9264 | Val Loss: 0.5390 | Val Acc: 0.8431\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.1957 | Train Acc: 0.9274 | Val Loss: 0.5234 | Val Acc: 0.8418\n",
      "[Fold 5 | Epoch 32] Train Loss: 0.1881 | Train Acc: 0.9302 | Val Loss: 0.4370 | Val Acc: 0.8645\n",
      "[Fold 5 | Epoch 33] Train Loss: 0.1759 | Train Acc: 0.9349 | Val Loss: 0.5567 | Val Acc: 0.8388\n",
      "[Fold 5 | Epoch 34] Train Loss: 0.1688 | Train Acc: 0.9369 | Val Loss: 0.5162 | Val Acc: 0.8622\n",
      "[Fold 5 | Epoch 35] Train Loss: 0.1637 | Train Acc: 0.9394 | Val Loss: 0.5283 | Val Acc: 0.8576\n",
      "[Fold 5 | Epoch 36] Train Loss: 0.1590 | Train Acc: 0.9406 | Val Loss: 0.5997 | Val Acc: 0.8460\n",
      "[Fold 5 | Epoch 37] Train Loss: 0.1545 | Train Acc: 0.9405 | Val Loss: 0.5372 | Val Acc: 0.8668\n",
      "[Fold 5 | Epoch 38] Train Loss: 0.1401 | Train Acc: 0.9483 | Val Loss: 0.6764 | Val Acc: 0.8296\n",
      "[Fold 5 | Epoch 39] Train Loss: 0.1436 | Train Acc: 0.9456 | Val Loss: 0.5465 | Val Acc: 0.8572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 40] Train Loss: 0.1356 | Train Acc: 0.9489 | Val Loss: 0.6134 | Val Acc: 0.8544\n",
      "[Fold 5 | Epoch 41] Train Loss: 0.1342 | Train Acc: 0.9494 | Val Loss: 0.6384 | Val Acc: 0.8440\n",
      "[Fold 5 | Epoch 42] Train Loss: 0.1248 | Train Acc: 0.9541 | Val Loss: 0.6092 | Val Acc: 0.8504\n",
      "[Fold 5 | Epoch 43] Train Loss: 0.1198 | Train Acc: 0.9567 | Val Loss: 0.5827 | Val Acc: 0.8503\n",
      "[Fold 5 | Epoch 44] Train Loss: 0.1283 | Train Acc: 0.9519 | Val Loss: 0.7611 | Val Acc: 0.8128\n",
      "[Fold 5 | Epoch 45] Train Loss: 0.1181 | Train Acc: 0.9559 | Val Loss: 0.6129 | Val Acc: 0.8554\n",
      "[Fold 5 | Epoch 46] Train Loss: 0.1120 | Train Acc: 0.9588 | Val Loss: 0.5894 | Val Acc: 0.8570\n",
      "[Fold 5 | Epoch 47] Train Loss: 0.1091 | Train Acc: 0.9603 | Val Loss: 0.6610 | Val Acc: 0.8441\n",
      "[Fold 5 | Epoch 48] Train Loss: 0.1048 | Train Acc: 0.9616 | Val Loss: 0.6885 | Val Acc: 0.8375\n",
      "[Fold 5 | Epoch 49] Train Loss: 0.1037 | Train Acc: 0.9611 | Val Loss: 0.8249 | Val Acc: 0.8390\n",
      "[Fold 5 | Epoch 50] Train Loss: 0.1011 | Train Acc: 0.9630 | Val Loss: 0.6962 | Val Acc: 0.8438\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 16\n",
      "ACC: 0.8669 | MF1: 0.8169 | G-Mean: 0.8750\n",
      "[Class 0] Prec: 0.9294 | Rec: 0.8957 | F1: 0.9122 | GM: 0.9390\n",
      "[Class 1] Prec: 0.6425 | Rec: 0.4686 | F1: 0.5420 | GM: 0.6775\n",
      "[Class 2] Prec: 0.9012 | Rec: 0.9137 | F1: 0.9074 | GM: 0.9200\n",
      "[Class 3] Prec: 0.9443 | Rec: 0.8628 | F1: 0.9017 | GM: 0.9254\n",
      "[Class 4] Prec: 0.7617 | Rec: 0.8908 | F1: 0.8213 | GM: 0.9129\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8692 | MF1: 0.8276 | G-Mean: 0.8863\n",
      "[Class 0] Prec: 0.9233 | Rec: 0.9041 | F1: 0.9136 | GM: 0.9429\n",
      "[Class 1] Prec: 0.6458 | Rec: 0.5477 | F1: 0.5927 | GM: 0.7314\n",
      "[Class 2] Prec: 0.8978 | Rec: 0.9036 | F1: 0.9007 | GM: 0.9132\n",
      "[Class 3] Prec: 0.9010 | Rec: 0.8876 | F1: 0.8943 | GM: 0.9354\n",
      "[Class 4] Prec: 0.8085 | Rec: 0.8671 | F1: 0.8368 | GM: 0.9084\n",
      "Confusion Matrix:\n",
      "[[ 5730   316   123    20   149]\n",
      " [  242  1371   389     2   499]\n",
      " [  126   188 13501   411   715]\n",
      " [    6     0   492  3941     1]\n",
      " [  102   248   533     0  5760]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# ==== Load and Normalize Data ====\n",
    "\n",
    "df = pd.read_csv(\"pruned_dataset3.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "# Z-score normalization\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== Evaluation Metric Function ====\n",
    "def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    gmeans = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        tn = np.sum((y_pred != c) & (y_true != c))\n",
    "        fp = np.sum((y_pred == c) & (y_true != c))\n",
    "        gm = np.sqrt((tp / (tp + fn + 1e-6)) * (tn / (tn + fp + 1e-6)))\n",
    "        gmeans.append(gm)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, mf1, np.mean(gmeans), prec, rec, f1s, gmeans, cm\n",
    "\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "    X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "    X_val, y_val = X_all[val_idx], y_all[val_idx]\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "\n",
    "    model = FinalNetwork(C=9, num_classes=num_classes, layers=9, genotype=searched_genotype).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "\n",
    "    for epoch in range(50):  # You can change this to 50 or more\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "349050a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[INFO] Total parameters BEFORE pruning: 117,851\n",
      "[INFO] Non-zero parameters AFTER pruning: 59,078\n",
      "[INFO] Pruned parameters: 58,773 (49.87%)\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5823 | Train Acc: 0.7804 | Val Loss: 0.5713 | Val Acc: 0.7816\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4767 | Train Acc: 0.8229 | Val Loss: 0.4816 | Val Acc: 0.8222\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4473 | Train Acc: 0.8349 | Val Loss: 0.4189 | Val Acc: 0.8478\n",
      "[Fold 1 | Epoch 4] Train Loss: 0.4335 | Train Acc: 0.8402 | Val Loss: 0.4217 | Val Acc: 0.8424\n",
      "[Fold 1 | Epoch 5] Train Loss: 0.4233 | Train Acc: 0.8424 | Val Loss: 0.4693 | Val Acc: 0.8344\n",
      "[Fold 1 | Epoch 6] Train Loss: 0.4179 | Train Acc: 0.8450 | Val Loss: 0.3929 | Val Acc: 0.8552\n",
      "[Fold 1 | Epoch 7] Train Loss: 0.4055 | Train Acc: 0.8497 | Val Loss: 0.4303 | Val Acc: 0.8428\n",
      "[Fold 1 | Epoch 8] Train Loss: 0.3967 | Train Acc: 0.8504 | Val Loss: 0.4216 | Val Acc: 0.8466\n",
      "[Fold 1 | Epoch 9] Train Loss: 0.3967 | Train Acc: 0.8524 | Val Loss: 0.5091 | Val Acc: 0.8083\n",
      "[Fold 1 | Epoch 10] Train Loss: 0.3863 | Train Acc: 0.8552 | Val Loss: 0.4077 | Val Acc: 0.8511\n",
      "[Fold 1 | Epoch 11] Train Loss: 0.3872 | Train Acc: 0.8541 | Val Loss: 0.3939 | Val Acc: 0.8582\n",
      "[Fold 1 | Epoch 12] Train Loss: 0.3737 | Train Acc: 0.8621 | Val Loss: 0.5260 | Val Acc: 0.8172\n",
      "[Fold 1 | Epoch 13] Train Loss: 0.3734 | Train Acc: 0.8590 | Val Loss: 0.4113 | Val Acc: 0.8540\n",
      "[Fold 1 | Epoch 14] Train Loss: 0.3642 | Train Acc: 0.8633 | Val Loss: 0.4100 | Val Acc: 0.8484\n",
      "[Fold 1 | Epoch 15] Train Loss: 0.3558 | Train Acc: 0.8681 | Val Loss: 0.4308 | Val Acc: 0.8455\n",
      "[Fold 1 | Epoch 16] Train Loss: 0.3495 | Train Acc: 0.8699 | Val Loss: 0.4042 | Val Acc: 0.8530\n",
      "[Fold 1 | Epoch 17] Train Loss: 0.3439 | Train Acc: 0.8714 | Val Loss: 0.4505 | Val Acc: 0.8391\n",
      "[Fold 1 | Epoch 18] Train Loss: 0.3413 | Train Acc: 0.8696 | Val Loss: 0.4271 | Val Acc: 0.8398\n",
      "[Fold 1 | Epoch 19] Train Loss: 0.3292 | Train Acc: 0.8744 | Val Loss: 0.3824 | Val Acc: 0.8640\n",
      "[Fold 1 | Epoch 20] Train Loss: 0.3250 | Train Acc: 0.8795 | Val Loss: 0.4321 | Val Acc: 0.8530\n",
      "[Fold 1 | Epoch 21] Train Loss: 0.3210 | Train Acc: 0.8791 | Val Loss: 0.3804 | Val Acc: 0.8609\n",
      "[Fold 1 | Epoch 22] Train Loss: 0.3121 | Train Acc: 0.8841 | Val Loss: 0.4286 | Val Acc: 0.8596\n",
      "[Fold 1 | Epoch 23] Train Loss: 0.3040 | Train Acc: 0.8858 | Val Loss: 0.4081 | Val Acc: 0.8632\n",
      "[Fold 1 | Epoch 24] Train Loss: 0.2988 | Train Acc: 0.8885 | Val Loss: 0.4087 | Val Acc: 0.8586\n",
      "[Fold 1 | Epoch 25] Train Loss: 0.2906 | Train Acc: 0.8924 | Val Loss: 0.4106 | Val Acc: 0.8605\n",
      "[Fold 1 | Epoch 26] Train Loss: 0.2862 | Train Acc: 0.8931 | Val Loss: 0.4297 | Val Acc: 0.8521\n",
      "[Fold 1 | Epoch 27] Train Loss: 0.2839 | Train Acc: 0.8950 | Val Loss: 0.4042 | Val Acc: 0.8619\n",
      "[Fold 1 | Epoch 28] Train Loss: 0.2699 | Train Acc: 0.8972 | Val Loss: 0.4011 | Val Acc: 0.8603\n",
      "[Fold 1 | Epoch 29] Train Loss: 0.2624 | Train Acc: 0.9015 | Val Loss: 0.4703 | Val Acc: 0.8536\n",
      "[Fold 1 | Epoch 30] Train Loss: 0.2531 | Train Acc: 0.9061 | Val Loss: 0.4452 | Val Acc: 0.8607\n",
      "[Fold 1 | Epoch 31] Train Loss: 0.2543 | Train Acc: 0.9045 | Val Loss: 0.4283 | Val Acc: 0.8516\n",
      "[Fold 1 | Epoch 32] Train Loss: 0.2389 | Train Acc: 0.9101 | Val Loss: 0.4611 | Val Acc: 0.8480\n",
      "[Fold 1 | Epoch 33] Train Loss: 0.2373 | Train Acc: 0.9108 | Val Loss: 0.5129 | Val Acc: 0.8390\n",
      "[Fold 1 | Epoch 34] Train Loss: 0.2255 | Train Acc: 0.9149 | Val Loss: 0.4825 | Val Acc: 0.8496\n",
      "[Fold 1 | Epoch 35] Train Loss: 0.2218 | Train Acc: 0.9156 | Val Loss: 0.5206 | Val Acc: 0.8401\n",
      "[Fold 1 | Epoch 36] Train Loss: 0.2198 | Train Acc: 0.9157 | Val Loss: 0.4623 | Val Acc: 0.8570\n",
      "[Fold 1 | Epoch 37] Train Loss: 0.2057 | Train Acc: 0.9226 | Val Loss: 0.4516 | Val Acc: 0.8648\n",
      "[Fold 1 | Epoch 38] Train Loss: 0.2054 | Train Acc: 0.9237 | Val Loss: 0.5182 | Val Acc: 0.8421\n",
      "[Fold 1 | Epoch 39] Train Loss: 0.1969 | Train Acc: 0.9256 | Val Loss: 0.5080 | Val Acc: 0.8447\n",
      "[Fold 1 | Epoch 40] Train Loss: 0.1997 | Train Acc: 0.9246 | Val Loss: 0.4718 | Val Acc: 0.8569\n",
      "[Fold 1 | Epoch 41] Train Loss: 0.1931 | Train Acc: 0.9267 | Val Loss: 0.5564 | Val Acc: 0.8547\n",
      "[Fold 1 | Epoch 42] Train Loss: 0.1853 | Train Acc: 0.9300 | Val Loss: 0.5602 | Val Acc: 0.8575\n",
      "[Fold 1 | Epoch 43] Train Loss: 0.1802 | Train Acc: 0.9307 | Val Loss: 0.4976 | Val Acc: 0.8550\n",
      "[Fold 1 | Epoch 44] Train Loss: 0.1823 | Train Acc: 0.9320 | Val Loss: 0.4946 | Val Acc: 0.8592\n",
      "[Fold 1 | Epoch 45] Train Loss: 0.1703 | Train Acc: 0.9347 | Val Loss: 0.5962 | Val Acc: 0.8334\n",
      "[Fold 1 | Epoch 46] Train Loss: 0.1691 | Train Acc: 0.9346 | Val Loss: 0.5651 | Val Acc: 0.8368\n",
      "[Fold 1 | Epoch 47] Train Loss: 0.1699 | Train Acc: 0.9358 | Val Loss: 0.6443 | Val Acc: 0.8213\n",
      "[Fold 1 | Epoch 48] Train Loss: 0.1665 | Train Acc: 0.9382 | Val Loss: 0.6200 | Val Acc: 0.8470\n",
      "[Fold 1 | Epoch 49] Train Loss: 0.1541 | Train Acc: 0.9423 | Val Loss: 0.5373 | Val Acc: 0.8529\n",
      "[Fold 1 | Epoch 50] Train Loss: 0.1535 | Train Acc: 0.9411 | Val Loss: 0.5137 | Val Acc: 0.8651\n",
      "\n",
      "===== BEST RESULT FOR FOLD 1 =====\n",
      "Best Epoch: 50\n",
      "ACC: 0.8651 | MF1: 0.8247 | G-Mean: 0.8843\n",
      "[Class 0] Prec: 0.9080 | Rec: 0.9150 | F1: 0.9115 | GM: 0.9464\n",
      "[Class 1] Prec: 0.6995 | Rec: 0.5157 | F1: 0.5937 | GM: 0.7118\n",
      "[Class 2] Prec: 0.9032 | Rec: 0.8839 | F1: 0.8934 | GM: 0.9068\n",
      "[Class 3] Prec: 0.8835 | Rec: 0.9148 | F1: 0.8989 | GM: 0.9478\n",
      "[Class 4] Prec: 0.7823 | Rec: 0.8748 | F1: 0.8259 | GM: 0.9086\n",
      "\n",
      "===== Fold 2 =====\n",
      "[INFO] Total parameters BEFORE pruning: 117,851\n",
      "[INFO] Non-zero parameters AFTER pruning: 59,078\n",
      "[INFO] Pruned parameters: 58,773 (49.87%)\n",
      "[Fold 2 | Epoch 1] Train Loss: 0.5982 | Train Acc: 0.7730 | Val Loss: 0.5417 | Val Acc: 0.7865\n",
      "[Fold 2 | Epoch 2] Train Loss: 0.4809 | Train Acc: 0.8217 | Val Loss: 0.4528 | Val Acc: 0.8348\n",
      "[Fold 2 | Epoch 3] Train Loss: 0.4602 | Train Acc: 0.8295 | Val Loss: 0.4223 | Val Acc: 0.8447\n",
      "[Fold 2 | Epoch 4] Train Loss: 0.4362 | Train Acc: 0.8386 | Val Loss: 0.5903 | Val Acc: 0.7911\n",
      "[Fold 2 | Epoch 5] Train Loss: 0.4227 | Train Acc: 0.8418 | Val Loss: 0.4346 | Val Acc: 0.8398\n",
      "[Fold 2 | Epoch 6] Train Loss: 0.4180 | Train Acc: 0.8464 | Val Loss: 0.4088 | Val Acc: 0.8491\n",
      "[Fold 2 | Epoch 7] Train Loss: 0.4107 | Train Acc: 0.8470 | Val Loss: 0.5001 | Val Acc: 0.8177\n",
      "[Fold 2 | Epoch 8] Train Loss: 0.4021 | Train Acc: 0.8505 | Val Loss: 0.4811 | Val Acc: 0.8243\n",
      "[Fold 2 | Epoch 9] Train Loss: 0.3938 | Train Acc: 0.8547 | Val Loss: 0.4638 | Val Acc: 0.8407\n",
      "[Fold 2 | Epoch 10] Train Loss: 0.3883 | Train Acc: 0.8553 | Val Loss: 0.4709 | Val Acc: 0.8354\n",
      "[Fold 2 | Epoch 11] Train Loss: 0.3789 | Train Acc: 0.8611 | Val Loss: 0.4178 | Val Acc: 0.8457\n",
      "[Fold 2 | Epoch 12] Train Loss: 0.3809 | Train Acc: 0.8591 | Val Loss: 0.3834 | Val Acc: 0.8586\n",
      "[Fold 2 | Epoch 13] Train Loss: 0.3672 | Train Acc: 0.8645 | Val Loss: 0.4694 | Val Acc: 0.8379\n",
      "[Fold 2 | Epoch 14] Train Loss: 0.3704 | Train Acc: 0.8632 | Val Loss: 0.3807 | Val Acc: 0.8592\n",
      "[Fold 2 | Epoch 15] Train Loss: 0.3598 | Train Acc: 0.8676 | Val Loss: 0.3985 | Val Acc: 0.8544\n",
      "[Fold 2 | Epoch 16] Train Loss: 0.3603 | Train Acc: 0.8651 | Val Loss: 0.4791 | Val Acc: 0.8206\n",
      "[Fold 2 | Epoch 17] Train Loss: 0.3510 | Train Acc: 0.8683 | Val Loss: 0.4319 | Val Acc: 0.8379\n",
      "[Fold 2 | Epoch 18] Train Loss: 0.3432 | Train Acc: 0.8716 | Val Loss: 0.4158 | Val Acc: 0.8503\n",
      "[Fold 2 | Epoch 19] Train Loss: 0.3421 | Train Acc: 0.8730 | Val Loss: 0.4003 | Val Acc: 0.8586\n",
      "[Fold 2 | Epoch 20] Train Loss: 0.3332 | Train Acc: 0.8753 | Val Loss: 0.3880 | Val Acc: 0.8597\n",
      "[Fold 2 | Epoch 21] Train Loss: 0.3285 | Train Acc: 0.8786 | Val Loss: 0.3849 | Val Acc: 0.8605\n",
      "[Fold 2 | Epoch 22] Train Loss: 0.3194 | Train Acc: 0.8823 | Val Loss: 0.4071 | Val Acc: 0.8560\n",
      "[Fold 2 | Epoch 23] Train Loss: 0.3158 | Train Acc: 0.8806 | Val Loss: 0.4494 | Val Acc: 0.8454\n",
      "[Fold 2 | Epoch 24] Train Loss: 0.3126 | Train Acc: 0.8811 | Val Loss: 0.3947 | Val Acc: 0.8597\n",
      "[Fold 2 | Epoch 25] Train Loss: 0.3029 | Train Acc: 0.8865 | Val Loss: 0.4098 | Val Acc: 0.8516\n",
      "[Fold 2 | Epoch 26] Train Loss: 0.2926 | Train Acc: 0.8924 | Val Loss: 0.4122 | Val Acc: 0.8567\n",
      "[Fold 2 | Epoch 27] Train Loss: 0.2919 | Train Acc: 0.8925 | Val Loss: 0.4806 | Val Acc: 0.8349\n",
      "[Fold 2 | Epoch 28] Train Loss: 0.2837 | Train Acc: 0.8940 | Val Loss: 0.4702 | Val Acc: 0.8349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2 | Epoch 29] Train Loss: 0.2776 | Train Acc: 0.8962 | Val Loss: 0.5317 | Val Acc: 0.8194\n",
      "[Fold 2 | Epoch 30] Train Loss: 0.2709 | Train Acc: 0.8991 | Val Loss: 0.4799 | Val Acc: 0.8404\n",
      "[Fold 2 | Epoch 31] Train Loss: 0.2632 | Train Acc: 0.9033 | Val Loss: 0.4707 | Val Acc: 0.8445\n",
      "[Fold 2 | Epoch 32] Train Loss: 0.2581 | Train Acc: 0.9057 | Val Loss: 0.4345 | Val Acc: 0.8559\n",
      "[Fold 2 | Epoch 33] Train Loss: 0.2492 | Train Acc: 0.9062 | Val Loss: 0.5193 | Val Acc: 0.8324\n",
      "[Fold 2 | Epoch 34] Train Loss: 0.2463 | Train Acc: 0.9086 | Val Loss: 0.5043 | Val Acc: 0.8311\n",
      "[Fold 2 | Epoch 35] Train Loss: 0.2350 | Train Acc: 0.9116 | Val Loss: 0.4665 | Val Acc: 0.8531\n",
      "[Fold 2 | Epoch 36] Train Loss: 0.2333 | Train Acc: 0.9138 | Val Loss: 0.4321 | Val Acc: 0.8623\n",
      "[Fold 2 | Epoch 37] Train Loss: 0.2274 | Train Acc: 0.9140 | Val Loss: 0.4351 | Val Acc: 0.8600\n",
      "[Fold 2 | Epoch 38] Train Loss: 0.2210 | Train Acc: 0.9183 | Val Loss: 0.5159 | Val Acc: 0.8431\n",
      "[Fold 2 | Epoch 39] Train Loss: 0.2146 | Train Acc: 0.9192 | Val Loss: 0.5041 | Val Acc: 0.8404\n",
      "[Fold 2 | Epoch 40] Train Loss: 0.2069 | Train Acc: 0.9209 | Val Loss: 0.5027 | Val Acc: 0.8534\n",
      "[Fold 2 | Epoch 41] Train Loss: 0.2023 | Train Acc: 0.9235 | Val Loss: 0.5037 | Val Acc: 0.8589\n",
      "[Fold 2 | Epoch 42] Train Loss: 0.1993 | Train Acc: 0.9236 | Val Loss: 0.4755 | Val Acc: 0.8542\n",
      "[Fold 2 | Epoch 43] Train Loss: 0.1970 | Train Acc: 0.9252 | Val Loss: 0.5662 | Val Acc: 0.8354\n",
      "[Fold 2 | Epoch 44] Train Loss: 0.1909 | Train Acc: 0.9284 | Val Loss: 0.4979 | Val Acc: 0.8536\n",
      "[Fold 2 | Epoch 45] Train Loss: 0.1840 | Train Acc: 0.9318 | Val Loss: 0.6180 | Val Acc: 0.8223\n",
      "[Fold 2 | Epoch 46] Train Loss: 0.1877 | Train Acc: 0.9308 | Val Loss: 0.5704 | Val Acc: 0.8421\n",
      "[Fold 2 | Epoch 47] Train Loss: 0.1791 | Train Acc: 0.9332 | Val Loss: 0.5069 | Val Acc: 0.8509\n",
      "[Fold 2 | Epoch 48] Train Loss: 0.1747 | Train Acc: 0.9350 | Val Loss: 0.5481 | Val Acc: 0.8392\n",
      "[Fold 2 | Epoch 49] Train Loss: 0.1687 | Train Acc: 0.9365 | Val Loss: 0.5140 | Val Acc: 0.8521\n",
      "[Fold 2 | Epoch 50] Train Loss: 0.1759 | Train Acc: 0.9338 | Val Loss: 0.6172 | Val Acc: 0.8425\n",
      "\n",
      "===== BEST RESULT FOR FOLD 2 =====\n",
      "Best Epoch: 36\n",
      "ACC: 0.8623 | MF1: 0.8209 | G-Mean: 0.8808\n",
      "[Class 0] Prec: 0.9403 | Rec: 0.8879 | F1: 0.9134 | GM: 0.9362\n",
      "[Class 1] Prec: 0.6147 | Rec: 0.5569 | F1: 0.5844 | GM: 0.7359\n",
      "[Class 2] Prec: 0.8846 | Rec: 0.9103 | F1: 0.8973 | GM: 0.9115\n",
      "[Class 3] Prec: 0.9198 | Rec: 0.8628 | F1: 0.8904 | GM: 0.9237\n",
      "[Class 4] Prec: 0.7929 | Rec: 0.8473 | F1: 0.8192 | GM: 0.8966\n",
      "\n",
      "===== Fold 3 =====\n",
      "[INFO] Total parameters BEFORE pruning: 117,851\n",
      "[INFO] Non-zero parameters AFTER pruning: 59,078\n",
      "[INFO] Pruned parameters: 58,773 (49.87%)\n",
      "[Fold 3 | Epoch 1] Train Loss: 0.6075 | Train Acc: 0.7719 | Val Loss: 0.6844 | Val Acc: 0.7530\n",
      "[Fold 3 | Epoch 2] Train Loss: 0.4906 | Train Acc: 0.8142 | Val Loss: 0.4856 | Val Acc: 0.8172\n",
      "[Fold 3 | Epoch 3] Train Loss: 0.4576 | Train Acc: 0.8292 | Val Loss: 0.4923 | Val Acc: 0.8172\n",
      "[Fold 3 | Epoch 4] Train Loss: 0.4357 | Train Acc: 0.8364 | Val Loss: 0.4223 | Val Acc: 0.8466\n",
      "[Fold 3 | Epoch 5] Train Loss: 0.4188 | Train Acc: 0.8454 | Val Loss: 0.4072 | Val Acc: 0.8511\n",
      "[Fold 3 | Epoch 6] Train Loss: 0.4116 | Train Acc: 0.8458 | Val Loss: 0.4673 | Val Acc: 0.8223\n",
      "[Fold 3 | Epoch 7] Train Loss: 0.4016 | Train Acc: 0.8507 | Val Loss: 0.4306 | Val Acc: 0.8451\n",
      "[Fold 3 | Epoch 8] Train Loss: 0.4012 | Train Acc: 0.8519 | Val Loss: 0.3818 | Val Acc: 0.8575\n",
      "[Fold 3 | Epoch 9] Train Loss: 0.3953 | Train Acc: 0.8534 | Val Loss: 0.5549 | Val Acc: 0.8024\n",
      "[Fold 3 | Epoch 10] Train Loss: 0.3905 | Train Acc: 0.8553 | Val Loss: 0.4314 | Val Acc: 0.8451\n",
      "[Fold 3 | Epoch 11] Train Loss: 0.3911 | Train Acc: 0.8557 | Val Loss: 0.4250 | Val Acc: 0.8417\n",
      "[Fold 3 | Epoch 12] Train Loss: 0.3780 | Train Acc: 0.8596 | Val Loss: 0.4172 | Val Acc: 0.8420\n",
      "[Fold 3 | Epoch 13] Train Loss: 0.3777 | Train Acc: 0.8594 | Val Loss: 0.3993 | Val Acc: 0.8526\n",
      "[Fold 3 | Epoch 14] Train Loss: 0.3722 | Train Acc: 0.8599 | Val Loss: 0.4247 | Val Acc: 0.8440\n",
      "[Fold 3 | Epoch 15] Train Loss: 0.3648 | Train Acc: 0.8640 | Val Loss: 0.3857 | Val Acc: 0.8553\n",
      "[Fold 3 | Epoch 16] Train Loss: 0.3624 | Train Acc: 0.8663 | Val Loss: 0.4117 | Val Acc: 0.8504\n",
      "[Fold 3 | Epoch 17] Train Loss: 0.3564 | Train Acc: 0.8666 | Val Loss: 0.3823 | Val Acc: 0.8628\n",
      "[Fold 3 | Epoch 18] Train Loss: 0.3495 | Train Acc: 0.8699 | Val Loss: 0.4120 | Val Acc: 0.8536\n",
      "[Fold 3 | Epoch 19] Train Loss: 0.3441 | Train Acc: 0.8724 | Val Loss: 0.4480 | Val Acc: 0.8398\n",
      "[Fold 3 | Epoch 20] Train Loss: 0.3403 | Train Acc: 0.8720 | Val Loss: 0.3824 | Val Acc: 0.8607\n",
      "[Fold 3 | Epoch 21] Train Loss: 0.3314 | Train Acc: 0.8750 | Val Loss: 0.3761 | Val Acc: 0.8638\n",
      "[Fold 3 | Epoch 22] Train Loss: 0.3323 | Train Acc: 0.8758 | Val Loss: 0.3923 | Val Acc: 0.8602\n",
      "[Fold 3 | Epoch 23] Train Loss: 0.3203 | Train Acc: 0.8809 | Val Loss: 0.4106 | Val Acc: 0.8503\n",
      "[Fold 3 | Epoch 24] Train Loss: 0.3175 | Train Acc: 0.8820 | Val Loss: 0.4300 | Val Acc: 0.8411\n",
      "[Fold 3 | Epoch 25] Train Loss: 0.3101 | Train Acc: 0.8860 | Val Loss: 0.3896 | Val Acc: 0.8576\n",
      "[Fold 3 | Epoch 26] Train Loss: 0.3082 | Train Acc: 0.8851 | Val Loss: 0.3894 | Val Acc: 0.8622\n",
      "[Fold 3 | Epoch 27] Train Loss: 0.3017 | Train Acc: 0.8875 | Val Loss: 0.4068 | Val Acc: 0.8554\n",
      "[Fold 3 | Epoch 28] Train Loss: 0.2912 | Train Acc: 0.8917 | Val Loss: 0.4897 | Val Acc: 0.8318\n",
      "[Fold 3 | Epoch 29] Train Loss: 0.2864 | Train Acc: 0.8931 | Val Loss: 0.4055 | Val Acc: 0.8569\n",
      "[Fold 3 | Epoch 30] Train Loss: 0.2820 | Train Acc: 0.8969 | Val Loss: 0.4553 | Val Acc: 0.8401\n",
      "[Fold 3 | Epoch 31] Train Loss: 0.2781 | Train Acc: 0.8966 | Val Loss: 0.4521 | Val Acc: 0.8529\n",
      "[Fold 3 | Epoch 32] Train Loss: 0.2689 | Train Acc: 0.9009 | Val Loss: 0.4813 | Val Acc: 0.8348\n",
      "[Fold 3 | Epoch 33] Train Loss: 0.2635 | Train Acc: 0.9011 | Val Loss: 0.4519 | Val Acc: 0.8537\n",
      "[Fold 3 | Epoch 34] Train Loss: 0.2583 | Train Acc: 0.9045 | Val Loss: 0.4998 | Val Acc: 0.8362\n",
      "[Fold 3 | Epoch 35] Train Loss: 0.2465 | Train Acc: 0.9072 | Val Loss: 0.4550 | Val Acc: 0.8473\n",
      "[Fold 3 | Epoch 36] Train Loss: 0.2428 | Train Acc: 0.9081 | Val Loss: 0.4110 | Val Acc: 0.8653\n",
      "[Fold 3 | Epoch 37] Train Loss: 0.2345 | Train Acc: 0.9126 | Val Loss: 0.4757 | Val Acc: 0.8498\n",
      "[Fold 3 | Epoch 38] Train Loss: 0.2307 | Train Acc: 0.9140 | Val Loss: 0.5233 | Val Acc: 0.8392\n",
      "[Fold 3 | Epoch 39] Train Loss: 0.2255 | Train Acc: 0.9143 | Val Loss: 0.4616 | Val Acc: 0.8563\n",
      "[Fold 3 | Epoch 40] Train Loss: 0.2196 | Train Acc: 0.9165 | Val Loss: 0.4413 | Val Acc: 0.8596\n",
      "[Fold 3 | Epoch 41] Train Loss: 0.2123 | Train Acc: 0.9201 | Val Loss: 0.4354 | Val Acc: 0.8609\n",
      "[Fold 3 | Epoch 42] Train Loss: 0.2127 | Train Acc: 0.9192 | Val Loss: 0.5031 | Val Acc: 0.8513\n",
      "[Fold 3 | Epoch 43] Train Loss: 0.1975 | Train Acc: 0.9264 | Val Loss: 0.4730 | Val Acc: 0.8579\n",
      "[Fold 3 | Epoch 44] Train Loss: 0.1983 | Train Acc: 0.9274 | Val Loss: 0.4888 | Val Acc: 0.8422\n",
      "[Fold 3 | Epoch 45] Train Loss: 0.1991 | Train Acc: 0.9255 | Val Loss: 0.4690 | Val Acc: 0.8580\n",
      "[Fold 3 | Epoch 46] Train Loss: 0.1916 | Train Acc: 0.9292 | Val Loss: 0.4819 | Val Acc: 0.8552\n",
      "[Fold 3 | Epoch 47] Train Loss: 0.1863 | Train Acc: 0.9307 | Val Loss: 0.4792 | Val Acc: 0.8599\n",
      "[Fold 3 | Epoch 48] Train Loss: 0.1828 | Train Acc: 0.9318 | Val Loss: 0.5297 | Val Acc: 0.8575\n",
      "[Fold 3 | Epoch 49] Train Loss: 0.1814 | Train Acc: 0.9321 | Val Loss: 0.6031 | Val Acc: 0.8381\n",
      "[Fold 3 | Epoch 50] Train Loss: 0.1779 | Train Acc: 0.9329 | Val Loss: 0.4941 | Val Acc: 0.8622\n",
      "\n",
      "===== BEST RESULT FOR FOLD 3 =====\n",
      "Best Epoch: 36\n",
      "ACC: 0.8653 | MF1: 0.8197 | G-Mean: 0.8789\n",
      "[Class 0] Prec: 0.9239 | Rec: 0.9104 | F1: 0.9171 | GM: 0.9459\n",
      "[Class 1] Prec: 0.6350 | Rec: 0.4980 | F1: 0.5582 | GM: 0.6977\n",
      "[Class 2] Prec: 0.8966 | Rec: 0.9008 | F1: 0.8987 | GM: 0.9121\n",
      "[Class 3] Prec: 0.9269 | Rec: 0.8695 | F1: 0.8973 | GM: 0.9277\n",
      "[Class 4] Prec: 0.7792 | Rec: 0.8809 | F1: 0.8269 | GM: 0.9111\n",
      "\n",
      "===== Fold 4 =====\n",
      "[INFO] Total parameters BEFORE pruning: 117,851\n",
      "[INFO] Non-zero parameters AFTER pruning: 59,078\n",
      "[INFO] Pruned parameters: 58,773 (49.87%)\n",
      "[Fold 4 | Epoch 1] Train Loss: 0.5558 | Train Acc: 0.7900 | Val Loss: 0.4660 | Val Acc: 0.8345\n",
      "[Fold 4 | Epoch 2] Train Loss: 0.4729 | Train Acc: 0.8239 | Val Loss: 0.5649 | Val Acc: 0.7978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4 | Epoch 3] Train Loss: 0.4549 | Train Acc: 0.8310 | Val Loss: 0.4617 | Val Acc: 0.8336\n",
      "[Fold 4 | Epoch 4] Train Loss: 0.4388 | Train Acc: 0.8374 | Val Loss: 0.5059 | Val Acc: 0.8173\n",
      "[Fold 4 | Epoch 5] Train Loss: 0.4310 | Train Acc: 0.8411 | Val Loss: 0.4608 | Val Acc: 0.8410\n",
      "[Fold 4 | Epoch 6] Train Loss: 0.4231 | Train Acc: 0.8435 | Val Loss: 0.4002 | Val Acc: 0.8556\n",
      "[Fold 4 | Epoch 7] Train Loss: 0.4091 | Train Acc: 0.8492 | Val Loss: 0.3942 | Val Acc: 0.8536\n",
      "[Fold 4 | Epoch 8] Train Loss: 0.4076 | Train Acc: 0.8484 | Val Loss: 0.4607 | Val Acc: 0.8394\n",
      "[Fold 4 | Epoch 9] Train Loss: 0.4005 | Train Acc: 0.8526 | Val Loss: 0.3928 | Val Acc: 0.8559\n",
      "[Fold 4 | Epoch 10] Train Loss: 0.3876 | Train Acc: 0.8563 | Val Loss: 0.4383 | Val Acc: 0.8375\n",
      "[Fold 4 | Epoch 11] Train Loss: 0.3881 | Train Acc: 0.8558 | Val Loss: 0.4328 | Val Acc: 0.8428\n",
      "[Fold 4 | Epoch 12] Train Loss: 0.3796 | Train Acc: 0.8575 | Val Loss: 0.4009 | Val Acc: 0.8585\n",
      "[Fold 4 | Epoch 13] Train Loss: 0.3769 | Train Acc: 0.8594 | Val Loss: 0.3960 | Val Acc: 0.8564\n",
      "[Fold 4 | Epoch 14] Train Loss: 0.3751 | Train Acc: 0.8613 | Val Loss: 0.3928 | Val Acc: 0.8586\n",
      "[Fold 4 | Epoch 15] Train Loss: 0.3644 | Train Acc: 0.8647 | Val Loss: 0.3843 | Val Acc: 0.8615\n",
      "[Fold 4 | Epoch 16] Train Loss: 0.3577 | Train Acc: 0.8675 | Val Loss: 0.3922 | Val Acc: 0.8587\n",
      "[Fold 4 | Epoch 17] Train Loss: 0.3549 | Train Acc: 0.8679 | Val Loss: 0.3980 | Val Acc: 0.8603\n",
      "[Fold 4 | Epoch 18] Train Loss: 0.3469 | Train Acc: 0.8712 | Val Loss: 0.4027 | Val Acc: 0.8556\n",
      "[Fold 4 | Epoch 19] Train Loss: 0.3422 | Train Acc: 0.8712 | Val Loss: 0.3990 | Val Acc: 0.8524\n",
      "[Fold 4 | Epoch 20] Train Loss: 0.3376 | Train Acc: 0.8760 | Val Loss: 0.3933 | Val Acc: 0.8570\n",
      "[Fold 4 | Epoch 21] Train Loss: 0.3345 | Train Acc: 0.8752 | Val Loss: 0.4039 | Val Acc: 0.8514\n",
      "[Fold 4 | Epoch 22] Train Loss: 0.3242 | Train Acc: 0.8803 | Val Loss: 0.4036 | Val Acc: 0.8613\n",
      "[Fold 4 | Epoch 23] Train Loss: 0.3185 | Train Acc: 0.8808 | Val Loss: 0.3856 | Val Acc: 0.8596\n",
      "[Fold 4 | Epoch 24] Train Loss: 0.3165 | Train Acc: 0.8820 | Val Loss: 0.3826 | Val Acc: 0.8665\n",
      "[Fold 4 | Epoch 25] Train Loss: 0.3070 | Train Acc: 0.8858 | Val Loss: 0.3896 | Val Acc: 0.8602\n",
      "[Fold 4 | Epoch 26] Train Loss: 0.2977 | Train Acc: 0.8908 | Val Loss: 0.4733 | Val Acc: 0.8279\n",
      "[Fold 4 | Epoch 27] Train Loss: 0.2967 | Train Acc: 0.8903 | Val Loss: 0.4020 | Val Acc: 0.8593\n",
      "[Fold 4 | Epoch 28] Train Loss: 0.2897 | Train Acc: 0.8916 | Val Loss: 0.3933 | Val Acc: 0.8607\n",
      "[Fold 4 | Epoch 29] Train Loss: 0.2775 | Train Acc: 0.8962 | Val Loss: 0.4013 | Val Acc: 0.8625\n",
      "[Fold 4 | Epoch 30] Train Loss: 0.2721 | Train Acc: 0.8982 | Val Loss: 0.4618 | Val Acc: 0.8372\n",
      "[Fold 4 | Epoch 31] Train Loss: 0.2669 | Train Acc: 0.9015 | Val Loss: 0.4695 | Val Acc: 0.8481\n",
      "[Fold 4 | Epoch 32] Train Loss: 0.2611 | Train Acc: 0.9030 | Val Loss: 0.4752 | Val Acc: 0.8494\n",
      "[Fold 4 | Epoch 33] Train Loss: 0.2528 | Train Acc: 0.9061 | Val Loss: 0.4566 | Val Acc: 0.8497\n",
      "[Fold 4 | Epoch 34] Train Loss: 0.2477 | Train Acc: 0.9059 | Val Loss: 0.4358 | Val Acc: 0.8570\n",
      "[Fold 4 | Epoch 35] Train Loss: 0.2409 | Train Acc: 0.9104 | Val Loss: 0.4201 | Val Acc: 0.8635\n",
      "[Fold 4 | Epoch 36] Train Loss: 0.2364 | Train Acc: 0.9116 | Val Loss: 0.4318 | Val Acc: 0.8539\n",
      "[Fold 4 | Epoch 37] Train Loss: 0.2296 | Train Acc: 0.9133 | Val Loss: 0.4259 | Val Acc: 0.8599\n",
      "[Fold 4 | Epoch 38] Train Loss: 0.2226 | Train Acc: 0.9166 | Val Loss: 0.4696 | Val Acc: 0.8629\n",
      "[Fold 4 | Epoch 39] Train Loss: 0.2216 | Train Acc: 0.9167 | Val Loss: 0.4407 | Val Acc: 0.8609\n",
      "[Fold 4 | Epoch 40] Train Loss: 0.2080 | Train Acc: 0.9244 | Val Loss: 0.4348 | Val Acc: 0.8648\n",
      "[Fold 4 | Epoch 41] Train Loss: 0.2061 | Train Acc: 0.9214 | Val Loss: 0.4651 | Val Acc: 0.8529\n",
      "[Fold 4 | Epoch 42] Train Loss: 0.2055 | Train Acc: 0.9235 | Val Loss: 0.4564 | Val Acc: 0.8626\n",
      "[Fold 4 | Epoch 43] Train Loss: 0.2035 | Train Acc: 0.9236 | Val Loss: 0.4466 | Val Acc: 0.8645\n",
      "[Fold 4 | Epoch 44] Train Loss: 0.1928 | Train Acc: 0.9278 | Val Loss: 0.4722 | Val Acc: 0.8648\n",
      "[Fold 4 | Epoch 45] Train Loss: 0.1815 | Train Acc: 0.9331 | Val Loss: 0.5530 | Val Acc: 0.8534\n",
      "[Fold 4 | Epoch 46] Train Loss: 0.1807 | Train Acc: 0.9306 | Val Loss: 0.5775 | Val Acc: 0.8460\n",
      "[Fold 4 | Epoch 47] Train Loss: 0.1867 | Train Acc: 0.9302 | Val Loss: 0.4632 | Val Acc: 0.8686\n",
      "[Fold 4 | Epoch 48] Train Loss: 0.1767 | Train Acc: 0.9355 | Val Loss: 0.5531 | Val Acc: 0.8539\n",
      "[Fold 4 | Epoch 49] Train Loss: 0.1722 | Train Acc: 0.9351 | Val Loss: 0.5707 | Val Acc: 0.8526\n",
      "[Fold 4 | Epoch 50] Train Loss: 0.1665 | Train Acc: 0.9373 | Val Loss: 0.5399 | Val Acc: 0.8669\n",
      "\n",
      "===== BEST RESULT FOR FOLD 4 =====\n",
      "Best Epoch: 47\n",
      "ACC: 0.8686 | MF1: 0.8380 | G-Mean: 0.8999\n",
      "[Class 0] Prec: 0.9339 | Rec: 0.9057 | F1: 0.9196 | GM: 0.9447\n",
      "[Class 1] Prec: 0.6667 | Rec: 0.6471 | F1: 0.6567 | GM: 0.7941\n",
      "[Class 2] Prec: 0.9097 | Rec: 0.8792 | F1: 0.8942 | GM: 0.9070\n",
      "[Class 3] Prec: 0.8561 | Rec: 0.9281 | F1: 0.8907 | GM: 0.9521\n",
      "[Class 4] Prec: 0.8061 | Rec: 0.8534 | F1: 0.8291 | GM: 0.9016\n",
      "\n",
      "===== Fold 5 =====\n",
      "[INFO] Total parameters BEFORE pruning: 117,851\n",
      "[INFO] Non-zero parameters AFTER pruning: 59,078\n",
      "[INFO] Pruned parameters: 58,773 (49.87%)\n",
      "[Fold 5 | Epoch 1] Train Loss: 0.6061 | Train Acc: 0.7698 | Val Loss: 0.6345 | Val Acc: 0.7836\n",
      "[Fold 5 | Epoch 2] Train Loss: 0.4812 | Train Acc: 0.8215 | Val Loss: 0.4655 | Val Acc: 0.8237\n",
      "[Fold 5 | Epoch 3] Train Loss: 0.4528 | Train Acc: 0.8354 | Val Loss: 0.4937 | Val Acc: 0.8206\n",
      "[Fold 5 | Epoch 4] Train Loss: 0.4341 | Train Acc: 0.8389 | Val Loss: 0.4200 | Val Acc: 0.8441\n",
      "[Fold 5 | Epoch 5] Train Loss: 0.4265 | Train Acc: 0.8409 | Val Loss: 0.4922 | Val Acc: 0.8085\n",
      "[Fold 5 | Epoch 6] Train Loss: 0.4160 | Train Acc: 0.8474 | Val Loss: 0.4481 | Val Acc: 0.8362\n",
      "[Fold 5 | Epoch 7] Train Loss: 0.4096 | Train Acc: 0.8491 | Val Loss: 0.4190 | Val Acc: 0.8404\n",
      "[Fold 5 | Epoch 8] Train Loss: 0.4000 | Train Acc: 0.8507 | Val Loss: 0.4272 | Val Acc: 0.8430\n",
      "[Fold 5 | Epoch 9] Train Loss: 0.3982 | Train Acc: 0.8536 | Val Loss: 0.4128 | Val Acc: 0.8536\n",
      "[Fold 5 | Epoch 10] Train Loss: 0.3912 | Train Acc: 0.8566 | Val Loss: 0.4173 | Val Acc: 0.8455\n",
      "[Fold 5 | Epoch 11] Train Loss: 0.3875 | Train Acc: 0.8574 | Val Loss: 0.4343 | Val Acc: 0.8461\n",
      "[Fold 5 | Epoch 12] Train Loss: 0.3800 | Train Acc: 0.8601 | Val Loss: 0.4160 | Val Acc: 0.8424\n",
      "[Fold 5 | Epoch 13] Train Loss: 0.3815 | Train Acc: 0.8586 | Val Loss: 0.3894 | Val Acc: 0.8609\n",
      "[Fold 5 | Epoch 14] Train Loss: 0.3739 | Train Acc: 0.8600 | Val Loss: 0.4073 | Val Acc: 0.8534\n",
      "[Fold 5 | Epoch 15] Train Loss: 0.3681 | Train Acc: 0.8636 | Val Loss: 0.3902 | Val Acc: 0.8579\n",
      "[Fold 5 | Epoch 16] Train Loss: 0.3591 | Train Acc: 0.8672 | Val Loss: 0.3855 | Val Acc: 0.8590\n",
      "[Fold 5 | Epoch 17] Train Loss: 0.3537 | Train Acc: 0.8687 | Val Loss: 0.4131 | Val Acc: 0.8517\n",
      "[Fold 5 | Epoch 18] Train Loss: 0.3479 | Train Acc: 0.8706 | Val Loss: 0.4665 | Val Acc: 0.8266\n",
      "[Fold 5 | Epoch 19] Train Loss: 0.3394 | Train Acc: 0.8748 | Val Loss: 0.3818 | Val Acc: 0.8612\n",
      "[Fold 5 | Epoch 20] Train Loss: 0.3341 | Train Acc: 0.8770 | Val Loss: 0.4052 | Val Acc: 0.8527\n",
      "[Fold 5 | Epoch 21] Train Loss: 0.3324 | Train Acc: 0.8756 | Val Loss: 0.4073 | Val Acc: 0.8569\n",
      "[Fold 5 | Epoch 22] Train Loss: 0.3185 | Train Acc: 0.8814 | Val Loss: 0.3887 | Val Acc: 0.8668\n",
      "[Fold 5 | Epoch 23] Train Loss: 0.3221 | Train Acc: 0.8813 | Val Loss: 0.4001 | Val Acc: 0.8559\n",
      "[Fold 5 | Epoch 24] Train Loss: 0.3123 | Train Acc: 0.8836 | Val Loss: 0.4433 | Val Acc: 0.8460\n",
      "[Fold 5 | Epoch 25] Train Loss: 0.3068 | Train Acc: 0.8855 | Val Loss: 0.4157 | Val Acc: 0.8554\n",
      "[Fold 5 | Epoch 26] Train Loss: 0.2973 | Train Acc: 0.8881 | Val Loss: 0.4027 | Val Acc: 0.8533\n",
      "[Fold 5 | Epoch 27] Train Loss: 0.2874 | Train Acc: 0.8947 | Val Loss: 0.3928 | Val Acc: 0.8698\n",
      "[Fold 5 | Epoch 28] Train Loss: 0.2820 | Train Acc: 0.8945 | Val Loss: 0.4578 | Val Acc: 0.8476\n",
      "[Fold 5 | Epoch 29] Train Loss: 0.2765 | Train Acc: 0.8956 | Val Loss: 0.4111 | Val Acc: 0.8600\n",
      "[Fold 5 | Epoch 30] Train Loss: 0.2716 | Train Acc: 0.9006 | Val Loss: 0.4246 | Val Acc: 0.8560\n",
      "[Fold 5 | Epoch 31] Train Loss: 0.2610 | Train Acc: 0.9013 | Val Loss: 0.4888 | Val Acc: 0.8295\n",
      "[Fold 5 | Epoch 32] Train Loss: 0.2559 | Train Acc: 0.9043 | Val Loss: 0.4504 | Val Acc: 0.8503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 5 | Epoch 33] Train Loss: 0.2502 | Train Acc: 0.9060 | Val Loss: 0.4572 | Val Acc: 0.8500\n",
      "[Fold 5 | Epoch 34] Train Loss: 0.2403 | Train Acc: 0.9094 | Val Loss: 0.4750 | Val Acc: 0.8427\n",
      "[Fold 5 | Epoch 35] Train Loss: 0.2375 | Train Acc: 0.9114 | Val Loss: 0.5503 | Val Acc: 0.8222\n",
      "[Fold 5 | Epoch 36] Train Loss: 0.2322 | Train Acc: 0.9128 | Val Loss: 0.4996 | Val Acc: 0.8322\n",
      "[Fold 5 | Epoch 37] Train Loss: 0.2276 | Train Acc: 0.9141 | Val Loss: 0.5029 | Val Acc: 0.8448\n",
      "[Fold 5 | Epoch 38] Train Loss: 0.2187 | Train Acc: 0.9174 | Val Loss: 0.4915 | Val Acc: 0.8444\n",
      "[Fold 5 | Epoch 39] Train Loss: 0.2075 | Train Acc: 0.9226 | Val Loss: 0.5521 | Val Acc: 0.8382\n",
      "[Fold 5 | Epoch 40] Train Loss: 0.2064 | Train Acc: 0.9213 | Val Loss: 0.4871 | Val Acc: 0.8573\n",
      "[Fold 5 | Epoch 41] Train Loss: 0.2010 | Train Acc: 0.9238 | Val Loss: 0.4808 | Val Acc: 0.8589\n",
      "[Fold 5 | Epoch 42] Train Loss: 0.1975 | Train Acc: 0.9238 | Val Loss: 0.4955 | Val Acc: 0.8510\n",
      "[Fold 5 | Epoch 43] Train Loss: 0.1869 | Train Acc: 0.9297 | Val Loss: 0.5440 | Val Acc: 0.8460\n",
      "[Fold 5 | Epoch 44] Train Loss: 0.1898 | Train Acc: 0.9282 | Val Loss: 0.5631 | Val Acc: 0.8471\n",
      "[Fold 5 | Epoch 45] Train Loss: 0.1860 | Train Acc: 0.9293 | Val Loss: 0.5114 | Val Acc: 0.8345\n",
      "[Fold 5 | Epoch 46] Train Loss: 0.1775 | Train Acc: 0.9325 | Val Loss: 0.6558 | Val Acc: 0.8316\n",
      "[Fold 5 | Epoch 47] Train Loss: 0.1717 | Train Acc: 0.9340 | Val Loss: 0.4962 | Val Acc: 0.8686\n",
      "[Fold 5 | Epoch 48] Train Loss: 0.1695 | Train Acc: 0.9349 | Val Loss: 0.4890 | Val Acc: 0.8651\n",
      "[Fold 5 | Epoch 49] Train Loss: 0.1685 | Train Acc: 0.9363 | Val Loss: 0.5671 | Val Acc: 0.8407\n",
      "[Fold 5 | Epoch 50] Train Loss: 0.1571 | Train Acc: 0.9409 | Val Loss: 0.5853 | Val Acc: 0.8454\n",
      "\n",
      "===== BEST RESULT FOR FOLD 5 =====\n",
      "Best Epoch: 27\n",
      "ACC: 0.8698 | MF1: 0.8235 | G-Mean: 0.8836\n",
      "[Class 0] Prec: 0.9078 | Rec: 0.9134 | F1: 0.9106 | GM: 0.9456\n",
      "[Class 1] Prec: 0.6694 | Rec: 0.4843 | F1: 0.5620 | GM: 0.6893\n",
      "[Class 2] Prec: 0.9229 | Rec: 0.8910 | F1: 0.9067 | GM: 0.9177\n",
      "[Class 3] Prec: 0.9164 | Rec: 0.9093 | F1: 0.9128 | GM: 0.9477\n",
      "[Class 4] Prec: 0.7610 | Rec: 0.9015 | F1: 0.8253 | GM: 0.9179\n",
      "\n",
      "===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\n",
      "ACC: 0.8662 | MF1: 0.8256 | G-Mean: 0.8858\n",
      "[Class 0] Prec: 0.9225 | Rec: 0.9065 | F1: 0.9144 | GM: 0.9438\n",
      "[Class 1] Prec: 0.6556 | Rec: 0.5404 | F1: 0.5924 | GM: 0.7268\n",
      "[Class 2] Prec: 0.9031 | Rec: 0.8931 | F1: 0.8980 | GM: 0.9111\n",
      "[Class 3] Prec: 0.8991 | Rec: 0.8969 | F1: 0.8980 | GM: 0.9399\n",
      "[Class 4] Prec: 0.7837 | Rec: 0.8716 | F1: 0.8253 | GM: 0.9072\n",
      "Confusion Matrix:\n",
      "[[ 5865   238   156    19   192]\n",
      " [  275  1378   316     2   579]\n",
      " [  122   224 13195   434   800]\n",
      " [   12     0   449  4054     5]\n",
      " [   84   262   495     0  5709]]\n"
     ]
    }
   ],
   "source": [
    "#p9\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ==== Load and Normalize Data ====\n",
    "\n",
    "df = pd.read_csv(\"pruned_dataset3.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "     # === Build and Prune Model ===\n",
    "    model_unpruned = FinalNetwork(C=9, num_classes=num_classes, layers=9, genotype=searched_genotype).to(device)\n",
    "    total_params_before = sum(p.numel() for p in model_unpruned.parameters())\n",
    "    print(f\"[INFO] Total parameters BEFORE pruning: {total_params_before:,}\")\n",
    "\n",
    "    model = prune_model_entropy(model_unpruned, prune_ratio=0.5)\n",
    "    nonzero_params_after = sum((p != 0).sum().item() for p in model.parameters())\n",
    "    zero_params = total_params_before - nonzero_params_after\n",
    "    pruned_ratio = 100 * zero_params / total_params_before\n",
    "    print(f\"[INFO] Non-zero parameters AFTER pruning: {nonzero_params_after:,}\")\n",
    "    print(f\"[INFO] Pruned parameters: {zero_params:,} ({pruned_ratio:.2f}%)\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    " \n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "\n",
    "    for epoch in range(50):  # You can change this to 50 or more\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b499a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fold 1 =====\n",
      "[Fold 1 | Epoch 1] Train Loss: 0.5687 | Train Acc: 0.7872 | Val Loss: 0.4963 | Val Acc: 0.8136\n",
      "[Fold 1 | Epoch 2] Train Loss: 0.4643 | Train Acc: 0.8297 | Val Loss: 0.4777 | Val Acc: 0.8278\n",
      "[Fold 1 | Epoch 3] Train Loss: 0.4509 | Train Acc: 0.8321 | Val Loss: 0.4428 | Val Acc: 0.8359\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from model_build import FinalNetwork\n",
    "\n",
    "# ==== Load and Normalize Data ====\n",
    "\n",
    "df = pd.read_csv(\"pruned_dataset3.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "# Z-score normalization\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==== Evaluation Metric Function ====\n",
    "def evaluate_metrics(y_true, y_pred, num_classes):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mf1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    prec = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "    f1s = f1_score(y_true, y_pred, average=None, zero_division=0)\n",
    "\n",
    "    gmeans = []\n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_pred == c) & (y_true == c))\n",
    "        fn = np.sum((y_pred != c) & (y_true == c))\n",
    "        tn = np.sum((y_pred != c) & (y_true != c))\n",
    "        fp = np.sum((y_pred == c) & (y_true != c))\n",
    "        gm = np.sqrt((tp / (tp + fn + 1e-6)) * (tn / (tn + fp + 1e-6)))\n",
    "        gmeans.append(gm)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    return acc, mf1, np.mean(gmeans), prec, rec, f1s, gmeans, cm\n",
    "\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "    X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "    X_val, y_val = X_all[val_idx], y_all[val_idx]\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64, shuffle=False)\n",
    "\n",
    "    model = FinalNetwork(C=9, num_classes=num_classes, layers=7, genotype=searched_genotype).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "\n",
    "    for epoch in range(50):  # You can change this to 50 or more\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad5a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p7\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ==== Load and Normalize Data ====\n",
    "\n",
    "df = pd.read_csv(\"pruned_dataset3.csv\")\n",
    "X_np = df.drop(columns=[\"label\"]).values\n",
    "y_np = df[\"label\"].values\n",
    "\n",
    "X_mean = X_np.mean(axis=0)\n",
    "X_std = np.where(X_np.std(axis=0) == 0, 1, X_np.std(axis=0))\n",
    "X_z = (X_np - X_mean) / X_std\n",
    "X_z = np.clip(X_z, -3, 3) / 3.0\n",
    "\n",
    "X_all = torch.tensor(X_z, dtype=torch.float32).unsqueeze(1)\n",
    "y_all = torch.tensor(y_np, dtype=torch.long)\n",
    "\n",
    "num_classes = len(np.unique(y_np))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ==== K-Fold Training ====\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "all_val_true, all_val_pred = [], []\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(kfold.split(X_all)):\n",
    "    print(f\"\\n===== Fold {fold_idx + 1} =====\")\n",
    "\n",
    "     # === Build and Prune Model ===\n",
    "    model_unpruned = FinalNetwork(C=9, num_classes=num_classes, layers=7, genotype=searched_genotype).to(device)\n",
    "    total_params_before = sum(p.numel() for p in model_unpruned.parameters())\n",
    "    print(f\"[INFO] Total parameters BEFORE pruning: {total_params_before:,}\")\n",
    "\n",
    "    model = prune_model_entropy(model_unpruned, prune_ratio=0.5)\n",
    "    nonzero_params_after = sum((p != 0).sum().item() for p in model.parameters())\n",
    "    zero_params = total_params_before - nonzero_params_after\n",
    "    pruned_ratio = 100 * zero_params / total_params_before\n",
    "    print(f\"[INFO] Non-zero parameters AFTER pruning: {nonzero_params_after:,}\")\n",
    "    print(f\"[INFO] Pruned parameters: {zero_params:,} ({pruned_ratio:.2f}%)\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    " \n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    best_result = {}\n",
    "\n",
    "    for epoch in range(50):  # You can change this to 50 or more\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_true, train_pred = [], []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_true.extend(y.cpu().numpy())\n",
    "            train_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true, val_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device).squeeze(-1), y.to(device)\n",
    "                output = model(x)\n",
    "                loss = criterion(output, y)\n",
    "                val_loss += loss.item()\n",
    "                val_true.extend(y.cpu().numpy())\n",
    "                val_pred.extend(output.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_true, train_pred)\n",
    "        val_acc = accuracy_score(val_true, val_pred)\n",
    "\n",
    "        print(f\"[Fold {fold_idx+1} | Epoch {epoch+1}] Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "              f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(val_true), np.array(val_pred), num_classes)\n",
    "            best_result = {\n",
    "                'epoch': epoch + 1,\n",
    "                'acc': acc,\n",
    "                'mf1': mf1,\n",
    "                'gmean': mgm,\n",
    "                'prec': prec,\n",
    "                'rec': rec,\n",
    "                'f1': f1s,\n",
    "                'gmean_class': gmeans,\n",
    "                'cm': cm,\n",
    "                'val_true': val_true,\n",
    "                'val_pred': val_pred\n",
    "            }\n",
    "\n",
    "    # === Print Best Result for Fold ===\n",
    "    print(f\"\\n===== BEST RESULT FOR FOLD {fold_idx+1} =====\")\n",
    "    print(f\"Best Epoch: {best_result['epoch']}\")\n",
    "    print(f\"ACC: {best_result['acc']:.4f} | MF1: {best_result['mf1']:.4f} | G-Mean: {best_result['gmean']:.4f}\")\n",
    "    for i in range(num_classes):\n",
    "        print(f\"[Class {i}] Prec: {best_result['prec'][i]:.4f} | Rec: {best_result['rec'][i]:.4f} \"\n",
    "              f\"| F1: {best_result['f1'][i]:.4f} | GM: {best_result['gmean_class'][i]:.4f}\")\n",
    "\n",
    "    # Gộp toàn bộ val_true và val_pred để đánh giá toàn bộ tập sau K-Fold\n",
    "    all_val_true.extend(best_result['val_true'])\n",
    "    all_val_pred.extend(best_result['val_pred'])\n",
    "\n",
    "# ==== FINAL EVALUATION ON MERGED VAL SET ====\n",
    "acc, mf1, mgm, prec, rec, f1s, gmeans, cm = evaluate_metrics(np.array(all_val_true), np.array(all_val_pred), num_classes)\n",
    "\n",
    "print(\"\\n===== FINAL EVALUATION ON MERGED TEST SET (AFTER K-FOLD) =====\")\n",
    "print(f\"ACC: {acc:.4f} | MF1: {mf1:.4f} | G-Mean: {mgm:.4f}\")\n",
    "for i in range(num_classes):\n",
    "    print(f\"[Class {i}] Prec: {prec[i]:.4f} | Rec: {rec[i]:.4f} | F1: {f1s[i]:.4f} | GM: {gmeans[i]:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ac3f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.5 (NGC 24.09/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
